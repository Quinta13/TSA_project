---
title: "Chicago - Red Light Camera Violations"
author: "Sebastiano Quintavalle"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    theme: united
editor_options: 
  chunk_output_type: console
---

```{r output setup, include=FALSE}
knitr::opts_chunk$set(include=TRUE)
knitr::opts_chunk$set(echo=FALSE)
knitr::opts_chunk$set(fig.align='center')
```

```{r environment setup, include=FALSE}
rm(list=ls())
Sys.setlocale("LC_TIME", "en_US.UTF-8")
```

```{r packages, include=FALSE}
library(forecast)
```

```{r source files}
source("./src/arima_utils.R")
source("./src/globals.R")
source("./src/plotting.R")
source("./src/smoothing.R")
source("./src/time.R")
```


# 1. Introduction

## Red Light Camera violations

With the advent of the digital era, urban areas are increasingly adopting **automated detection systems** to gather detailed data on city dynamics. This approach aims to enhance the overall conditions of the city through the analysis of relevant information, with the primary goal of implementing innovative solutions that improve the city's efficiency based on automatically collected data.

Examples of this include cameras that regulate traffic flows, such as **red light violation detectors**. Analyzing the trend of this factor over time is crucial for road safety and urban planning policies, as the violation is often a highly probable cause of accidents.

## Report structure

Il report analizza un caso specifico di questa tipologia di dato, utilizzando come caso di studio il numero di infrazioni di semaforo rosso nella città di chicago. Il report si articola in 5 sezioni.

1. Per primo viene fornita una overview del dataset oggetto dello studio, specificandone la fonte, il preprocessing effettuato e effettuando alcune operazioni preliminari di pulizia dei dati, la suddivisione della città di Chicagoi in diverse  zone e la creazione di serie temporali con frequenza sia giornaliera che settimanale.

2. Una prima indagine riguarda la scomposizione della serie temporale in termini di stagionalità e trend utilizzando diverse tecniche di filtering. Seppur sia molto comune che il numero di violazioni sia governato da un fattore stagionale questo evidenzi un certo trend che sia indicativo di alcune politiche nell'ambito.

3. Una seconda analisi è in merito al 

4.

5. Da fare alla fine

## The dataset

### Resource reference
The dataset is available on the [Chicago Data Portal](https://data.cityofchicago.org), the official open-data website of the city of Chicago, Illinois, USA. It consists of a **daily camera survey on red traffic light violations** downloadable [here](https://data.cityofchicago.org/Transportation/Red-Light-Camera-Violations/spqx-js37/about_data). There are approximately 300 cameras scattered throughout the city, ind their positions, specified by **latitude** and **longitude**, are provided

### Preprocessing
The dataset on which the analysis will be conducted it's not the raw downloadable version, but a **preprocessed version** elaborated in the [attached Jupyter Notebook](./data_preparation.ipynb). The main reason for preprocessing using a different technology is the extensive set of utilities that *Python* offers for geospatial analysis, particularly with tools like [GeoPandas](https://geopandas.org/en/stable/). The major preliminary operations include:"

1. **Grouping by region**. Recognizing the impracticality of analyzing each camera observation individually, a necessary step is aggregation. To achieve this, geo-spatial data corresponding to the nine regions that comprise the city was downloaded (the [file](https://data.cityofchicago.org/Facilities-Geographic-Boundaries/Boundaries-Community-Areas-current-/cauq-8yn6) is always available on the Chicago Data Portal). Each camera was then assigned to the specific region within whose polygon it resides. For visual representation, a [Folium document](./out/camera_map.html) is provided to showcase the camera locations on the map.

2. **Time period**. After assigning each camera to a specific region, observations can be aggregated within a given region and on a specific day by calculating the sum of violations recorded by individual cameras. It's crucial to note that cameras were not universally activated or deactivated simultaneously, which may impact the transparency of the observation count. To address this, only cameras active throughout the entire period from *01/01/2015* to *12/31/2022* were considered. This ensures a consistent dataset, minimizing potential biases arising from variations in the number of active cameras on specific dates.


### Overview

The dataset `violations.csv`is available at [this path](./out/violations.csv). Let's inspect the very first few lines.

```{r reading file}
# Reading the file
violations.region.df <- read.csv(file=violation_file)

# Casting Regions as factors
violations.region.df$Region = factor(violations.region.df$Region, levels=unlist(names.regions))

# Converting Date column to DateType
violations.region.df$Date <- as.Date(
  x      = as.character(violations.region.df$Date),
  format = "%m/%d/%Y"
)
```


```{r df head}
# Inspect first lines
head(violations.region.df, 15)
```

The dataset consists of **daily observations for each region**, where each entry represents a triplet of Region-Date-Violation count. Now, let's proceed to analyze the basic statistics.

```{r df summary}
summary(violations.region.df)
```

For each region we have a total of $2922$ observations, which cover a **time window of 8 years**, from *January 1, 2015*, to *December 31, 2022* (note *2016* and *2020* are leap years). 

#### Violation and cameras

Statistics related to the number of violations are highly condensed as they aggregate data from multiple regions. Therefore, we prefer a more detailed visualization through a boxplot. 

```{r df violations boxplot, fig.width=8, fig.height=6}
boxplot(Violations ~ Region, data = violations.region.df, main = "Violations by Region",
        xlab = "Region", ylab = "Violations", col=unlist(region.colors))

unlist(names.regions)
```

The center of **mass of violations is contained** within all regions, except for the *West*, which has a more extended body and, in general, a more dispersed pattern of observations. It is not possible to make direct comparisons on the number of observations since regions do not have equal surface areas or, especially, an equal number of cameras. However, it is interesting to note that, in general, there are **many more observations exceeding the tails** in terms of **peeks** as compared to **minum**. This condition is particularly pronounced in the South, while it is absent in the *FarNorth*.

```{r df violations cameras, fig.width=6, fig.height=6}
# Reading the file
camera.df <- read.csv(file = camera_file)
camera.df <- camera.df[match(unlist(names.regions), camera.df$Region),]

# Casting Regions as factors
camera.df$Region <- factor(camera.df$Region, levels = unlist(names.regions))

camera.df
```

As we anticipated, the comparison between regions is not fair in terms of observations because it is strictly linked to the **number of cameras**. Let's investigate their distribution.

```{r camera histogram, fig.width=6, fig.height=6}
barplot(
  camera.df$Camera,
  names.arg = camera.df$Region,
  col = unlist(region.colors),
  main = 'Camera per Region', 
  ylab = 'Cameras',
  las=2
)
grid()
```

The variability highlighted by the boxplot is easily explained by the number of cameras in each region: the region with the least variability, the *Center*, also has a relatively low number of cameras, while the high variability in the *West* is certainly indicative of a large number of cameras. It is also noticeable that, in general, there are more cameras in the northern regions compared to those in the south.

Consequently, we can use this information to calculate the average number of violations relative to the number of cameras. This allows for metrics that facilitate comparisons between regions."

```{r mean violation per camera histogram, fig.width=6, fig.height=6}
# Mean violations per region
camera.df <- merge(
  aggregate(Violations ~ Region, 
            data = violations.region.df, 
            FUN = mean),
  camera.df, 
  by = "Region")

# Sort rows
camera.df <- camera.df[match(unlist(names.regions), camera.df$Region),]

# Compute mean violation
camera.df$ViolationsPerCamera <- camera.df$Violations / camera.df$Camera

barplot(
  camera.df$ViolationsPerCamera,
  names.arg = camera.df$Region,
  col = unlist(region.colors),
  main = 'Average Violation per Camera per Region', 
  xlab = 'Region', ylab = 'Avg Violations', las=2
)
grid()
```

The graph highlights a probable tendency to commit more violations in the two southern regions, South and FarSouthEast, and a lower number in the FarNorth, especially in the NorthWest.

#### Missing values

As indicated by the summary, there are $5$ missing values. Let's inspect them:

```{r df nan}
violations.region.df[is.na(violations.region.df$Violations),]
```

They all correspond to the same date: *December 7, 2021*. A quick internet search doesn't reveal any specific conditions related to this date. Its handling is deferred to further sections.

#### Region in Chicago

As previously seen, the dataset divides the information across the **9 regions of Chicago**:

```{r region levels}
levels(violations.region.df$Region)
```

We are also analyzing the political map.

```{r chicago regions, out.width = "450px"}
knitr::include_graphics("./out/chicago_sides.png")
```

```{r region split}
region.df <- split(
  violations.region.df,
  violations.region.df$Region
)
```

The following analyses will be conducted by **treating observations from each region separately**. The main goal is to investigate potential differences in terms of characteristic phenomena within each region, leading to different intervention strategies.

### Daily observations

```{r region daily conversion}
region.ts.daily <- lapply(
  region.df, 
  daily_df_to_daily_ts
)
```

Let's start by considering a **time series of daily violations** for each **region**.

```{r region daily ts grid, fig.width=8, fig.height=10}
plot_ts_grid(
  ts_list = region.ts.daily,
  n_row   = 5,
  names   = unlist(names.regions),
  colors  = region.colors,
  main    = "Daily red light camera violations in Chicago regions",
  ylab    = "Daily violations"
)
```

We can already make some initial observations:

* The time series already reveal, at first glance, a crucial **seasonal pattern**, with the number of violations tending to increase during the summer seasons.
* Additionally, some regions seem to have specific years with notably higher violation counts, such as 2017 for Central and Southwest or 2020 for the South. 
* In general, the patterns of the three northern regions (*FarNorth*, *Northwest*, and *North*) exhibit a high degree of similarity, as do the three southern regions (*South*, *FarSouthWest*, and *FarSouthEast*).

However, it is important to exercise caution when making direct comparisons between these graphs due to differing scales. Let's attempt to plot them on a single graph.

```{r region daily ts, fig.width=8, fig.height=6}
plot_multiple_ts(
  ts_list = region.ts.daily,
  colors  = region.colors,
  names   = unlist(names.regions),
  main    = "Daily red light camera violations in Chicago regions",
  ylab    = names.ylab$daily
)
```

The result is not satisfactory; the large number of data points makes the graph challenging to interpret. Nevertheless, we can still visualize a significant seasonal pattern more clearly and observe that there are some **anomalous observations** occurring on the same day across multiple areas. Let's proceed to analyze them in the very next paragraph.

### Anomalous observations

#### Black Lives Matter protest

The most prominent one is a very high spike that occurs in most regions in the central and southern areas.

```{r outlier1}
above_threshold(
  ts = region.ts.daily$West,
  threshold = 700
)
```

The date *May 30, 2020*, corresponds to significant days of protests and unrest in the city following the Black Lives Matter movement demonstration, which protested the death of George Floyd. The confrontation led to a real urban battle, causing traffic jams and accidents along the city streets. Read more [here](https://en.wikipedia.org/wiki/George_Floyd_protests_in_Chicago).

```{r blm protest,  fig.cap="Protesters destroy police vehicles , on May 30, 2020 during a protest against the death of George Floyd (Photo by Jim Vondruska)", out.width = "400px", echo=FALSE, include=TRUE}
knitr::include_graphics("https://media.nbcchicago.com/2019/09/GettyImages-1216502225.jpg?quality=85&strip=all&fit=8660%2C5773&w=775&h=436&crop=0")
```

#### Potential system failure

In addition, there is a second negative peak that is common to almost every region:

```{r outlier2}
above_threshold(
  ts=region.ts.daily$NorthWest,
  threshold=29,
  upper=FALSE
)
```

Many datasets record a negative peak on *December 7, 2021*, which we recall is the same day for which some readings are missing. Although, as mentioned earlier, it is difficult to find information on the web, it is possible to consider that there might have been a general malfunction on that date. Even where the data is available, it seems too low to be plausible.

#### Snowstorms

The last interesting cases are a series of negative peaks that occur in some regions at more or less regular intervals over the years.

```{r outlier3}
above_threshold(
  ts=region.ts.daily$West,
  threshold = 110,
  upper=FALSE
) 
```

The dates include the already discussed *December 7, 2021*, but also a series of dates that occur between late January and early February. As suggested by some internet research, this is a period that typically brings snowstorms to the city, like this one [here](https://www.weather.gov/lot/2015_Feb01_Snow), partially blocking roads and during which it is generally not advisable to go out.

Since the data will undergo further forms of aggregation, the handling of these problematic observations is postponed to future sessions.

### Weekly observations

As we have seen, daily observations can be abundant and might somewhat complicate visual interpretation. For this reason, we also work with a second version of time series that involves weekly average observations. The frequency of this type of time series is 52 weeks, so potential days at the beginning or end of the year are grouped with the adjacent week.

```{r region weekly conversion}
region.ts.weekly <- lapply(
  region.df,
  daily_df_to_weekly_ts
)
```


```{r region weekly ts grid, fig.width=8, fig.height=10}
plot_ts_grid(
  ts_list=region.ts.weekly,
  n_row=5,
  names=unlist(names.regions),
  colors=region.colors,
  main="Avg daily red light camera violations per week in Chicago regions",
  ylab="Avg daily violations per week"
)
```

A smaller number of points certainly makes the observations smoother to interpret. The previous observations appear clearer, especially the apparent similarity between two northern regions, *FarNorth* and *NorthWest*, and the three southern regions, *South*, *FarSouthWest*, and *FarSouthEast*.

Let's investigate possible relationships by visualizing them all in a single plot.

```{r region weekly ts, fig.width=8, fig.height=6}
plot_multiple_ts(
  ts_list=region.ts.weekly,
  colors=region.colors,
  names=unlist(names.regions),
  main="Avg daily red light camera violations per week in Chicago regions",
  ylab=names.ylab$weekly,
  lwd=2
)
```

Even with a smoother version, we are not able to draw many conclusions, except to emphasize once again the evidence of a significant seasonal pattern.

For this reason, in the next section, we suggest a second step of aggregation by grouping the regions into three areas based on geographical proximity and similar patterns found in previous analyses.

## Aggregating by areas

The dataset encompasses observations for **nine distinct regions** within Chicago. To streamline the analysis, which could become cumbersome when examining each of the nine regions individually, a **subsequent aggregation** is conducted, categorizing the city into **three primary areas**:

* ***North***: FarNorth, NorthWest, North.
* ***Center***: Central, West, SouthWest.
* ***South***: , South, FarSouthWest, FarSouthEast.

```{r chicago sides,  fig.cap="Chicago sides", out.width = "700px"}
knitr::include_graphics("./out/chicago_sides_and_areas.png")
```

```{r area definition}
# Assigning each Region to the specific Area
violations.region.df$Area <- 
  ifelse(violations.region.df$Region %in% names.regions$North,  'North',
  ifelse(violations.region.df$Region %in% names.regions$Center, 'Center',
  ifelse(violations.region.df$Region %in% names.regions$South,  'South',  NA)))

# Casting to factors
violations.region.df$Area = as.factor(violations.region.df$Area)

# Aggregating violations by areas
violations.area.df = aggregate(
  Violations ~ Area + Date,
  data=violations.region.df,
  sum
)
```


```{r areas add missing info}

# Add missing observation
violations.area.df <- rbind(
  violations.area.df, 
  data.frame(
    Area=as.factor("South"),
    Date=as.Date("2021-12-07"),
    Violations=0
  )
)

# Sort the dataset by the date column
violations.area.df <- violations.area.df[order(violations.area.df$Date), ]
```

```{r dataframe area split}
# List of areas
area.df <- split(
  violations.area.df,
  violations.area.df$Area
)
names(area.df)
```

### Daily observations

As previously done, we present the different views of daily and monthly observations in the new aggregated version for areas.

```{r area daily conversion}
area.ts.daily <- lapply(
  area.df, 
  daily_df_to_daily_ts
)
```

```{r area daily ts grid, fig.width=6, fig.height=8}
plot_ts_grid(
  ts_list=area.ts.daily,
  n_row=3,
  names=names.area,
  colors=area.colors,
  main="Daily red light camera violations in Chicago areas",
  ylab=names.ylab$daily
)
```

This more condensed version partially reaffirms some observations made at the region level, such as a higher number of violations in a specific year. In particular, both negative and positive peaks are more evident.

```{r area daily ts, fig.width=8, fig.height=6}
plot_multiple_ts(
  ts_list=area.ts.daily,
  names=names.area,
  colors=area.colors,
  main="Daily red light camera violations in Chicago areas",
  ylab=names.ylab$daily
)
```

The simultaneous visualization now finally provides some insights. It is particularly evident that while the trend between the north and the center has remained quite similar, the south was initially lower, but then a noticeable trend has brought it, in the post-pandemic years, to reach levels similar to those of the other two areas.

### Weekly observations

In general, we expect to see similar and perhaps clearer results in the weekly version.

```{r area weekly conversion}
area.ts.weekly <- lapply(
  area.df, 
  daily_df_to_weekly_ts
)
```


```{r area weekly ts grid, fig.width=6, fig.height=8}
plot_ts_grid(
  ts_list=area.ts.weekly,
  n_row=3,
  names=names.area,
  colors=area.colors,
  main="Avg daily red light camera violations per week in Chicago regions",
  ylab=names.ylab$weekly
)
```

This visualization might still be able to highlight how there are even local peaks that are common to all three areas, thus indicating a condition that is shared across the entire city.

```{r area weekly ts, fig.width=7, fig.height=6}
plot_multiple_ts(
  ts_list=area.ts.weekly,
  names=names.area,
  colors=area.colors,
  main="Avg daily red light camera violations per week in Chicago regions",
  ylab=names.ylab$weekly,
  lwd=2
)
```

The combined graph even better highlights the upward trend in the South area. However, compared to before, it is capable of showing that, although the North and Center areas have a very similar overall trend, the one in the center reaches much higher peaks during the summer.

## Replacing outliers

The following chapters will use this last aggregated representation by area as the subject of investigation. Before proceeding in detail with the analysis, it is therefore necessary to address the anticipated issue of **outliers**, i.e. observations that differ substantially from the vast majority of observations.

### Outliers detection

Outliers detection and replacement rely on the `tsoutliers()` function in the `forecast package`. 

1. First, outliers are identified by calculating an STL decomposition and then identifying outliers in the residual regime.

2. Then, the replace value is estimated using linear interpolation of neighoring observations.

More details can be found [here](https://robjhyndman.com/hyndsight/tsoutliers/).

#### North

```{r north outliers, fig.height=4, fig.width=6}
outliers <- list()

outliers$North <- outliers_diagnostic(
  ts=area.ts.daily$North,
  colors=list(plot=area.colors$North, 
              old='deeppink', 
              new='steelblue'),
  main=paste("North Outliers"),
  ylab=names.ylab$daily
)
```

In the *North* area the only identified information pertains to *December 7, 2021*, which we have already analyzed as a day when a potential malfunction in the detection system may have occurred.

```{r north outliers replacement}
area.df$North = replace_outliers(
  df=area.df$North,
  ts=area.ts.daily$North,
  outliers=outliers$North
)
```

#### Center

```{r center outliers, fig.height=4, fig.width=6}
outliers$Center <- outliers_diagnostic(
    ts=area.ts.daily$Center,
    colors=list(plot=area.colors$Center, 
                old='deeppink', 
                new='steelblue'),
    main=paste("Center Outliers"),
    ylab=names.ylab$daily
)
outliers
```

Moving to the central area, we still find the date *December 7, 2021*, but also the date *May 31, 2021*, where we know there was an abnormal spike due to the protests in the city during the Black Lives Matter demonstration.

```{r center outliers replacement}
outliers$Center$index[1] <- outliers$Center$index[1]+1 # 365.25 format fix
area.df$Center = replace_outliers(
  df=area.df$Center,
  ts=area.ts.daily$Center,
  outliers=outliers$Center
)
```

#### South
```{r south outliers, fig.height=4, fig.width=6}
outliers$South <- outliers_diagnostic(
  ts=area.ts.daily$South,
  colors=list(plot=area.colors$South, 
              old='deeppink', 
              new='orange'),
  main=paste("South Outliers"),
  ylab=names.ylab$daily
)
```

Differently from the other two areas, for the South, many outliers have been identified, all in the second half of the time series when there was a significant increase in the average number of violations following the pandemic years. Some points cannot be considered outliers in all respects and may be the result of some limitations in the procedure; therefore, we only retain modifications for some of them:

* The dates *2020-05-30* and *2020-05-31*, where very high peaks were recorded due to protests sparked by the Black Lives Matter movement.
* The dates *2021-02-15* and *2022-02-02*, where significant snowstorms that blocked the streets occurred.
* The date *2021-07-12*, the already mentioned date where we assume some sort of malfunction occurred."

```{r south remove outliers}
outliers$South$index        = outliers$South$index       [c(1, 2, 3, 8, 9)]
outliers$South$replacements = outliers$South$replacements[c(1, 2, 3, 8, 9)]
```


```{r south outliers replacement}
# replace outliers
area.df$South = replace_outliers(
  df=area.df$South,
  ts=area.ts.daily$South,
  outliers=outliers$South
)
```

### Outliers replacement

Once the suggested outliers from the procedure are replaced, let's replot the final time series on which future analyses will be conducted.

```{r area daily weekly conversion new}
area.ts.daily<- lapply(
  area.df, 
  daily_df_to_daily_ts
)
area.ts.weekly <- lapply(
  area.df, 
  daily_df_to_weekly_ts
)
```


```{r area daily ts grid new, fig.width=6, fig.height=8}
plot_ts_grid(
  ts_list=area.ts.daily,
  n_row=3,
  names=names.area,
  colors=area.colors,
  main="Daily red light camera violations in Chicago areas after outlier removal",
  ylab=names.ylab$daily
)
```

```{r area weekly ts grid new, fig.width=6, fig.height=8}
plot_ts_grid(
  ts_list=area.ts.weekly,
  n_row=3,
  names=names.area,
  colors=area.colors,
  main="Avg daily red light camera violations per week in Chicago regions",
  ylab=names.ylab$weekly
)
```

# 2. Trend and Seasonality patterns in Chicago Areas

As we have already inferred from a simple visualization, the time series in question exhibit a **strong seasonal component** that seems to cause an increase in the average number of violations during the summer seasons.

This section aims to address this phenomenon in a more technical manner by employing **smoothing** and **filtering techniques** capable of highlighting or either removing this type of component. The seasonality could mask another type of pattern, such as a trend. Finally, it is important to quantify how these **components contribute to the final observation**.

## Smoothing and Low-pass filtering

First, let's use various filtering techniques, linear transformations of the time series that highlight certain properties.

### Simple moving average filter

First, let's start with a basic filter: the simple moving average, which calculates the **arithmetic average** over a time window $p$.

$$
\hat{f}_t = \frac{1}{2p + 1} \sum_{i=-p}^p y_{t+i}
$$

We test different values of $p$. The value plays a significant role in determining the effect of smoothing by considering a larger time window. The larger the time window, the less the filter will be affected by high frequency components.

```{r simple ma daily, fig.width=9, fig.height=9}
# Using different values of p
p        <- c(         45,            90,          180)
p.colors <- c('lawngreen', 'deepskyblue', 'chocolate1')

par(mfrow = c(length(area.ts.daily), 1))

for (area_name in names.area) {
  
  daily <- area.ts.daily[[area_name]]
  
  plot_simple_ma_varying_p(
    ts=daily,
    p=p,
    p.color=p.colors,
    main=paste(area_name, "- Simple Moving Average filter"),
    ylab="Daily violations"
  )
  
}
par(mfrow=c(1,1))
```

The effect of p has a significant impact on the transformation.

* `p = 45`, which considers a time window of about three months and is capable of smoothing out many of the oscillations resulting, for example, from daily variability.
* `p=90`, which considers a time window of half a year, has a similar trend to the previous one but is less sensitive to the minimal observations of winter lows and the maximal observations of summer peaks.
* `p=180`, which considers a window of about a year, does not seem to be strongly influenced by seasonal variability. The transformation allows observing a certain type of pattern over the years: the most evident is the one that tends to grow after 2020 in the *South* area, but also in the other two areas, a structure can be discerned.

Let's repeat the same type of analysis for the weekly version, moving towards a smoother visualization of the same scenario. Similarly, here `p = 6`, `p = 13`, and `p = 26` consider time windows of about 3 months, 6 months, and a year.

```{r simple ma weekly, fig.width=9, fig.height=9}
# Using different values of p
p        <- c(          6,            13,            26)
p.colors <- c('lawngreen', 'deepskyblue', 'chocolate1')

par(mfrow = c(length(area.ts.daily), 1))

for (area_name in names.area) {
  
  weekly <- area.ts.weekly[[area_name]]
  
  plot_simple_ma_varying_p(
    ts=weekly,
    p=p,
    p.color=p.colors,
    main=paste(area_name, "- Simple Moving Average filter"),
    ylab="Avg weekly violations pday"
  )
  
}
par(mfrow=c(1,1))
```

The results are very similar to the previous version, although this new one perhaps offers a more appreciable version of the annual smoothing in the North and Center areas, where there is a noticeable increase in 2017 followed by a decline that extended until the pandemic years. Afterward, there is a return to an upward phase after 2021.

### Deseasoning filter

We can apply a **low-pass filter** that highlights low-frequency patterns such as the trend. We use a filter that averages among two consecutive time windows of a period $p$.

$$
\hat{f}_t = \frac{0.5\ y_{t-p} + y_{t-p+1}+ \ldots + y_0 + \ldots + y_{t+p-1} + 0.5\ y_{t+p}}{p}
$$


Let's first consider the periods of:

* a week (`p = 7`);
* a month (`p = 30`);
* a quarter (`p = 90`);

```{r daily weekly monthly quarterly deseasoning, fig.width=9, fig.height=9}
par(mfrow = c(length(area.ts.daily), 1))

for(area_name in names.area) {
  
  daily <- area.ts.daily[[area_name]]
  
  plot_deseasoning_varying_freq(
    ts=daily,
    main=paste(area_name, "- Deseasoning of daily observations"),
    freq = c(7, 30, 90),
    freq.names = c("Weekly", "Monthly", "Quarterly"),
    freq.color = c("firebrick", "cyan3", "orange2"),
    ylab=names.ylab$daily,
    lwd=2
  )
  
}

par(mfrow=c(1,1))
```

In general, none of the three variants seems to be able to eliminate a certain seasonal pattern; the transformations remain closely aligned with the original curve.

So let's try with the period that seems to be the most relevant, namely the annual one. We use both versions with `p = 365` for daily observations and `p = 52` for monthly ones.


```{r daily yearly deseasoning, fig.width=9, fig.height=9}
par(mfrow = c(length(area.ts.daily), 1))

for(area_name in names.area) {
  
  daily <- area.ts.daily[[area_name]]
  
  plot(
    daily,
    main=paste(area_name, "- Yearly deseasoning of daily observations"),
    ylab="Daily violations",
    col="dimgray"
  )
  
  deseasonal.trend = deseasoning(
    ts=daily, 
    as.integer(freq$daily)
  )
  
  lines(
    deseasonal.trend,
    lty='dashed', lwd=3,
    col='cyan2'
  )
  
}

par(mfrow=c(1,1))
```


#### Yearly deseasoning of daily observations

Finally, an analogous situation occurs when considering yearly deseasoning of weekly observations

```{r weekly yearly deseasoning, fig.width=9, fig.height=9}
par(mfrow = c(length(area.ts.weekly), 1))

for(area_name in names.area) {
  
  weekly <- area.ts.weekly[[area_name]]
  
  plot(
    weekly,
    main=paste(area_name, "- Weekly Deseasoning"),
    ylab="Weekly violations",
    col="dimgray"
  )
  
  deseasonal.trend = deseasoning(
    ts=weekly, 
    freq=freq$weekly
  )
  
  lines(
    deseasonal.trend,
    lty='dashed', lwd=3,
    col='steelblue1'
  )
  
}

par(mfrow=c(1,1))
```

The results highlight a strong *annual seasonality**, showing patterns similar to those already identified: an alternating phase of decrease and increase for the *North* and *Center* areas, and a sharp increase in violations for the *South* starting from 2021.

### Monthplot

The previous results highlight two important components contributing to the observations. To better quantify the magnitude of their impact, a first tool can be the **monthplot**, a graphical that allows visualizing and comparing these two components by showing 12 different time series, one for each month.

```{r monthplot, fig.width=9, fig.height=9}
par(mfrow = c(length(area.df), 1))

for (area_name in names.area) {
  
  monthly <- daily_df_to_monthly_ts(df=area.df[[area_name]])
  
  monthplot(
    monthly,
    main=paste(area_name, " - Monthplot"),
    ylab="Monthly violations"
  )
  
}
  
par(mfrow=c(1,1))
```


The graph confirms what was expected: the observations exhibit a strong monthly seasonality, generally showing an increase in the summer months and a decrease in the winter month; however, it also reveals a certain systematic trend regardless of the month: the two effects seem more or less balanced in terms of their contribution to the final observation. Moving specifically to each Area:

* the ***North*** area highlights the previously described alternating trend, with a significant peak in 2017 followed by a decline that reached a very low point in the pandemic years, especially in April and May when the strictest quarantines were in place. The subsequent resurgence of violations in the following years tends to reach the same levels as in 2017 in the winter months, surpassing them in the summer months.

* the ***Central*** area generally shows similar trends to the North, but it is important to note the absence of the hump shape present in the pandemic years, which is here only present in the months from March to November.

* the South area shows, after a slight oscillation, a general increase in observations from 2021 onward, with a trend that has started to decrease in the very recent period. The increase is significantly steeper in the summer months.

## STL Decomposition

The previous results encourage a decomposition of the time series into three components: Trend, Seasonality, and Error. To achieve this, we use the STL technique (Seasonal and Trend Decomposition using Loess). We compute the decompositions for the three areas using the weekly version which we know to be smoother and easier to interpret.

### STL Decomposition

First, we will focus on the proportion in terms of contribution of the three components. In a second part, we will describe the structure of each component, comparing it with the other areas.

#### North
```{r stl north decomposition, fig.width=6, fig.height=5}
plot_stl_decomposition(
  ts=area.ts.weekly$North,
  main=paste("North - Weekly STL Decomposition")
)
```

In the *North* area, the trend seems to contribute with a magnitude of about 150 observations, while seasonality with 200; the erratic component is quite substantial, contributing almost as much as the trend to the final observation."

#### Center

```{r stl center decomposition, fig.width=6, fig.height=5}
plot_stl_decomposition(
  ts=area.ts.weekly$Center,
  main=paste("Center - Weekly STL Decomposition")
)
```

For the Central area, both the trend and seasonality seem to contribute equally with an amount of 250 observations, while the erratic component is contained in a range of about 100.

#### South
```{r stl south decomposition, fig.width=6, fig.height=5}
plot_stl_decomposition(
  ts=area.ts.weekly$South,
  main=paste("South - Weekly STL Decomposition")
)
```

In the South, the trend covers about 250 observations, while both seasonality and error contribute to about 200 of the observations.

In general, the contribution among the three components is mostly balanced. This is not very desirable when the error is also involved, as we aim to make it the smaller as possible. However, it confirms that between trend and seasonality, there isn't a clear component that prevails over the other. Both somehow have a balanced contribution to the final number of violations.

### STL - Component comparision



To better inspect the differences between the three areas, let's compare the three components with particular attention to the trend.

#### Trend

```{r stl trend decomposition, fig.width=8, fig.height=6}
plot_stl_components(
  ts_list = area.ts.daily,
  names=names.area,
  component_name="trend", 
  main=paste("Trend comparison of Chicago areas"), 
  ylab="Daily violations"
)
```

Here some main point:

* All three areas highlight a peak of observations in *2017*, which is less pronounced in the South.
* Between *2018* and *2020*, there is a decline in the North and Center, reaching a significant drop in the North, while during these years the trend in the South remains unchanged. 
* For all three areas, *2021* shows a rapid growth in violations, reaching the levels of *2017* for the North and Center and reaching new previously unrecorded levels in the South.

#### Seasonality

```{r stl decomposition season, fig.width=8, fig.height=6}
plot_stl_components(
  ts_list = area.ts.daily,
  names=names.area,
  component_name="seasonal", 
  main=paste("Seasonal decomposition comparison of Chicago areas"), 
  ylab="Daily violations"
)
```

The seasonal effect is nearly identical and indicates a general condition of the city. The only slight difference that might be noticed is that the summer peaks in the *South* tends to focus more in a shorter period.

#### Erratic component

```{r stl decomposition errors, fig.width=8, fig.height=6}
plot_stl_components(
  ts_list = area.ts.daily,
  names=names.area,
  component_name="remainder", 
  main=paste("Error decomposition comparison of Chicago areas"), 
  ylab="Daily violations"
)
```

The erratic component is not entirely satisfactory, as it is possible to identify a pattern with clusters of observations with positive and negative sign, that is generally undesirable for the residuals of a model. This behavior was hinted to be present in the trend or in the seasonality but perhaps not fully captured.

## Conclusion

TODO

# 3. Analyzing weekly seasonality

The analysis in the previous chapter highlights a strong component linked to the month but also hint at possible fluctuations within a single month. These fluctuations may be related, for example, to varying conditions concerning the day of the week. This chapter aims to analyze the importance of the weekly component within the observations.

## Correlation of daily observations

First, we use various tools to understand if there is evidence in the data of weekly dependencies.

### Analyzing ACF and PACF

We inspect the autocorrelation function of daily observations $Y_t$. More precisely we are interested in the **spikes at lags multiple of $7$**, that indicates the linear correlation between the number of violations in the same weekday.

```{r daily acf pacf, fig.width=6, fig.height=6}
for(area_name in names.area) {
    
  daily <- area.ts.daily[[area_name]]

  tsdisplay(
    daily,
    main=paste(area_name, "- Daily plot"),
    ylab=expression(Y[t])
  )
  
}
```

The ACF shows an sinusoidal trend (with the exception that the values do not tend to become negative in the first cycle for the South). The correlation tends to decrease in absolute value but then returns to be higher in lags that are multiples of an annual frequency. However, it is possible to identify a series of higher spikes throughout the sequence; let's try using a smaller number of lags to better understand if this factor can prove useful in the weekly day dependency.

```{r daily acf pacf 2, fig.width=6, fig.height=6}
for(area_name in names.area) {
    
  daily <- area.ts.daily[[area_name]]

  tsdisplay(
    daily,
    lag.max=50,
    main=paste(area_name, "- Daily plot"),
    ylab=expression(Y[t])
  )
  
}
```

As can be seen, although the correlation is still very high, the multiples of 7 lags, i.e., those referring to the same day of the week, tend to always have a higher correlation. This may be a sign of a recurring pattern on that day of the week.

### Weekly seasonality

Exploiting this insight into the weekly day dependency, let's plot an analogue of the monthplot: the **weeklyplot**, a collection of 7 different time series, each corresponding to a different day of the week.

```{r weeklyplot, fig.width=12, fig.height=3}
for(area_name in names.area) {
    
  df <- area.df[[area_name]]
  
  weeklyplot(
    df=df,
    main=paste(area_name, "- Weekly plot")
  )
}
```

In general, the trend is consistent regardless of the weekday, and it's very similar to what was already described in the previous section. However, the weekly trend shows how the average number of violations tends to be higher on Fridays, reaching its peak on Saturdays, decreasing almost to Friday's levels on Sundays, and then returning to a slightly lower level for the rest of the week. However, this type of pattern has a significantly reduced impact compared to a much clearer trend.

### Analyzing ACF and PACF of 7-lagged version

In light of what has been analyzed, let's try to remove the weekly factor through differencing. We inspect the correlation of the $7$-lagged version of the observations considering $\widetilde{Y}_t = Y_t - Y_{t-7}$.

```{r daily 7 lag acf pacf, fig.width=6, fig.height=6}
for(area_name in names.area) {
    
  daily      <- area.ts.daily[[area_name]]
  daily_lag7 <- diff(daily, 7)

  tsdisplay(
    daily_lag7,
    lag.max=60,
    main=paste(area_name, "- 7 lagged Daily plot"),
    ylab=expression(tilde(Y[t]))
  )
  
}
```

We can conclude that although there is evidence of a certain type of dependency related to the weekday, this has a reduced effect in the data compared to more influential periodic components such as the annual one.

## Weekday and Weekend split

There is evidence in the data of an increase in observations during the weekend. Let's create two separate time series for weekdays and weekends to investigate if they are 

```{r weekday weekend split}
area.ts.weeklydays <- lapply(
  area.df, 
  daily_df_to_weekly_ts_weekday_weekend
)
```

### Violations comparison

Let's plot the two in the same plot to investigate the plots.

```{r weekday weekend plot, fig.width=9, fig.height=9}
par(mfrow = c(length(area.ts.weeklydays), 1))

for(area_name in names.area) {
    
  weeklydays <- area.ts.weeklydays[[area_name]]

  plot_multiple_ts(
    ts_list = weeklydays,
    names   = names(area.ts.weeklydays$Center),
    colors  = list(weekday='steelblue1', weekend='tomato1'),
    main    = paste(area_name, "- Violations in Weekdays and Weekends"),
    ylab    = "Average daily violations"
  )

}

par(mfrow=c(1,1))
```

For any area the number of violations per day is higher during the weekend compared to weekdays, with gap between the two that tends to amplify during the summer months. They are both subject to the most seasonal effect with more pronounced peaks in the summer seasons for the weekend.

### Weekend and Weekday CCF

This fact can be visualized in a more formal manner by looking at the cross-correlation plot.

```{r weekday weekend ccf, fig.width=9, fig.height=8}
par(mfrow = c(length(area.ts.weeklydays), 1))

for(area_name in names.area) {
    
  weeklydays <- area.ts.weeklydays[[area_name]]
  
  ccf(
    x=as.numeric(weeklydays$weekday),
    y=as.numeric(weeklydays$weekend),
    lag.max = 50,
    main=paste(area_name, "- Weekdays and Weekend Cross Correlogram"),
    ylab="CCF"
  )
} 

par(mfrow = c(1, 1))
```

The graph highlights what was expected, namely the strong linear dependence between weekdays and weekends.

### Linear regression fit

The previous results highlight a strong linearity between weekdays and weekends, suggesting that a simple linear regression model may be sufficient to achieve a good level of prediction between them.

```{r weekday weekend linear regression, fig.width6, fig.height=4}
for(area_name in names.area) {
  
  weekday <- as.numeric(area.ts.weeklydays[[area_name]]$weekday)
  weekend <- as.numeric(area.ts.weeklydays[[area_name]]$weekend)
  
  # Fitting linear regression
  fit <- lm(weekend ~ weekday)
  print(area_name)
  print(summary(fit))
  
  plot(
    x=weekday,
    y=weekend,
    pch=16, col="steelblue",
    main=paste(area_name, " - Weekdays VS Weekend violations"),
    xlab="Weekly violations on weekdays",
    ylab="Weekly violations on weekdays",
  )
  abline(fit,  col = "orange2", lwd = 2, lty="dashed")
  grid()
  
}
```

The result evidence the dependency between weekdays and weekends, which we can conclude to be linear. In particular, for the *South* area, it has a multiple R-squared that exceeds 0.9. This type of visualization also provides another view of the number of violations for the *South* area, which we know has undergone a mean increase in recent years, highlighted by the different density of two point clouds in the graph.

## Conclusions

TODO



---
# 4. Forecasting

One of the tasks certainly more interesting is the time series forecasting: that is, using statistical techniques that leverage a historical dataset to make predictions about the number of future observations. This chapter will focus on predictions using ARIMA models, employing both daily and weekly forecasts. Since a good predictive mechanism requires a varied analysis and experimentation, this chapter will only focus on making predictions for the Central area. The other two will be considered again in the next chapter, investigating predictive capabilities with reference to the central area.

The process requires training a model and evaluating it, for this reason, we adhere to the typical paradigm of splitting our dataset into training, for model fitting, and test to measure generalization capabilities on unseen data. In this case, we use observations from the first seven years as training and observations from the last year, i.e., 2022, as the test set.


```{r train test split}
test_split_date <- as.Date("2022-01-01")

area.ts.daily.split  <- lapply(
  area.ts.daily,
  function(ts) {
    split_ts(ts=ts, date_split=test_split_date, train_test = TRUE)
  }
)
fit.daily <- list()

area.ts.weekly.split  <- lapply(
  area.ts.weekly,
  function(ts) {
    split_ts(ts=ts, date_split=test_split_date, train_test = TRUE)
  }
)
fit.weekly <- list()
```

## Daily forecasting

Let's begin daily prediction. First of all we visualize the split between training and testing.

```{r daily train test split, fig.height=5, fig.width=7}
plot_multiple_ts(
  ts_list=area.ts.daily.split$Center,
  names=names(area.ts.daily.split$Center),
  colors=list(train="steelblue", test="orange2"),
  main="North, daily - Train test split",
  ylab=names.ylab$Daily,
)
```

### Fitting models

Let's start considering possible transformations of the original time series and, if appropriate, fit some models.

#### Original one

First of all, let's visualize the original time series.

```{r daily tsdisplay1, fig.width=8, fig.height=6}
tsdisplay(
  area.ts.daily.split$Center$train,
  main = "Center - Original time series",
  ylab = names.ylab$Daily
)
```

We know the time series has a trend, although not super evident; the ACF shows a sinusoidal pattern that does not tend to decay uniformly, while the PACF is null after a certain lag. Let's try fitting a model that has both autoregressive and moving average components, for example, ARMA(4, 2).

```{r daily fit1}
fit.daily$Center <- list()
fit.daily$Center$fit1 <- Arima(
  area.ts.daily.split$Center$train, 
  order=c(4, 0, 2)
)
summary(fit.daily$Center$fit1)
```

The fitted model:

$$(1 - 1.8380B + 1.4247B^2 - 0.2017B^3 - 0.3120B^4) Y_t = 557.6361 + (1 + 1.2473B - 0.9912B^2) Z_t$$
with 

$$Z_t \sim WN(0, 4087) $$

#### Firt order differencing

We apply first order differencing attempting to make the process stationary.

```{r daily tsdisplay2, fig.width=8, fig.height=6}
tsdisplay(
  diff(area.ts.daily.split$Center$train, 1),
  main = "Center - First order differencing",
  ylab = paste(names.ylab$Daily, "- Diff(1)"),
  lag.max = 70
)
```

The process is now definitely more in line with the requirements of stationarity. Both ACF and PACF exhibit a sinusoidal pattern that tends to fade in the later lags of PACF. Let's try fitting a model, for example, ARIMA(3, 1, 2).

```{r daily fit2}
fit.daily$Center$fit2 <- Arima(
  area.ts.daily.split$Center$train, 
  order=c(3, 1, 2)
)
summary(fit.daily$Center$fit2)
```

The fitted model:

$$(1 - 0.797 B + 0.415 B^2 + 0.2983 B^3) (1 - B) Y_t = (1 - 1.2433 B + 0.599 B^2) Z_t$$
with 

$$Z_t \sim WN(0, 4211) $$

#### Yearly order differencing

We can try removing the seasonal effect by differencing for the period, that is 365 days.

```{r daily tsdisplay3, fig.width=8, fig.height=6}
tsdisplay(
  diff(area.ts.daily.split$Center$train, as.integer(freq$daily)),
  main = "Center - Daily order differencing",
  ylab = paste(names.ylab$Daily, "- Diff(", as.integer(freq$daily), ")", sep=""),
  lag.max = 70
)
```

However, applying differencing to remove possible periodic factors may be impractical and risky in this case, as we are not considering months or weeks where a certain type of nature is expected over a relatively large time period. The difference between days in two different years is highly variable, for example, due to weather or the day of the week, and it is really uninformative and difficult to exploit."


#### Autofit

Finally, let's leverage an automatic fit with parameters generated automatically by the software, using AICc as the criterion for the best fit selection.

```{r daily autofit}
# fit.daily$center$auto <- auto.arima(
#   area.ts.daily.split$center$train,
#   trace=true,
#   ic="aicc"
# )
fit.daily$Center$auto <- arima(
  area.ts.daily.split$Center$train,
  order=c(5, 1, 1)
)

summary(fit.daily$Center$auto)
```

The fitted model is an *ARIMA(5, 1, 1)*:

$$(1 - 0.0475B - 0.2813B^2 - 0.3331B^3 - 0.2949B^4 - 0.2383B^5)(1 - B)Y_t = (1 - 0.4414B)Z_t $$
with 

$$Z_t \sim WN(0, 4108) $$

### Best fit selection

We compare the three fitted models and choose the best one in terms of AICc.

```{r daily best fit}
fit.daily$Center$best <- arima_fit_selection(
  fit_list = fit.daily$Center,
  criteria = 'AICc'
)
```

The best fitted model is the one resulted by the automatic paramter selection. Let's inspect the behaviour of it's residuals.

```{r daily best fit diagnostic, fig.width=8, fig.height=6}
tsdiag(fit.daily$Center$best, main="Daily fit - Residuals")
```

The residuals are not satisfactory, as the Ljung-Box test suggests some autocorrelation, and they do not exhibit characteristics consistent with white noise.

### Forecasting

Let's use the best model to make forecasts for the following time windows:

* last year;
* last six months;
* last three months;
* last month.


```{r daily forecasts, fig.width=12, fig.height=10}
par(mfrow=c(2, 2))

split_dates <- list(
  as.Date("2022-01-01"),
  as.Date("2022-06-01"),
  as.Date("2022-09-01"),
  as.Date("2022-12-01")
)

errors <- list()

errors$daily <- model_multiple_evaluation(
  ts=area.ts.daily$Center,
  model=fit.daily$Center$best,
  split_dates=split_dates,
  main="Prediction until",
  ylab=names.ylab$Daily
)

par(mfrow=c(1, 1))
```

The model provides a prediction, albeit highly variable, only for a very short time window, and then predicts a mean value with a variability that becomes extremely large. The expected errors are very high.

```{r daily forecasts errors}
print(errors$daily)
```

This result is not surprising, as time series models are generally more reliable for short-term forecasts and tend to have limited accuracy over longer horizons.

### One-step-ahead Forecasting

We employ a second type of variation: we perform one-step-ahead forecasting for each instance in the test set, meaning a single daily prediction using the information available up to the day before.

```{r daily one step ahead forecasts, fig.height=6, fig.width=8}
osa_prediction <- list()
osa_prediction$daily <- model_one_step_ahead_evaluation(
  ts=area.ts.daily$Center,
  model=fit.daily$Center$best,
  date_start=as.Date("2022-01-01"), # first Monday
  date_end=as.Date("2022-12-31"),
  freq_type="daily",
  main="aa",
  ylab="bb"
)
```

The prediction manages to follow the general trend of the data. However, having access to the entire information up to the day before, the accuracy is not optimal, and the variability is also quite high, confirming the low quality of the model. This type of evaluation allows us to determine for which days the model makes the best and worst predictions.

Let's for example investigate the error made in terms of RMSE.

```{r daily one step ahead forecasts errors, fig.height=6, fig.width=8}
errors_analysis(
  pred_ts = osa_prediction$daily,
  error_type = "RMSE",
  k=6,
  h=3,
  freq_type = "daily",
  start_date=as.Date("2022-01-03"),
  main="AA",
  ylab="BB"
)
```

The chart is not very interpretable since it alternates between highs and lows throughout the year. The only noteworthy information is that three of the dates with the highest errors occur around the New Year when a period brings unpredictability that is challenging for the model to capture.

In conclusion, daily modeling is ineffective and poorly reliable. However, perhaps predicting the individual daily value is not truly the focus. It might be more interesting and useful to predict an average weekly trend, which is what we aim to do in the next chapter.

## Weekly forecasting

Let's move to weekly prediction. We start by visualizing the split between training and testing.

```{r weekly train test split, fig.height=6, fig.width=8}
plot_multiple_ts(
  ts_list=area.ts.weekly.split$Center,
  names=names(area.ts.weekly.split$Center),
  colors=list(train="steelblue", test="orange2"),
  main="North, weekly - Train test split",
  ylab=names.ylab$weekly,
)
```

### Fitting models

As we have previously done with the daily forecasting, we inspect different trasformation of the time series to devise different fitting models.

#### Original one

We start with the original time series.

```{r weekly tsdisplay1, fig.width=8, fig.height=6}
tsdisplay(
  area.ts.weekly.split$Center$train,
  main = "Center - Original time series",
  ylab = names.ylab$Weekly
)
```

Even though we cannot fully rely on normality assumptions, the ACF shows a sinusoidal trend that is decreasing, and the PACF does not have significant spikes after the fifth lag. Based on this, we fit an AR(5) model.

```{r weekly fit1}
fit.weekly <- list()
fit.weekly$Center <- list()
fit.weekly$Center$fit_orig <- Arima(
  area.ts.weekly.split$Center$train, 
  order=c(5, 0, 0)
)
summary(fit.weekly$Center$fit_orig)
```

The fitted model:

$$ (1 - 0.7171 B - 0.1853 B^2 - 0.0829 B^3 - 0.1205 B^4 + 0.1645 B^5)Y_t = 549.6611 + Z_t$$
with 

$$ Z_t \sim WN(0, 1812) $$

#### First order differencing

To better adhere to the assumption of stationarity, we model the time series with first-order differencing.

```{r weekly tsdisplay2, fig.width=8, fig.height=6}
tsdisplay(
  diff(area.ts.weekly.split$Center$train, 1),
  main = "Center - First order differencing",
  ylab = paste(names.ylab$Weekly, "- Diff(1)"),
  lag.max = 70
)
```

However no clear structure can be evinced by ACF and PACF. The process mainly resemble white noise.

#### Yearly order differencing

Let's try to remove the seasonal effect by taking $52$-order differencing, that is the weekly frequency in a year.

```{r weekly tsdisplay3, fig.width=8, fig.height=6}
tsdisplay(
  diff(area.ts.weekly.split$Center$train, freq$weekly),
  main = "Center - Weekly order differencing",
  ylab = paste(names.ylab$Weekly, "- Diff(", freq$weekly, ")", sep=""),
  lag.max = 70
)
```

The process is clearly non stationary so we cannot make any conclusion on the ACF and PACF to fit models.

#### Yearly and first order differencing

We apply first order differencing to $52$-order one, attempting for stationarity.


```{r weekly tsdisplay4, fig.width=8, fig.height=6}
tsdisplay(
  diff(diff(area.ts.weekly.split$Center$train, freq$weekly), 1),
  main = "Center - Weekly order differencing plus fist order differencing",
  ylab = paste(names.ylab$Weekly, "- Diff(", freq$weekly, ", 1)", sep=""),
  lag.max = 70
)
```

ACF and PACF have really few significative spikes. We model this process as a SARIMA(0, 1, 1)(0, 1, 1)[52].

```{r weekly fit2}
fit.weekly$Center$seasonal <- Arima(
  area.ts.weekly.split$Center$train, 
  order=c(0, 1, 1),
  seasonal=list(order=c(0, 1, 1), period=freq$weekly)
)
summary(fit.weekly$Center$seasonal)
```

The fitted model:

$$(1 - B)(1 - B^{52}) Y_t = (1 + 0.4435B)(1 + 0.9976B^{52})Z_t$$

with

$$Z_t \sim WN(0, 1504)$$

#### Autofit

Finally we employ automatic model selection, using AICc as criteria.


```{r weekly autofit}
# fit.weekly$Center$auto <- auto.arima(
#   area.ts.weekly.split$Center$train,
#   trace=TRUE,
#   ic="aicc"
# )
fit.weekly$Center$auto <- Arima(
  area.ts.weekly.split$Center$train,
  order=c(1, 1, 0),
  seasonal=list(order=c(1, 1, 0), period=freq$weekly)
)

summary(fit.weekly$Center$auto)
```

The fitted model is an *SARIMA(1, 1, 0)(1, 1, 0)[52]*:

$$(1 + 0.3405 B)(1 + 0.5437 B^{52})(1-B)(1-B^{52}) Y_t = Z_t$$
with 

$$ Z_t \sim WN(0, 2340) $$

### Best fit selection

We select the best among the three fitted models in terms of AICc.

```{r weekly best fit}
fit.weekly$Center$best <- arima_fit_selection(
  fit_list = fit.weekly$Center,
  criteria = 'AICc'
)
```

The best select one is the *SARIMA(0,1,1)(0,1,1)[52]* we devised from the yearly and first order differencing analysis. Let's investigate it's behavior in terms of residuals.

```{r weekly best fit diagnostic, fig.width=8, fig.height=6}
tsdiag(fit.weekly$Center$best)
```

The residuals passes the Ljiung-Box test and so behave as white noise. Our model can be validated.

### Forecasting

We employ the model on the four different forecasting horizons as the daily predictions.

```{r weekly forecasts, fig.width=12, fig.height=10}
par(mfrow=c(2, 2))

errors$weekly <- model_multiple_evaluation(
  ts=area.ts.weekly$Center,
  model=fit.weekly$Center$best,
  split_dates=split_dates,
  main="Prediction until",
  ylab=names.ylab$Weekly
)

par(mfrow=c(1, 1))
```

The prediction interval in quite wide and tends to shorten when the prediction horizon is reduced. The one-month and three-month point predictions are of high quality, while there is an underestimation for the last six months and an overestimation for the last month. This observation is also reflected in the errors made.

```{r weekly forecasts errors}
print(errors$weekly)
```

### One-step-ahead forecasting

We are reiterating the analysis of a one-step forecasting, where we use information available up to the previous week to make predictions for the next one.

```{r weekly one step ahead forecasts, fig.height=6, fig.width=8}
osa_prediction$weekly <- model_one_step_ahead_evaluation(
  ts=area.ts.weekly$Center,
  model=fit.weekly$Center$best,
  date_start=as.Date("2022-01-03"), # first monday
  date_end=as.Date("2022-12-31"),
  freq_type="weekly",
  main="aa",
  ylab="bb"
)
```

The prediction appears to adequately follow the actual trend with moderately contained variability. Let's further analyze which weeks have experienced high errors.

```{r weekly one step ahead forecasts errors, fig.height=6, fig.width=8}
errors_analysis(
  pred_ts = osa_prediction$weekly,
  error_type = "RMSE",
  k=5,
  h=5,
  freq_type = "weekly",
  start_date=as.Date("2022-01-03"),
  main="AA",
  ylab="BB"
)
```

The weeks in April and July stand out as having lower errors, suggesting potentially better predictive capabilities for the model during these periods. Conversely, the model performs poorly especially on the last two weeks of May;  can suspect that an unexpected event may have occurred, leading to increased traffic during that time. Similarly to what happened with daily predictions even year the last week ok the year, typically a vocation one, is difficult to predict.

## Conclusion

Should be interesting to inspect 2, 3 forecasting

---
# 5. Dependencies between areas

In this final section, our objective is to explore the possibility of a correlation between different regions and whether such a correlation could improve the predictive capabilities of forecasting models. The idea is to examine whether there are patterns or relationships among regions that, when considered in the forecasting process, could lead to more accurate predictions.

## Analyze influence

As an initial step, we can employ statistical tools to analyze potential relationships that interconnect the regions. These will help us in quantifying and understand the strength and nature of the relationships between different areas

### Cross correlation

We start with the analysis of the cross-correlation between the Center area (the region of interest for prediction) and the other two regions.

We plot the cross correlation between the Center and the North.

```{r north ccf, fig.height=6, fig.width=8}
ccf(
  y=as.numeric(area.ts.weekly$Center), 
  x=as.numeric(area.ts.weekly$North),
  lag.max = 100
)
```

We plot the cross correlation between the Center and the South.

```{r south ccf, fig.height=6, fig.width=8}
ccf(
  x=as.numeric(area.ts.weekly$Center),
  y=as.numeric(area.ts.weekly$South), 
  lag.max = 100
)
```

The two cross-correlograms reveal a robust linear dependence between the two time series, persisting even at considerable time lags. The observed pattern is sinusoidal, indicating a negative correlation occurring roughly every six months. The substantial linear relationship is in general expected since the all observations are probably affected by a scenario common to the entire city (such as weather conditions or specific holiday days).

While the cross-correlogram with the North is symmetric, indicating a symmetric dependence between the two regions, the same cannot be said for the cross-correlogram with the South. Particularly, when looking at the negative portions of the sinusoid, it reveals a dependence of the South on the North that is less pronounced than the reciprocal one.

### Linear regression

Given the insights obtained, it is reasonable to explore the predictive capabilities of the North and South areas on the Center area through the lens of linear regression. In this regard, we proceed to fit several models employing these two regions as predictive factors. 

#### North

Let's start by using the North area as the sole predictor.

```{r north lr, fig.height=6, fig.width=8}
plot(
  x=as.numeric(area.ts.weekly$North),
  y=as.numeric(area.ts.weekly$Center),
  pch=19, col="steelblue"
)
grid()

lm.fit <- list()

lm.fit$North <- lm(area.ts.weekly$Center ~ area.ts.weekly$North)
summary(lm.fit$North)
abline(lm.fit$North,  col = "orangered", lwd = 3, lty="dashed")
```


The scatterplot indicates that the relationship is well-suited for linear regression, explaining approximately 82% of the variability. Let's examine the residuals in terms of autocorrelation.

```{r north lr resid, fig.height=6, fig.width=8}
checkresiduals(lm.fit$North)
```

The ACF does not resemble that of white noise, which is expected. The linear fitting was not explicitly optimized to achieve this purpose. Instead, it was designed to produce residuals with zero mean and a normal distribution.

#### South

Let's start by using the South area as the sole predictor.

```{r south lr, fig.height=6, fig.width=8}
plot(
  x=as.numeric(area.ts.weekly$South),
  y=as.numeric(area.ts.weekly$Center),
  pch=19, col="steelblue"
)
grid()

lm.fit$South <- lm(area.ts.weekly$Center ~ area.ts.weekly$South)
summary(lm.fit$South)
abline(lm.fit$South,  col = "orangered", lwd = 3, lty="dashed")
```

n the case of the South, the relationship is not as straightforwardly linear. The linearity appears to diminish as the number of observations increases. However, the model can still explain 65% of the variability, which is a respectable result. Now, let's examine the residuals.

```{r south lr resid, fig.height=6, fig.width=8}
checkresiduals(lm.fit$South)
```

Similar to what occurred with the North, the residuals appear to have a zero mean and follow a normal distribution. However, the ACF deviates significantly from the white noise pattern one would expect, again because linear regression is not explicitly optimized to produce white noise residuals.

#### North and South

Let's now combine the information from both predictors.

```{r north south lr, fig.height=6, fig.width=8}
lm.fit$NorthSouth <- lm(area.ts.weekly$Center ~ area.ts.weekly$North + area.ts.weekly$South)
summary(lm.fit$NorthSouth)
```

When used together both predictors are significant and lead to an increase in explained variability up to 87%. The result suggests that both predictors can contribute to explaining the number of violations in the center by providing two diverse pieces of information.

```{r north south lr resid, fig.height=6, fig.width=8}
checkresiduals(lm.fit$NorthSouth)
```


The considerations about the residuals are almost the same as those conducted in the models using a single area as a predictor.

## Dynamic regression

In this last part we employ a different model for forecasting the number of violations in the Center area. This alternative approach involves employing a dynamic regression technique, which include in the model a set of regressors that in our context to the violations in the other two areas.

### Fitting

As we did with linear regression, we fitted various models by altering the types of regressors. This also allows us to make comparisons with the model fitted in the previous chapter.

#### North

We start using the violations in the North area as regressor.

```{r north dm fit}
dr.fit <- list()

dr.fit$North <- auto.arima(
  area.ts.weekly.split$Center$train,
  xreg=area.ts.weekly.split$North$train
)
summary(dr.fit$North)
```

The fitted model is a regression with *ARIMA(0,1,2)(0,0,1)[52]* errors:

$$Y_t = 0.9545 X_t + \eta_t \\ (1-B)\eta_t = (1 - 0.4374B - 0.0776 B^2)(1 - 0.0869B^{52})\epsilon_t $$

#### South

We replicate the same operation using South area as regressor
```{r south dm fit}
dr.fit$South <- auto.arima(
  area.ts.weekly.split$Center$train,
  xreg=area.ts.weekly.split$South$train
)
summary(dr.fit$South)
```

The fitted model is a regression with *ARIMA(0,1,2)(0,0,2)[52]* errors:

$$ Y_t = 0.9141 X_t + \eta_t \\ (1-B)\eta_t = (1 - 0.3704 B - 0.1108 B^2)(1 + 0.1015 B^{52} + 0.0656 B^{104})\epsilon_t $$

#### North and South

Finally we employ both North and South as regressors.

```{r south dm fit}
dr.fit$NorthSouth <- auto.arima(
  area.ts.weekly.split$Center$train,
  xreg=cbind(North=area.ts.weekly.split$North$train, 
             South=area.ts.weekly.split$South$train)
)
summary(dr.fit$NorthSouth)
```

The fitted model is a regression with *ARIMA(2, 3, 1)* errors, which differently from previous ones hasn't a seasonal part:

$$
Y_t = 0.7411 X_{North_t} + 0.4080 X_{South_t} + \eta_t \\ (1+1.2167 B + 0.6068 B^2)(1-B)\eta_t = (1 + 0.8165 B - 0.0332 B^2 - 0.4636 B^3)\epsilon_t
$$


### Model comparison

We evaluate the models from two main perspectives. First, we examine their forecasts and compare their Information Criteria (IC). Second, we assess their performance based on the errors observed in the test set. These two viewpoints provide a comprehensive understanding of how well the models capture the dynamics and variability of the data.

### Confidence Interval and Information Criteria

We proceed to compare these three dynamic regression models alongside the deterministic model resulting from the previous analyses. We visualize their forecasting performance over the entire test set and compare their Information Criteria (IC). This comprehensive evaluation allows us to gauge how well each model captures the underlying patterns and variability in the data.

```{r model comparison ic, fig.width=8, fig.height=10}
models <- list(
  North = list(
    fit=dr.fit$North, 
    xreg=area.ts.weekly.split$North$test, 
    main="North regressor", 
    col="orangered2"
  ),
  South = list(
    fit=dr.fit$South,
    xreg=area.ts.weekly.split$South$test,
    main="South regressor",
    col="green2"
  ),
  NorthSouth = list(
    fit=dr.fit$NorthSout,
    xreg=cbind(North=area.ts.weekly.split$North$test,
               South=area.ts.weekly.split$South$test),
    main="North-South regressor",
    col="pink2"
  ),
  Deterministic = list(
    fit=fit.weekly$Center$best,
    h=length(area.ts.weekly.split$South$test),
    main="Deterministic",
    col="deepskyblue2"
  )
)

model_comparison_ic(
  models=models,
  ylab=names.ylab$weekly
)
```

In general, the three models are comparable both in terms of point predictions and prediction intervals. However, the deterministic model exhibits a smoother line with fewer oscillations compared to the other dynamic regression models. These oscillations in the dynamic regression models are attributed to the regressors, which, being test data, introduce  themselves slight fluctuations in the predictions.

The information criteria (IC) of the three regression models align with the observations made during the linear regression analysis. The North appears to explain the observations in the Center better than the South in isolation. However, a combined use of both predictors can still contribute to some improvement. Nevertheless, the deterministic model, which also uses fewer parameters compared to the other regression models, remains the best model in terms of IC.

### Prediction error

Moving on, let's assess the performance of the models in terms of forecasting errors on the test set. It's worth noting that the regression models have an advantage in this regard because they use the current recorded values as inputs, whereas in a real-world scenario, their own predictions would need to be used. In this case, they can provide information about potential fluctuations that would be challenging to capture in a real-world study.

```{r model comparison err 1, fig.width=8, fig.height=6, include=FALSE}
model_comparison_prediction(
  models=models,
  train=area.ts.weekly.split$Center$train,
  test=area.ts.weekly.split$Center$test,
  main="AA",
  ylab="bb"
)
```

We zoom in on the prediction horizon to gain a better understanding.

```{r model comparison err 2, fig.width=8, fig.height=6}
model_comparison_prediction(
  models=models,
  train=area.ts.weekly.split$Center$train,
  test=area.ts.weekly.split$Center$test,
  main="AA",
  ylab="bb",
  lwd = 2,
  plot_train = FALSE
)
```

The predictions from the South area are, as expected, the least precise, while the most accurate predictions come from the North and NorthSouth areas, with the latter not seeming to significantly benefit from the second regressor. However, the deterministic model achieves a good level of accuracy compared to these, even though it doesn't have the opportunity to utilize current and future estimated information, as is the case in this evaluation with the regressors. Looking at the graph, it's evident that these models can capture fluctuations that would be challenging to predict.

## Conclusion
