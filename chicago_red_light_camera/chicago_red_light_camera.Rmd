---
title: "Chicago - Red Light Camera Violations"
author: "Sebastiano Quintavalle"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    theme: united
---

```{r output setup, include=FALSE}
knitr::opts_chunk$set(include=FALSE)
knitr::opts_chunk$set(echo=TRUE)
knitr::opts_chunk$set(fig.align='center')
```

```{r environment setup, echo=FALSE}
rm(list=ls())
Sys.setlocale("LC_TIME", "en_US.UTF-8")
```

```{r packages, include=FALSE}
library(forecast)
```

```{r source files}
source("./src/arima_utils.R")
source("./src/globals.R")
source("./src/plotting.R")
source("./src/smoothing.R")
source("./src/time.R")
```

# 1. Red Light Camera violations

## The case of study

aaaa


## The dataset

Describe the dataset and how it was preprocessed

```{r reading file}
# Reading the file
violations.region.df <- read.csv(file=violation_file)

# Casting Regions as factors
violations.region.df$Region = as.factor(violations.region.df$Region)

# Converting Date column to DateType
violations.region.df$Date <- as.Date(
  x      = as.character(violations.region.df$Date),
  format = "%m/%d/%Y"
)
```

Inspect the first few lines

```{r df head}
head(violations.region.df, 15)
```

Moreover, we are take a look to **basics statistics**.
```{r df summary}
summary(violations.region.df)
```

For each region we have a total of $2922$ observations, which cover a **time window of 8 years**, from *January 1, 2015*, to *December 31, 2022* (please note *2016* and *2020* are leap years).

Evidence of some nans
```{r df nan}
violations.region.df[is.na(violations.region.df$Violations),]
```

## Region

There are a total of **nine different regions**:

```{r region levels}
levels(violations.region.df$Region)
```

the map:

```{r chicago regions}
knitr::include_graphics("./out/chicago_sides.png")
```

Creating a list of dataset for each different region

```{r region split}
region.df <- split(
  violations.region.df,
  violations.region.df$Region
)
```

### Daily observations

Convert to daily ts

```{r region daily conversion}
region.ts.daily <- lapply(
  region.df, 
  daily_df_to_daily_ts
)
```

Plot daily ts

```{r region daily ts grid, fig.width=10, fig.height=12}
plot_ts_grid(
  ts_list = region.ts.daily,
  n_row   = 5,
  names   = unlist(names.regions),
  colors  = region.colors,
  main    = "Daily red light camera violations in Chicago regions",
  ylab    = "Daily violations"
)
```

Different degreees of magnitutes, let's plot together the data

```{r region daily ts, fig.width=10, fig.height=10}
plot_multiple_ts(
  ts_list = region.ts.daily,
  colors  = region.colors,
  names   = unlist(names.regions),
  main    = "Daily red light camera violations in Chicago regions",
  ylab    = names.ylab$daily
)
```

### Outliers

Confusing. In general we can see different critical observation

```{r outlier1}
above_threshold(
  ts = region.ts.daily$West,
  threshold = 700
)
```

BLM

```{r blm protest,  fig.cap="Protesters destroy police vehicles , on May 30, 2020 during a protest against the death of George Floyd (Photo by Jim Vondruska)", out.width = "400px", echo=FALSE, include=TRUE}
#https://www.nbcchicago.com/news/local/20-stunning-photos-show-how-protests-unrest-unfolded-in-chicago/2281065/
knitr::include_graphics("https://media.nbcchicago.com/2019/09/GettyImages-1216502225.jpg?quality=85&strip=all&fit=8660%2C5773&w=775&h=436&crop=0")
```

```{r outlier2}
above_threshold(
  ts=region.ts.daily$West,
  threshold = 110,
  upper=FALSE
) 
```

Anomaly + storm

```{r outlier3}
above_threshold(
  ts=region.ts.daily$FarSouthEast,
  threshold=300
)
```

DonÃ¬t know

https://www.weather.gov/lot/2015_Feb01_Snow


### Weekly observations

work at weekly level+ 53 week

```{r region weekly conversion}
region.ts.weekly <- lapply(
  region.df,
  daily_df_to_weekly_ts
)
```


```{r region weekly ts grid, fig.width=10, fig.height=12}
plot_ts_grid(
  ts_list=region.ts.weekly,
  n_row=5,
  names=unlist(names.regions),
  colors=region.colors,
  main="Avg daily red light camera violations per week in Chicago regions",
  ylab="Avg daily violations per week"
)
```

One point as a summary of seven, smoother reduce variablity over a month. Since can be measliding let's try to plot them together

```{r region weekly ts, fig.width=10, fig.height=10}
plot_multiple_ts(
  ts_list=region.ts.weekly,
  colors=region.colors,
  names=unlist(names.regions),
  main="Avg daily red light camera violations per week in Chicago regions",
  ylab=names.ylab$weekly,
  lwd=2
)
```

better but stilll confusing

## Aggregating by areas

The dataset encompasses observations for **nine distinct regions** within Chicago. To streamline the analysis, which could become cumbersome when examining each of the nine regions individually, a **subsequent aggregation** is conducted, categorizing the city into **three primary areas**:

* ***North***: FarNorth, NorthWest, North.
* ***Center***: Central, West, SouthWest, South.
* ***South***: FarSouthWest, FarSouthEast.

Motivate why but in the end it make sense :)

The NAN had no intervention so risk, but as we saw the date is problematic so the problem it's posponed but it will probably end up in a rescheduling. south missing observations.

```{r chicago sides,  fig.cap="Chicago sides", out.width = "700px"}
knitr::include_graphics("./out/chicago_sides_and_areas.png")
```

```{r area definition}
# Assigning each Region to the specific Area
violations.region.df$Area <- 
  ifelse(violations.region.df$Region %in% names.regions$North,  'North',
  ifelse(violations.region.df$Region %in% names.regions$Center, 'Center',
  ifelse(violations.region.df$Region %in% names.regions$South,  'South',  NA)))

# Casting to factors
violations.region.df$Area = as.factor(violations.region.df$Area)

# Aggregating violations by areas
violations.area.df = aggregate(
  Violations ~ Area + Date,
  data=violations.region.df,
  sum
)
```

Again we inspect the first few lines of the dataset and we take a look to the principal statistics.

```{r areas head}
head(violations.area.df)
```


```{r areas statistics}
summary(violations.area.df)
```

one missing, add 0

```{r areas add missing info}

# Add missing observation
violations.area.df <- rbind(
  violations.area.df, 
  data.frame(
    Area=as.factor("South"),
    Date=as.Date("2021-12-07"),
    Violations=0
  )
)

# Sort the dataset by the date column
violations.area.df <- violations.area.df[order(violations.area.df$Date), ]
```


We utilize the labels associated to each region and area to **partition the dataset into a list** of datasets, with each one linked to a specific region or area.

```{r dataframe area split}
# List of areas
area.df <- split(
  violations.area.df,
  violations.area.df$Area
)
names(area.df)
```

### Daily observations

We employ custom functions to transform the dataset into **daily**, **weekly** and **monthly formats**. The monthly format involves aggregating the total number of violations within each month, revealing essential insights for seasonality analysis.

same reasoning as before at an higher level

```{r area daily conversion}
area.ts.daily <- lapply(
  area.df, 
  daily_df_to_daily_ts
)
```

```{r area daily ts grid, fig.width=10, fig.height=12}
plot_ts_grid(
  ts_list=area.ts.daily,
  n_row=3,
  names=names.area,
  colors=area.colors,
  main="Daily red light camera violations in Chicago areas",
  ylab=names.ylab$daily
)
```

same

```{r area daily ts, fig.width=10, fig.height=10}
plot_multiple_ts(
  ts_list=area.ts.daily,
  names=names.area,
  colors=area.colors,
  main="Daily red light camera violations in Chicago areas",
  ylab=names.ylab$daily
)
```

comment

### Weekly observations

With weekly

```{r area weekly conversion}
area.ts.weekly <- lapply(
  area.df, 
  daily_df_to_weekly_ts
)
```

```{r area weekly ts grid, fig.width=10, fig.height=12}
plot_ts_grid(
  ts_list=area.ts.weekly,
  n_row=3,
  names=names.area,
  colors=area.colors,
  main="Avg daily red light camera violations per week in Chicago regions",
  ylab=names.ylab$weekly
)
```

all in one

```{r area weekly ts, fig.width=10, fig.height=10}
plot_multiple_ts(
  ts_list=area.ts.weekly,
  names=names.area,
  colors=area.colors,
  main="Avg daily red light camera violations per week in Chicago regions",
  ylab=names.ylab$weekly,
  lwd=2
)
```

discuss the approximation form the region, more on the center but in general good

The observations recorded in the Center are generally more numerous than those in the North and especially the South. In general, the three regions seem to reflect a shared condition of the city, particularly highlighting a significant factor related to seasonality over the course of a year.

## Replacing anomaly dates

use outliers diagnostic based on stl decomposition

#### North
```{r north outliers, fig.height=6, fig.width=4}
outliers <- list()

outliers$North <- outliers_diagnostic(
  ts=area.ts.daily$North,
  colors=list(plot=area.colors$North, 
              old='deeppink', 
              new='steelblue'),
  main=paste("North Outliers"),
  ylab="Daily violations"
)

```

```{r north outliers replacement}
area.df$North = replace_outliers(
  df=area.df$North,
  ts=area.ts.daily$North,
  outliers=outliers$North
)
```

#### Center
```{r center outliers, fig.height=6, fig.width=4}
outliers$Center <- outliers_diagnostic(
    ts=area.ts.daily$Center,
    colors=list(plot=area.colors$Center, 
                old='deeppink', 
                new='steelblue'),
    main=paste("Center Outliers"),
    ylab="Daily violations"
)
```


```{r center outliers replacement}
area.df$Center = replace_outliers(
  df=area.df$Center,
  ts=area.ts.daily$Center,
  outliers=outliers$Center
)
```

#### South
```{r south outliers, fig.height=6, fig.width=4}
outliers$South <- outliers_diagnostic(
  ts=area.ts.daily$South,
  colors=list(plot=area.colors$South, 
              old='deeppink', 
              new='orange'),
  main=paste("South Outliers"),
  ylab="Daily violations"
)
```

discuss + replace
```{r south outliers replacement}
# replace outliers
area.df$South = replace_outliers(
  df=area.df$South,
  ts=area.ts.daily$South,
  outliers=outliers$South
)
```

Recreate ts starting from dataset
```{r area daily weekly conversion new}
area.ts.daily<- lapply(
  area.df, 
  daily_df_to_daily_ts
)
area.ts.weekly <- lapply(
  area.df, 
  daily_df_to_weekly_ts
)
```

and we plot back

```{r area daily ts grid new, fig.width=10, fig.height=12}
plot_ts_grid(
  ts_list=area.ts.daily,
  n_row=3,
  names=names.area,
  colors=area.colors,
  main="Daily red light camera violations in Chicago areas after outlier removal",
  ylab=names.ylab$daily
)
```

```{r area weekly ts grid new, fig.width=10, fig.height=12}
plot_ts_grid(
  ts_list=area.ts.weekly,
  n_row=3,
  names=names.area,
  colors=area.colors,
  main="Avg daily red light camera violations per week in Chicago regions",
  ylab=names.ylab$weekly
)
```

---
# 2. Trend and Seasonality decomposition

## Smoothing and Low-pass filtering

The objective of this section is to utilize **filtering techniques** to analyze certain components of time series data. 

1. Initially, various **smoothing techniques** will be employed to eliminate noise and short-term fluctuations, **emphasizing more apparent patterns**.
2. Similarly, these smoothed components can be utilized as **low-pass filters**, highlighting the **trend** of the time series.
3. From these low-pass filters, **high-pass filters** can be eventually derived to accentuate high-frequency components, such as **seasonality**.

### Simple moving average filter

The filter computes an **arithmetic average** within a time window $p$.

$$
\hat{f}_t = \frac{1}{2p + 1} \sum_{i=-p}^p y_{t+i}
$$

The value of $p$ plays a significant role in determining the effect of smoothing by considering a larger time window. The larger the time window, the less the filter will be affected by high frequency components.

```{r simple ma daily, fig.width=8, fig.height=8}
# Using different values of p
p        <- c(         30,            90,          180)
p.colors <- c('lawngreen', 'deepskyblue', 'chocolate1')

par(mfrow = c(length(area.ts.daily), 1))

for (area_name in names.area) {
  
  daily <- area.ts.daily[[area_name]]
  
  plot_simple_ma_varying_p(
    ts=daily,
    p=p,
    p.color=p.colors,
    main=paste(area_name, "- Simple Moving Average filter"),
    ylab="Daily violations"
  )
  
}
par(mfrow=c(1,1))
```

```{r simple ma weekly, fig.width=8, fig.height=8}
# Using different values of p
p        <- c(          6,            13,            26)
p.colors <- c('lawngreen', 'deepskyblue', 'chocolate1')

par(mfrow = c(length(area.ts.daily), 1))

for (area_name in names.area) {
  
  weekly <- area.ts.weekly[[area_name]]
  
  plot_simple_ma_varying_p(
    ts=weekly,
    p=p,
    p.color=p.colors,
    main=paste(area_name, "- Simple Moving Average filter"),
    ylab="Avg weekly violations pday"
  )
  
}
par(mfrow=c(1,1))
```

As anticipated, higher values of $p$ emphasize a trend that is not influenced by a specific seasonal component. In particular, when $p=183$, it considers a time window of one year and is therefore capable of removing the annual seasonality.

Compared to the results obtained with the moving average, $p$ does not seem to have an effect in changing the type of trend obtained. In all three cases, it produces a smoothed version of the seasonal pattern of the series, eliminating many fluctuations. 

As $p$ increases, enlarging the window, the weight associated with central observations also increases, making it less effective in removing seasonal effects within a given window.

### Deseasoning filter

We can highlight trend by removing seasonality effect, this can be achieved with a filter that averages among two consecutive time windows of a period $p$.

$$
\hat{f}_t = \frac{0.5\ y_{t-p} + y_{t-p+1}+ \ldots + y_0 + \ldots + y_{t+p-1} + 0.5\ y_{t+p}}{p}
$$

Let's consider multiple cases.

#### Weekly deseasoning of daily observations 

The resulting trend reduces a more frequent level of fluctuations that could be attributed to weekly seasonality. However, there still remains a noticeable annual oscillation, likely attributed to monthly patterns.

```{r daily weekly deseasoning, fig.width=8, fig.height=8}
par(mfrow = c(length(area.ts.daily), 1))

for(area_name in names.area) {
  
  daily <- area.ts.daily[[area_name]]
  
  plot(
    daily,
    main=paste(area_name, "- Weekly deseasoning of daily observations"),
    ylab="Daily violations",
    col="dimgray"
  )
  
  deseasonal.trend = deseasoning(
    ts=daily, 
    freq=7
  )
  
  lines(
    deseasonal.trend,
    col='firebrick1', lwd=2
  )
  
}

par(mfrow=c(1,1))
```
  
#### Yearly deseasoning of daily observations

The trend is capable of almost completely eliminating seasonal effects related to the time of the year.

```{r daily yearly deseasoning, fig.width=8, fig.height=8}
par(mfrow = c(length(area.ts.daily), 1))

for(area_name in names.area) {
  
  daily <- area.ts.daily[[area_name]]
  
  plot(
    daily,
    main=paste(area_name, "- Yearly deseasoning of daily observations"),
    ylab="Daily violations",
    col="dimgray"
  )
  
  deseasonal.trend = deseasoning(
    ts=daily, 
    as.integer(freq$daily)
  )
  
  lines(
    deseasonal.trend,
    lty='dashed', lwd=3,
    col='steelblue1'
  )
  
}

par(mfrow=c(1,1))
```

#### Yearly deseasoning of daily observations

Finally, an analogous situation occurs when considering yearly deseasoning of weekly observations

```{r weekly yearly deseasoning, fig.width=8, fig.height=8}
par(mfrow = c(length(area.ts.weekly), 1))

for(area_name in names.area) {
  
  weekly <- area.ts.weekly[[area_name]]
  
  plot(
    weekly,
    main=paste(area_name, "- Weekly Deseasoning"),
    ylab="Weekly violations",
    col="dimgray"
  )
  
  deseasonal.trend = deseasoning(
    ts=weekly, 
    freq=freq$weekly
  )
  
  lines(
    deseasonal.trend,
    lty='dashed', lwd=3,
    col='steelblue1'
  )
  
}

par(mfrow=c(1,1))
```

### Monthplot

The previous results highlight the importance of a significant seasonal component tied to the month but also indicate the presence of a certain trend. The graphical tool **monthplot** allows visualizing and comparing these two components by showing 12 different time series for each month.

```{r monthplot, fig.width=8, fig.height=8}
par(mfrow = c(length(area.df), 1))

for (area_name in names.area) {
  
  monthly <- daily_df_to_monthly_ts(df=area.df[[area_name]])
  
  monthplot(
    monthly,
    main=paste(area_name, " - Monthplot"),
    ylab="Monthly violations"
  )
  
}
  
par(mfrow=c(1,1))
```

The graph confirms what was expected: the observations exhibit a strong monthly seasonality, generally showing an increase in the summer months and a decrease in the winter months. However, it also reveals a certain systematic trend regardless of the month. The two effects seem more or less balanced in terms of their contribution to the final observation.


### Moving Average Decomposition

To better analyze these properties, let's use the **Moving Average Decomposition** into trend, seasonality, and error.

```{r ma decomposition, fig.width=6, fig.height=5}
for(area_name in names.area) {
  
  daily <- area.ts.daily[[area_name]]
  
  plot_ma_decomposition(
    ts=daily,
    main=paste(area_name, "- Daily MA Decomposition")
  )
}
```

The decomposition highlights a trend that is generally similar for the three areas but with some distinct differences. The seasonality, on the other hand, is common across the entire city. More detailed results on the decomposition will be provided in the next paragraph.

## STL Decomposition

### STL Decomposition - Areas and Frequencies

A more powerful decomposition tool is STL (Seasonal and Trend decomposition using Loess), which relies on Loess smoothing to ensure more flexible seasonality and a robust trend. Let's analyze the decomposition for all three versions.

#### Daily
```{r stl north daily decomposition, fig.width=6, fig.height=5}
plot_stl_decomposition(
  ts=area.ts.daily$North,
  main=paste("North - Daily STL Decomposition")
)
```

```{r stl center daily decomposition, fig.width=6, fig.height=5}
plot_stl_decomposition(
  ts=area.ts.daily$Center,
  main=paste("Center - Daily STL Decomposition")
)
```

```{r stl south daily decomposition, fig.width=6, fig.height=5}
plot_stl_decomposition(
  ts=area.ts.daily$South,
  main=paste("South - Daily STL Decomposition")
)
```

#### Weekly
```{r stl north weekly decomposition, fig.width=6, fig.height=5}
plot_stl_decomposition(
  ts=area.ts.weekly$North,
  main=paste("North - Weekly STL Decomposition")
)
```

```{r stl center weekly decomposition, fig.width=6, fig.height=5}
plot_stl_decomposition(
  ts=area.ts.weekly$Center,
  main=paste("Center - Weekly STL Decomposition")
)
```

```{r stl south weekly decomposition, fig.width=6, fig.height=5}
plot_stl_decomposition(
  ts=area.ts.weekly$South,
  main=paste("South - Weekly STL Decomposition")
)
```

### STL - Component comparision

To better inspect the differences between the three areas, let's compare the three components with particular attention to the trend.

#### Trend

```{r stl trend decomposition, fig.width=8, fig.height=6}
plot_stl_components(
  ts_list = area.ts.daily,
  names=names.area,
  component_name="trend", 
  main=paste("Trend comparison of Chicago areas"), 
  ylab="Daily violations"
)
```


The three trends show a peak in *2017* followed by a significant decline, remaining relatively low until the pandemic years. They then experience a rapid growth in *2022*. Some important details to highlight:

* The northern area experiences a further decline in *2020*, leading to a decrease in violations never recorded before. It generally tends to rebound with a slight delay compared to the other two regions.
* While for the north and center, the growth in *2022* is comparable to the levels of the previous 5 years, the southern area surpasses that level significantly.

#### Seasonality

```{r stl decomposition season, fig.width=8, fig.height=6}
plot_stl_components(
  ts_list = area.ts.daily,
  names=names.area,
  component_name="seasonal", 
  main=paste("Seasonal decomposition comparison of Chicago areas"), 
  ylab="Daily violations"
)
```

The seasonal effect is nearly identical and indicates a general condition of the city. The only slight difference that might be noticed is that the summer peaks in the south generally last for a shorter duration.

#### Erratic component

```{r stl decomposition errors, fig.width=8, fig.height=6}
plot_stl_components(
  ts_list = area.ts.daily,
  names=names.area,
  component_name="remainder", 
  main=paste("Error decomposition comparison of Chicago areas"), 
  ylab="Daily violations"
)
```

The erratic component is not entirely satisfactory, as it is possible to identify a pattern that is generally undesirable for the residuals of a model. In particular, errors often tend to be positive before *2018* and after *2021*, and negative in the intervening period, highlighting a different behavior that was hinted at in the trend but perhaps not fully captured.

---
# 3. Analyzing weekly seasonality

The analysis in the previous chapter highlights a strong component linked to the month but also hint at possible fluctuations within a single month. These fluctuations may be related, for example, to varying conditions concerning the day of the week. This chapter aims to analyze the importance of the weekly component within the observations.

## Correlation of daily observations

aaa

### Analyzing ACF and PACF

For first we inspect the autocorrelation function of daily observations $Y_t$. We are interested in the linear correlations at lags multiple of 7.

```{r daily acf pacf, fig.width=8, fig.height=6}
for(area_name in names.area) {
    
  daily <- area.ts.daily[[area_name]]

  tsdisplay(
    daily,
    lag.max=100,
    main=paste(area_name, "- Daily plot"),
    ylab=expression(Y[t])
  )
  
}
```

The ACF shows an exponential decreasing trend, the PACF a sinusoidal decreasing one. The ACF always highlights higher spikes at lag multiple of $7$, that is indicative for the importance of the weekday component. We can not reason in terms of AR and MA interpretation because as we saw the process has a trend and it's not stationary, thus we'll probably need to apply differencing.

### Weekly seasonality

Let's plot an analogous representation of the monthplot for the weekdays, comparing the 7 different time series, each corresponding to a different day of the week.

```{r weeklyplot, fig.width=12, fig.height=3}
for(area_name in names.area) {
    
  df <- area.df[[area_name]]
  
  weeklyplot(
    df=df,
    main=paste(area_name, "- Weekly plot")
  )
}
```

Although there is evidence of an average increase on weekdays, especially on Saturdays, the seasonality does not appear to be significant when compared to the trend, which remains consistent for each weekday.

### Analyzing ACF and PACF of 7-lagged version

Let's firstly inspect the correlation of a $7$-lagged version of the observations considering $\widetilde{Y}_t = Y_t - Y_{t-7}$.

```{r daily 7 lag acf pacf, fig.width=8, fig.height=6}
for(area_name in names.area) {
    
  daily      <- area.ts.daily[[area_name]]
  daily_lag7 <- diff(daily, 7)

  tsdisplay(
    daily_lag7,
    lag.max=60,
    main=paste(area_name, "- 7 lagged Daily plot"),
    ylab=expression(tilde(Y[t]))
  )
  
}
```

The plot still shows important spikes right at lags that are multiple of seven, meaning that the weekly dependence was not eliminated.


## Weekday and Weekend split

There is evidence in the data of an increase in observations during the weekend. Let's try to create two separate time series for weekdays and weekends.

```{r weekday weekend split}
area.ts.weeklydays <- lapply(
  area.df, 
  daily_df_to_weekly_ts_weekday_weekend
)
```

### Violations comparison

Let's plot the two in the same plot to investigate the plots.

```{r weekday weekend plot, fig.width=6, fig.height=5}
plot_multiple_ts(
  ts_list = area.ts.weeklydays$Center,
  names   = names(area.ts.weeklydays$Center),
  colors  = list(weekday='steelblue1', weekend='tomato1'),
  main    = paste("Center - Violations in Weekdays and Weekends"),
  ylab    = "Average daily violations"
)
```

In general, the number of violations per day is higher during the weekend compared to weekdays, the trend is almost the same and the difference between the two tends to amplify during the summer months.

### Weekend and Weekday CCF

This fact can be visualized in a more formal manner by looking at the cross-correlation plot, which highlights a clear linear dependence.

```{r weekday weekend ccf, fig.width=9, fig.height=8}
ccf(
  x=as.numeric(area.ts.weeklydays$Center$weekday),
  y=as.numeric(area.ts.weeklydays$Center$weekday),
  lag.max = 50,
  main=paste("Center - Weekdays and Weekend Cross Correlogram"),
  ylab="CCF"
)
```

### Linear regression fit

The linear relationship is so strong that the dependence between the two can be easily modeled by a linear regression.

```{r weekday weekend linear regression, fig.width=7, fig.height=7}

violations.weekday <- as.numeric(area.ts.weeklydays$Center$weekday)
violations.weekend <- as.numeric(area.ts.weeklydays$Center$weekend)
  
plot(
  x=area.ts.weeklydays$Center$weekday,
  y=area.ts.weeklydays$Center$weekend,
  pch=16, col="steelblue",
  main=paste("Center - Weekdays VS Weekend violations"),
  xlab="Weekly violations on weekdays",
  ylab="Weekly violations on weekdays",
)
grid()

fit <- lm(violations.weekend ~ violations.weekday)
abline(fit,  col = "orange2", lwd = 2, lty="dashed")
summary(fit)
```

---
# 4. ARIMA Decomposition

## Train test split

Train test split
```{r train test split}
test_split_date <- as.Date("2022-01-01")

area.ts.daily.split  <- lapply(
  area.ts.daily,
  function(ts) {
    split_ts(ts=ts, date_split=test_split_date, train_test = TRUE)
  }
)
fit.daily <- list()

area.ts.weekly.split  <- lapply(
  area.ts.weekly,
  function(ts) {
    split_ts(ts=ts, date_split=test_split_date, train_test = TRUE)
  }
)
fit.weekly <- list()
```

## Daily forecasting

```{r daily train test split, fig.height=6, fig.width=8}
plot_multiple_ts(
  ts_list=area.ts.daily.split$Center,
  names=names(area.ts.daily.split$Center),
  colors=list(train="steelblue", test="orange2"),
  main="North, daily - Train test split",
  ylab=names.ylab$Daily,
)
```

### Fitting models

#### Original one

```{r daily tsdisplay1, fig.width=8, fig.height=6}
tsdisplay(
  area.ts.daily.split$Center$train,
  main = "Center - Original time series",
  ylab = names.ylab$Daily
)
```

```{r daily fit1}
fit.daily$Center <- list()
fit.daily$Center$fit1 <- Arima(
  area.ts.daily.split$Center$train, 
  order=c(4, 0, 2)
)
summary(fit.daily$Center$fit1)
```

#### Firt order differencing
```{r daily tsdisplay2, fig.width=8, fig.height=6}
tsdisplay(
  diff(area.ts.daily.split$Center$train, 1),
  main = "Center - First order differencing",
  ylab = paste(names.ylab$Daily, "- Diff(1)"),
  lag.max = 70
)
```

```{r daily fit2}
fit.daily$Center$fit2 <- Arima(
  area.ts.daily.split$Center$train, 
  order=c(3, 1, 2)
)
summary(fit.daily$Center$fit2)
```

#### Yearly order differencing
```{r daily tsdisplay3, fig.width=8, fig.height=6}
tsdisplay(
  diff(area.ts.daily.split$Center$train, as.integer(freq$daily)),
  main = "Center - Daily order differencing",
  ylab = paste(names.ylab$Daily, "- Diff(", as.integer(freq$daily), ")", sep=""),
  lag.max = 70
)
```

#### Yearly order plus first order differencing
```{r daily tsdisplay4, fig.width=8, fig.height=6}
tsdisplay(
  diff(diff(area.ts.daily.split$Center$train, as.integer(freq$daily)), 1),
  main = "Center - Daily order differencing",
  ylab = paste(names.ylab$Daily, "- Diff(", as.integer(freq$daily), ", 1)", sep=""),
  lag.max = 70
)
```

#### Autofit
```{r daily autofit}
# fit.daily$Center$auto <- auto.arima(
#   area.ts.daily.split$Center$train,
#   trace=TRUE,
#   ic="aicc"
# )
fit.daily$Center$auto <- Arima(
  area.ts.daily.split$Center$train,
  order=c(5, 1, 1)
)

summary(fit.daily$Center$auto)
```

### Best fit selection

```{r daily best fit}
fit.daily$Center$best <- arima_fit_selection(
  fit_list = fit.daily$Center,
  criteria = 'AICc'
)
```

```{r daily best fit diagnostic, fig.width=8, fig.height=6}
tsdiag(fit.daily$Center$best)
```

### Forecasting

```{r daily forecasts, fig.width=12, fig.height=10}
par(mfrow=c(2, 2))

split_dates <- list(
  as.Date("2022-01-01"),
  as.Date("2022-06-01"),
  as.Date("2022-09-01"),
  as.Date("2022-12-01")
)

errors <- model_multiple_evaluation(
  ts=area.ts.daily$Center,
  model=fit.daily$Center$best,
  split_dates=split_dates,
  main="Prediction until",
  ylab=names.ylab$Daily
)

par(mfrow=c(1, 1))
```

```{r daily forecasts errors}
print(errors)
```

### One-step-ahead Forecasting

```{r daily one step ahead forecasts, fig.height=6, fig.width=8}
osa_prediction <- model_one_step_ahead_evaluation(
  ts=area.ts.daily$Center,
  model=fit.daily$Center$best,
  date_start=as.Date("2022-01-01"), # first Monday
  date_end=as.Date("2022-12-31"),
  freq_type="daily",
  main="aa",
  ylab="bb"
)
```


```{r daily one step ahead forecasts errors, fig.height=6, fig.width=8}
errors_analysis(
  pred_ts = osa_prediction,
  error_type = "RMSE",
  k=10,
  freq_type = "daily",
  start_date=as.Date("2022-01-03"),
  main="AA",
  ylab="BB"
)
```

## Weekly forecasting

```{r weekly train test split, fig.height=6, fig.width=8}
plot_multiple_ts(
  ts_list=area.ts.weekly.split$Center,
  names=names(area.ts.weekly.split$Center),
  colors=list(train="steelblue", test="orange2"),
  main="North, weekly - Train test split",
  ylab=names.ylab$Weekly,
)
```

### Fitting models

#### Original one

```{r weekly tsdisplay1, fig.width=8, fig.height=6}
tsdisplay(
  area.ts.weekly.split$Center$train,
  main = "Center - Original time series",
  ylab = names.ylab$Weekly
)
```

```{r weekly fit1}
fit.weekly <- list()
fit.weekly$Center <- list()
fit.weekly$Center$fit_orig <- Arima(
  area.ts.weekly.split$Center$train, 
  order=c(5, 0, 0)
)
summary(fit.weekly$Center$fit_orig)
```

#### First order differencing

```{r weekly tsdisplay2, fig.width=8, fig.height=6}
tsdisplay(
  diff(area.ts.weekly.split$Center$train, 1),
  main = "Center - First order differencing",
  ylab = paste(names.ylab$Weekly, "- Diff(1)"),
  lag.max = 70
)
```


#### Yearly order differencing

```{r weekly tsdisplay3, fig.width=8, fig.height=6}
tsdisplay(
  diff(area.ts.weekly.split$Center$train, freq$weekly),
  main = "Center - Weekly order differencing",
  ylab = paste(names.ylab$Weekly, "- Diff(", freq$weekly, ")", sep=""),
  lag.max = 70
)
```

#### Yearly and first order diffrencing
```{r weekly tsdisplay4, fig.width=8, fig.height=6}
tsdisplay(
  diff(diff(area.ts.weekly.split$Center$train, freq$weekly), 1),
  main = "Center - Weekly order differencing plus fist order differencing",
  ylab = paste(names.ylab$Weekly, "- Diff(", freq$weekly, ", 1)", sep=""),
  lag.max = 70
)
```

```{r weekly fit2}
fit.weekly$Center$seasonal <- Arima(
  area.ts.weekly.split$Center$train, 
  order=c(0, 1, 1),
  seasonal=list(order=c(0, 1, 1), period=freq$weekly)
)
summary(fit.weekly$Center$seasonal)
```

#### Autofit
```{r weekly autofit}
# fit.weekly$Center$auto <- auto.arima(
#   area.ts.weekly.split$Center$train,
#   trace=TRUE,
#   ic="aicc"
# )
fit.weekly$Center$auto <- Arima(
  area.ts.weekly.split$Center$train, 
  order=c(1, 1, 0),
  seasonal=list(order=c(1, 1, 0), period=freq$weekly)
)

summary(fit.weekly$Center$auto)
```

### Best fit selection

```{r weekly best fit}
fit.weekly$Center$best <- arima_fit_selection(
  fit_list = fit.weekly$Center,
  criteria = 'AICc'
)
```

```{r weekly best fit diagnostic, fig.width=8, fig.height=6}
tsdiag(fit.weekly$Center$best)
```

### Forecasting

```{r weekly forecasts, fig.width=12, fig.height=10}
par(mfrow=c(2, 2))

split_dates <- list(
  as.Date("2022-01-01"),
  as.Date("2022-06-01"),
  as.Date("2022-09-01"),
  as.Date("2022-12-01")
)

errors <- model_multiple_evaluation(
  ts=area.ts.weekly$Center,
  model=fit.weekly$Center$best,
  split_dates=split_dates,
  main="Prediction until",
  ylab=names.ylab$Weekly
)

par(mfrow=c(1, 1))
```

```{r weekly forecasts errors}
print(errors)
```

### One-step-ahead forecasting

```{r weekly one step ahead forecasts, fig.height=6, fig.width=8}
osa_prediction <- model_one_step_ahead_evaluation(
  ts=area.ts.weekly$Center,
  model=fit.weekly$Center$best,
  date_start=as.Date("2022-01-03"), # first monday
  date_end=as.Date("2022-12-31"),
  freq_type="weekly",
  main="aa",
  ylab="bb"
)
```

```{r weekly one step ahead forecasts errors, fig.height=6, fig.width=8}
errors_analysis(
  pred_ts = osa_prediction,
  error_type = "RMSE",
  k=5,
  freq_type = "weekly",
  start_date=as.Date("2022-01-03"),
  main="AA",
  ylab="BB"
)
```

---
# 5. Dependencies between areas

aa

## Analyze influence
bb
### Cross correlation
cc
#### North
aa

```{r north ccf, fig.height=6, fig.width=8}
ccf(
  y=as.numeric(area.ts.weekly$Center), 
  x=as.numeric(area.ts.weekly$North),
  lag.max = 100
)
```

#### South
aa

```{r south ccf, fig.height=6, fig.width=8}
ccf(
  x=as.numeric(area.ts.weekly$Center),
  y=as.numeric(area.ts.weekly$South), 
  lag.max = 100
)
```

### Linear regression

#### North
```{r north lr, fig.height=6, fig.width=8}
plot(
  x=as.numeric(area.ts.weekly$North),
  y=as.numeric(area.ts.weekly$Center),
  pch=19, col="steelblue"
)
grid()

lm1 <- lm(area.ts.weekly$Center ~ area.ts.weekly$North)
summary(lm1)
abline(lm1,  col = "orangered", lwd = 3, lty="dashed")
```


```{r north lr resid, fig.height=6, fig.width=8}
checkresiduals(lm1)
```

#### South

```{r south lr, fig.height=6, fig.width=8}
plot(
  x=as.numeric(area.ts.weekly$South),
  y=as.numeric(area.ts.weekly$Center),
  pch=19, col="steelblue"
)
grid()

lm2 <- lm(area.ts.weekly$Center ~ area.ts.weekly$South)
summary(lm1)
abline(lm2,  col = "orangered", lwd = 3, lty="dashed")
```

```{r south lr resid, fig.height=6, fig.width=8}
checkresiduals(lm2)
```

#### North and South
```{r north south lr, fig.height=6, fig.width=8}
lm3 <- lm(area.ts.weekly$Center ~ area.ts.weekly$North + area.ts.weekly$South)
summary(lm3)
```

```{r north south lr resid, fig.height=6, fig.width=8}
checkresiduals(lm2)
```

## Dynamic regression

### Fitting

#### North

```{r north dm fit}
fit1 <- auto.arima(
  area.ts.weekly.split$Center$train,
  xreg=area.ts.weekly.split$North$train
)
summary(fit1)
```

#### South
```{r south dm fit}
fit2 <- auto.arima(
  area.ts.weekly.split$Center$train,
  xreg=area.ts.weekly.split$South$train
)
summary(fit2)
```

### Model comparison

### Confidence Interval and Information Criteria

```{r model comparison ic, fig.width=8, fig.height=10}
models <- list(
  mod1 = list(fit=fit1, xreg=area.ts.weekly.split$North$test, main="AA", col="red"),
  mod2 = list(fit=fit2, xreg=area.ts.weekly.split$South$test, main="BB", col="green"),
  mod3 = list(fit=fit.weekly$Center$best, h=length(area.ts.weekly.split$South$test), main="CC", col="blue"
)
)

model_comparison_ic(
  models=models,
  ylab=names.ylab$Weekly
)

```

### Prediction error

```{r model comparison err 1, fig.width=8, fig.height=6, echo=FALSE}
model_comparison_prediction(
  models=models,
  train=area.ts.weekly.split$Center$train,
  test=area.ts.weekly.split$Center$test,
  main="AA",
  ylab="bb"
)
```


```{r model comparison err 2, fig.width=8, fig.height=6, echo=FALSE}
model_comparison_prediction(
  models=models,
  train=area.ts.weekly.split$Center$train,
  test=area.ts.weekly.split$Center$test,
  main="AA",
  ylab="bb",
  plot_train = FALSE
)
```







