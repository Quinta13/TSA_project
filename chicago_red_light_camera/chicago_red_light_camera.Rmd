---
title: "Chicago - Red Light Camera Violations"
author: "Sebastiano Quintavalle"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    theme: united
editor_options: 
  chunk_output_type: console
---

```{r output setup, include=FALSE}
knitr::opts_chunk$set(include=TRUE)
knitr::opts_chunk$set(echo=FALSE)
knitr::opts_chunk$set(fig.align='center')
```

```{r environment setup, include=FALSE}
rm(list=ls())
Sys.setlocale("LC_TIME", "en_US.UTF-8")
```

```{r packages, include=FALSE}
library(forecast)
```

```{r source files}
source("./src/arima_utils.R")
source("./src/globals.R")
source("./src/plotting.R")
source("./src/smoothing.R")
source("./src/time.R")
```

***
# 1. Introduction

## Red Light Camera violations

With the advent of the digital era, urban areas are increasingly adopting **automated detection systems** to gather **detailed data on city dynamics**. This approach aims to enhance the overall conditions of the city through the analysis of relevant information, with the primary goal of implementing innovative solutions that improve the city's efficiency based on automatically collected data.

Examples of this include cameras that regulate traffic flows, including **red light violation detectors**. Analyzing the trend of this factor over time is crucial for **road safety** and **urban planning policies**, as the violation is often a highly probable cause of accidents.

## Report outline

The report analyzes a specific case of this type of data, using the number of **red light violations** in the **city of Chicago** as a case study. The report is structured into 5 sections.

1. We start with an **overview of the dataset** under study, specifying the source, preprocessing steps, and performing some preliminary data cleaning operations. We divide the city of Chicago into **different zones** and create **time series** with both **daily and weekly frequencies**.

2. A first investigation involves **decomposing the time series into seasonality and trend**, using various filtering techniques. While it is common for the number of violations to be influenced by seasonal factors, they can also reveal a certain tendency the area is subject to and may be addressed through policies to reduce violations.

3. A second analysis explores the **potential different nature of violations between weekdays and weekends**. Considering that people usually have different lifestyles on these two periods in the week, mainly due to work-related reasons, it makes sense to investigate if this is reflected in the data and if separate modeling is warranted.

4. After delving into the mechanisms and components generating the observations, we develop **ARIMA models to forecast the future number of violations**, generating predictions for both **daily and weekly intervals**. We will compare and analyze the predictive capabilities of these two types of models and their effectiveness in a real-world scenario.

5. Finally, a second type of **forecasting model using dynamic regression** will be employed to investigate whether **combining information from different areas of the city can enhance prediction quality**. We will then compare this approach with the model validated in the previous section. 

## The dataset

### Resource reference
The dataset is available on the [Chicago Data Portal](https://data.cityofchicago.org), the official open-data website of the city of Chicago, Illinois, USA. It consists of a **daily camera survey on red traffic light violations** downloadable [here](https://data.cityofchicago.org/Transportation/Red-Light-Camera-Violations/spqx-js37/about_data). There are approximately 300 cameras scattered throughout the city, with their positions specified by **latitude** and **longitude**.

### Preprocessing
The dataset on which the analysis will be conducted it's not the raw downloadable version, but a **preprocessed version** elaborated in the [attached Jupyter Notebook](./data_preparation.ipynb). The main reason for preprocessing using a different technology is the extensive set of utilities that *Python* offers for geospatial analysis, particularly with tools like [GeoPandas](https://geopandas.org/en/stable/). The major preliminary operations include:

1. **Grouping by region**. Recognizing the impracticality of analyzing each camera observation individually, aggregation is a necessary step. To achieve this, geo-spatial data corresponding to the nine regions that comprise the city was downloaded (the [file](https://data.cityofchicago.org/Facilities-Geographic-Boundaries/Boundaries-Community-Areas-current-/cauq-8yn6) is always available on the Chicago Data Portal). Each camera was then assigned to the specific region within whose polygon it resides. For visual representation, a [Folium document](./out/camera_map.html) is provided to showcase the camera locations on the map.

2. **Time period**. After assigning each camera to a specific region, observations can be aggregated within a given region and on a specific day. It's crucial to note that cameras were not universally activated or deactivated simultaneously, which may impact the transparency of the observation count. To address this, only cameras active throughout the entire period from 01/01/2015 to 12/31/2022 were considered. This ensures a consistent dataset, minimizing potential biases arising from variations in the number of active cameras on specific dates.


### Overview

The dataset `violations.csv`is available at [this path](./out/violations.csv). Let's inspect the very first few lines.

```{r reading file}
# Reading the file
violations.region.df <- read.csv(file=violation_file)

# Casting Regions as factors
violations.region.df$Region = factor(violations.region.df$Region, levels=unlist(names.regions))

# Converting Date column to DateType
violations.region.df$Date <- as.Date(
  x      = as.character(violations.region.df$Date),
  format = "%m/%d/%Y"
)
```


```{r df head}
head(violations.region.df, 15)
```

The dataset consists of **daily observations for each region**, where each entry represents a triplet of Region-Date-Violation count. Now, let's proceed to analyze the basic statistics.

```{r df summary}
summary(violations.region.df)
```

For each region we have a total of 2922 observations, which cover a **time window of 8 years**, from January 1, 2015, to December 31, 2022 (note 2016 and 2020 are leap years). 

#### Violation and cameras

Statistics related to the number of violations are highly condensed as they aggregate data from multiple regions. Therefore, we prefer a more detailed visualization for each Region through a boxplot. 

```{r df violations boxplot, fig.width=7, fig.height=6}
boxplot(
  Violations ~ Region, data = violations.region.df, main = "Violations per Region",xlab = "",
        ylab = "Violations", col=unlist(region.colors), las=2)
```

The center of **mass of violations is contained** within all regions, except for the West, which has a more extended body and, in general, a more sparse pattern of observations. It is not possible to make direct comparisons on the number of observations since regions do not have equal surface areas or, especially, an equal number of cameras. However, it is interesting to note that there are **many more observations exceeding the tails** in terms of **peeks** as compared to **minum**. This condition is particularly pronounced in the South, while it is absent in the FarNorth.

As we anticipated, the comparison between regions is not fair in terms of observations because it is strictly linked to the **number of cameras**. Let's investigate their distribution.

```{r df violations cameras}
# Reading the file
camera.df <- read.csv(file = camera_file)
camera.df <- camera.df[match(unlist(names.regions), camera.df$Region),]

# Casting Regions as factors
camera.df$Region <- factor(camera.df$Region, levels = unlist(names.regions))

camera.df
```

```{r camera histogram, fig.width=6, fig.height=5}
barplot(
  camera.df$Camera,
  names.arg = camera.df$Region,
  col = unlist(region.colors),
  main = 'Number of cameras', 
  xlab = "",
  ylab = 'Cameras',
  las=2
)
grid()
```

The variability highlighted by the boxplot is easily explained by the number of cameras in each region: the region with the least variability, the Center, also has a relatively low number of cameras; while the high variability in the West is certainly indicative of a large number of cameras. It is also noticeable that, in general, there are more cameras in the Northern regions compared to those in the South.

Consequently, we can use this information to calculate the **average number of violations relative to the number of cameras**. This allows for metrics that facilitate comparisons between regions in terms of violations

```{r mean violation per camera histogram, fig.width=6, fig.height=5}
# Mean violations per region
camera.df <- merge(
  aggregate(Violations ~ Region, 
            data = violations.region.df, 
            FUN = mean),
  camera.df, 
  by = "Region")

# Sort rows
camera.df <- camera.df[match(unlist(names.regions), camera.df$Region),]

# Compute mean violation
camera.df$ViolationsPerCamera <- camera.df$Violations / camera.df$Camera

barplot(
  camera.df$ViolationsPerCamera,
  names.arg = camera.df$Region,
  col = unlist(region.colors),
  main = 'Avg Violation per Camera', 
  xlab = "", ylab = 'Avg Violations', las=2
)
grid()
```

The graph highlights a probable tendency to commit more violations in the two southern regions, South and FarSouthEast, and less in the FarNorth, and especially in the NorthWest.

#### Missing values

As indicated by the summary, there are **5 missing values**. Let's inspect them:

```{r df nan}
violations.region.df[is.na(violations.region.df$Violations),]
```

They all correspond to the same date: December 7, 2021. A quick internet search doesn't reveal any specific conditions related to this date. Its handling is deferred to further paragraphs.

#### Region in Chicago

As previously seen, the dataset divides the information across the **9 Regions of Chicago**. The following analyses will be conducted by **treating observations from each region separately**. The main goal is to investigate potential differences in terms of characteristic phenomena within each region, leading to different intervention strategies.

```{r region levels, include=FALSE}
levels(violations.region.df$Region)
```

```{r chicago regions, fig.cap="Chicago Regions", out.width = "370px"}
knitr::include_graphics("./out/chicago_sides.png")
```

```{r region split}
region.df <- split(
  violations.region.df,
  violations.region.df$Region
)
```


### Daily observations

```{r region daily conversion}
region.ts.daily <- lapply(
  region.df, 
  daily_df_to_daily_ts
)
```

Let's start by considering a **time series of daily violations** for each **Region**.

```{r region daily ts grid, fig.width=9, fig.height=10}
plot_ts_grid(
  ts_list = region.ts.daily,
  n_row   = 5,
  names   = unlist(names.regions),
  colors  = region.colors,
  ylab    = names.ylab$daily
)
```

We can start by making some initial observations.

* The time series already reveal, at first glance, a crucial **seasonal pattern**, with the number of violations tending to increase during the summer seasons.
* Additionally, some regions seem to have **specific years with notably higher violation counts**, such as 2017 for Central and Southwest or 2020 for the South.
 In general, the patterns of the three Northern regions (FarNorth, Northwest, and North) exhibit a high visual similarity, as do the three Southern regions (South, FarSouthWest, and FarSouthEast).

However, it is important to exercise caution when making direct comparisons between these graphs due to differing scales. Let's attempt to plot them on a single graph.

```{r region daily ts, fig.width=7, fig.height=6}
plot_multiple_ts(
  ts_list = region.ts.daily,
  colors  = region.colors,
  names   = unlist(names.regions),
  main    = "Red light violations in Chicago Regions",
  ylab    = names.ylab$daily
)
```

The result is not satisfactory; the large number of data points makes the graph challenging to interpret. Nevertheless, we can still visualize a significant seasonal pattern more clearly and observe that there are some **anomalous observations occurring on the same day across multiple regions**. Let's proceed to analyze them in the very next paragraph.

### Anomalous observations

#### Black Lives Matter protest

```{r outlier1, include=FALSE}
above_threshold(
  ts = region.ts.daily$West,
  threshold = 700
)
```

The most prominent one is a very high spike that occurs in most regions in the central and southern areas. The date May 30, 2020, corresponds to significant days of protests and unrest in the city following the **Black Lives Matter movement demonstration**, which protested the death of George Floyd. The confrontation led to a real urban battle, causing traffic jams and accidents along the city streets. Read more [here](https://en.wikipedia.org/wiki/George_Floyd_protests_in_Chicago).

<br>
```{r blm protest,  fig.cap="Protesters destroy police vehicles , on May 30, 2020 during a protest against the death of George Floyd (Photo by Jim Vondruska)", out.width = "470px", echo=FALSE, include=TRUE}
knitr::include_graphics("https://media.nbcchicago.com/2019/09/GettyImages-1216502225.jpg?quality=85&strip=all&fit=8660%2C5773&w=775&h=436&crop=0")
```
<br>

#### Potential system failure

In addition, there is a second negative peak on December 7, 2021 that is common to almost every region. We recall is the same day for which some readings are missing. Although, as mentioned earlier, it is difficult to find information on the web, it is possible to consider that there might have been a **general system malfunction**. Even where the data is available, it seems too low to be plausible.

```{r outlier2, include = FALSE}
above_threshold(
  ts=region.ts.daily$NorthWest,
  threshold=29,
  upper=FALSE
)
```

#### Snowstorms

The last interesting cases are a series of negative peaks that occur in some regions at more or less regular intervals over the years.


```{r outlier3, include=FALSE}
above_threshold(
  ts=region.ts.daily$West,
  threshold = 110,
  upper=FALSE
) 
```


The dates include a series of dates that occur between late January and early February (January 31, 2015; February 2, 2015; January 27, 2019; January 31, 2021; February 2, 2022). As suggested by some internet research, this is a **period that typically brings snowstorms to the city**, like this one [here](https://www.weather.gov/lot/2015_Feb01_Snow), partially blocking roads and during which it is generally not advisable to go out.

Since the data will undergo further forms of aggregation, the handling of these problematic observations is postponed to future sessions.

<br>
```{r snowsotorm,  fig.cap="Time to dig out from the Groundhog Day snowstorm, Feb. 2, 2022. (Patty Wetli / WTTW News)", out.width = "470px", echo=FALSE, include=TRUE}
knitr::include_graphics("https://news.wttw.com/sites/default/files/styles/full/public/field/image/SnowStreetBlurFeb2022Crop.jpg?itok=hKyHYeZT")
```
<br>

### Weekly observations

As we have seen, daily observations can be abundant and might somewhat complicate visual interpretation. For this reason, we also work with a **second version of time series that involves weekly average observations**. The **frequency** of this type of time series is **52 weeks**, so potential days at the beginning or end of the year are grouped with the adjacent week.

```{r region weekly conversion}
region.ts.weekly <- lapply(
  region.df,
  daily_df_to_weekly_ts
)
```


```{r region weekly ts grid, fig.width=9, fig.height=10}
plot_ts_grid(
  ts_list=region.ts.weekly,
  n_row=5,
  names=unlist(names.regions),
  colors=region.colors,
  ylab=names.ylab$weekly
)
```

A smaller number of points certainly makes the observations smoother to interpret. The previous observations appear clearer, especially the apparent similarity between the three northern Regions and the three southern ones.

Let's also visualize them all in a single plot.

```{r region weekly ts, fig.width=7, fig.height=6}
plot_multiple_ts(
  ts_list=region.ts.weekly,
  colors=region.colors,
  names=unlist(names.regions),
  main="Red light camera violations in Chicago regions",
  ylab=names.ylab$weekly,
  lwd=2
)
```

Even with a smoother version, we are not able to draw many conclusions, except to emphasize once again the evidence of a significant seasonal pattern. For this reason, in the next section, we suggest a **second step of aggregation by grouping the Regions into three Areas** based on geographical proximity and similar patterns found in analyses.

## Aggregating by areas

The dataset encompasses observations for **nine distinct regions** within Chicago. To streamline the analysis, which could become cumbersome when examining each of the nine regions individually, a **subsequent aggregation** is conducted, categorizing the city into **three primary areas**:

* ***North***: FarNorth, NorthWest, North.
* ***Center***: Central, West, SouthWest.
* ***South***: South, FarSouthWest, FarSouthEast.

```{r chicago sides,  fig.cap="Chicago Areas", out.width = "550px"}
knitr::include_graphics("./out/chicago_sides_and_areas.png")
```

```{r area definition}
# Assigning each Region to the specific Area
violations.region.df$Area <- 
  ifelse(violations.region.df$Region %in% names.regions$North,  'North',
  ifelse(violations.region.df$Region %in% names.regions$Center, 'Center',
  ifelse(violations.region.df$Region %in% names.regions$South,  'South',  NA)))

# Casting to factors
violations.region.df$Area = as.factor(violations.region.df$Area)

# Aggregating violations by areas
violations.area.df = aggregate(
  Violations ~ Area + Date,
  data=violations.region.df,
  sum
)
```


```{r areas add missing info}

# Add missing observation
violations.area.df <- rbind(
  violations.area.df, 
  data.frame(
    Area=as.factor("South"),
    Date=as.Date("2021-12-07"),
    Violations=0
  )
)

# Sort the dataset by the date column
violations.area.df <- violations.area.df[order(violations.area.df$Date), ]
```

```{r dataframe area split, include=FALSE}
# List of areas
area.df <- split(
  violations.area.df,
  violations.area.df$Area
)
names(area.df)
```

### Daily observations

As previously done, we present the **different views of daily and weekly observations** in the new aggregated version for Areas. We start from daily ones.

```{r area daily conversion}
area.ts.daily <- lapply(
  area.df, 
  daily_df_to_daily_ts
)
```

```{r area daily ts grid, fig.width=6, fig.height=7}
plot_ts_grid(
  ts_list=area.ts.daily,
  n_row=3,
  names=names.area,
  colors=area.colors,
  ylab=names.ylab$daily
)
```

This more condensed version partially **reaffirms some observations made at the region level**. In particular, both negative and positive outliers are more evident.

```{r area daily ts, fig.width=7, fig.height=5}
plot_multiple_ts(
  ts_list=area.ts.daily,
  names=names.area,
  colors=area.colors,
  main="Daily red light camera violations in Chicago areas",
  ylab=names.ylab$daily
)
```

The simultaneous visualization now finally provides some insights. It is particularly evident a clear trend for the South area, which has a steep increase towards 2021; the mean level of the other two region has a more soft fluctuation with slightly reduced number of violations in the central part of the time series, but the average number of violations appears to be more stable during the years.

### Weekly observations

In general, we expect to see similar and perhaps clearer results in the Weekly version.

```{r area weekly conversion}
area.ts.weekly <- lapply(
  area.df, 
  daily_df_to_weekly_ts
)
```


```{r area weekly ts grid, fig.width=6, fig.height=7}
plot_ts_grid(
  ts_list=area.ts.weekly,
  n_row=3,
  names=names.area,
  colors=area.colors,
  ylab=names.ylab$weekly
)
```

This visualization might still be able to highlight how there are even local peaks that are common to all three areas, thus indicating a condition that is shared across the entire city.

```{r area weekly ts, fig.width=7, fig.height=5}
plot_multiple_ts(
  ts_list=area.ts.weekly,
  names=names.area,
  colors=area.colors,
  main="Daily red light camera violations in Chicago regions",
  ylab=names.ylab$weekly,
  lwd=2
)
```

The combined graph even better highlights the upward trend in the South area. It also now capable of showing that the North and Center areas have a very similar overall curve, although they have typically comparable values in the winter, the Center reaches much higher peaks during the summers.

## Outliers detection and replacement

The following chapters will use this last aggregated representation by area as the subject of investigation. Before proceeding in detail with the analysis, it is therefore necessary to address the anticipated **issue of outliers**, i.e. observations that differ substantially from the vast majority of observations.

### Outliers detection

Outliers detection and replacement rely on the `tsoutliers()` function in the `forecast package`, which follows the step.

1. ***Identification*** - Outliers are identified by calculating an STL decomposition and then identifying outliers in the residual regime.

2. ***Replacement***, the replace value is estimated using linear interpolation of neighboring observations.

More details can be found [here](https://robjhyndman.com/hyndsight/tsoutliers/).

#### North

```{r north outliers, fig.height=4, fig.width=6}
outliers <- list()

outliers$North <- outliers_diagnostic(
  ts=area.ts.daily$North,
  colors=list(plot=area.colors$North, 
              old='deeppink', 
              new='steelblue'),
  main=paste("North Outliers"),
  ylab=names.ylab$daily
)
```

In the North area the only identified information pertains to December 7, 2021, which we have already analyzed as a day when a potential malfunction in the detection system may have occurred.

```{r north outliers replacement}
area.df$North = replace_outliers(
  df=area.df$North,
  ts=area.ts.daily$North,
  outliers=outliers$North
)
```

#### Center

```{r center outliers, fig.height=4, fig.width=6}
outliers$Center <- outliers_diagnostic(
    ts=area.ts.daily$Center,
    colors=list(plot=area.colors$Center, 
                old='deeppink', 
                new='steelblue'),
    main=paste("Center Outliers"),
    ylab=names.ylab$daily
)
```

Moving to the central area, we still find the date December 7, 2021, but also the date May 31, 2021, where we know there was an abnormal peek due to the protests in the city during the Black Lives Matter demonstration.

```{r center outliers replacement}
outliers$Center$index[1] <- outliers$Center$index[1]+1 # 365.25 format fix
area.df$Center = replace_outliers(
  df=area.df$Center,
  ts=area.ts.daily$Center,
  outliers=outliers$Center
)
```

#### South
```{r south outliers, fig.height=4, fig.width=6}
outliers$South <- outliers_diagnostic(
  ts=area.ts.daily$South,
  colors=list(plot=area.colors$South, 
              old='deeppink', 
              new='orange'),
  main=paste("South Outliers"),
  ylab=names.ylab$daily
)
```

Differently from the other two areas, for the South many outliers have been identified, and all in the second half of the time series when there was a significant increase in the average number of violations following the pandemic years. Some points may not be considered outliers in all respects and might be the result of some limitations in the procedure; therefore, we only retain modifications for some of them:

* the dates 2020-05-30 and 2020-05-31, where very high peaks were recorded due to protests sparked by the Black Lives Matter movement.
* the dates 2021-02-15 and 2022-02-02, where significant snowstorms that blocked the streets occurred.
* the date 2021-07-12, the already mentioned date where we assume some sort of malfunction occurred.

```{r south remove outliers}
outliers$South$index        = outliers$South$index       [c(1, 2, 3, 8, 9)]
outliers$South$replacements = outliers$South$replacements[c(1, 2, 3, 8, 9)]
```

```{r south outliers replacement}
# replace outliers
area.df$South = replace_outliers(
  df=area.df$South,
  ts=area.ts.daily$South,
  outliers=outliers$South
)
```

```{r area daily weekly conversion new}
area.ts.daily<- lapply(
  area.df, 
  daily_df_to_daily_ts
)
area.ts.weekly <- lapply(
  area.df, 
  daily_df_to_weekly_ts
)
```

***
# 2. Trend and Seasonality patterns in Chicago Areas

As we have already inferred from a simple visualization, the time series in object exhibit a **strong seasonal pattern** that seems to cause an increase in the average number of violations during the summer seasons.

This section aims to address this phenomenon in a more technical manner by employing **smoothing** and **filtering techniques** capable of highlighting or either removing this type of component: the seasonality could mask another type of interesting pattern, such as a trend. Finally, it is important to quantify how these **components contribute to the final observation**.

## Smoothing and Low-pass filtering

First, let's use various **filtering techniques**, i.e. linear transformations of the time series that highlight certain properties.

### Simple moving average filter

We begin with a basic filter: the **simple moving average**, which calculates the **arithmetic average** over a time window $p$.

$$
\hat{f}_t = \frac{1}{2p + 1} \sum_{i=-p}^p y_{t+i}
$$

We test different values of $p$, which plays a significant **role in determining the effect of smoothing** by considering a larger time window.

```{r simple ma daily, fig.width=8, fig.height=8}
# Using different values of p
p        <- c(         45,            90,          180)
p.colors <- c('lawngreen', 'deepskyblue', 'chocolate1')

par(mfrow = c(length(area.ts.daily), 1))

for (area_name in names.area) {
  
  daily <- area.ts.daily[[area_name]]
  
  plot_simple_ma_varying_p(
    ts=daily,
    p=p,
    p.color=p.colors,
    main=paste(area_name, "- Simple Moving Average filter"),
    ylab="Daily violations"
  )
  
}
par(mfrow=c(1,1))
```

The effect of $p$ has a significant impact on the results.

* `p=45`, which considers a time window of about **three months** and is capable of **smoothing out many of the oscillations** resulting, for example, from daily variability.
* `p=90`, which considers a time window of **half a year**, has a similar trend to the previous one but is **less sensitive to winter lows and summer peaks**.
* `p=180`, which considers a window of **about a year**, does not seem to be strongly influenced by seasonal variability. The transformation allows **observing a certain type of pattern over the years**: the most evident is the one that tends to grow after 2020 in the South area, but also in the other two areas a structure can be discerned.

Let's repeat the **same type of analysis for the weekly version**, moving towards a smoother visualization of the same scenario. Similarly, here `p=6`, `p=13`, and `p=26` consider time windows of about 3 months, 6 months, and a year.

```{r simple ma weekly, fig.width=8, fig.height=8}
# Using different values of p
p        <- c(          6,            13,            26)
p.colors <- c('lawngreen', 'deepskyblue', 'chocolate1')

par(mfrow = c(length(area.ts.daily), 1))

for (area_name in names.area) {
  
  weekly <- area.ts.weekly[[area_name]]
  
  plot_simple_ma_varying_p(
    ts=weekly,
    p=p,
    p.color=p.colors,
    main=paste(area_name, "- Simple Moving Average filter"),
    ylab="Avg weekly violations pday"
  )
  
}
par(mfrow=c(1,1))
```

The results are very similar to the previous version, although this new one perhaps offers a **more appreciable version of the yearly window smoothing** in the North and Center areas, where there is a noticeable increase in 2017 followed by a decline that extended until the pandemic years, with then return to an upward phase after 2021.

### Deseasnoaling filter

We can apply a **low-pass filter** that **highlights low-frequency patterns such as the trend**. We use a filter that averages among two consecutive time windows of a period $p$.

$$
\hat{f}_t = \frac{0.5\ y_{t-p/2} + y_{t-p/2+1}+ \ldots + y_0 + \ldots + y_{t+p/2-1} + 0.5\ y_{t+p/2}}{p}
$$


Let's first consider the periods of:

* a week (`p=7`);
* a month (`p=30`);
* a quarter (`p=90`);

```{r daily weekly monthly quarterly deseasonaling, fig.width=8, fig.height=8}
par(mfrow = c(length(area.ts.daily), 1))

for(area_name in names.area) {
  
  daily <- area.ts.daily[[area_name]]
  
  plot_deseasonaling_varying_freq(
    ts=daily,
    main=paste(area_name, "- Multiple deseasonaling of daily observations"),
    freq = c(7, 30, 90),
    freq.names = c("Weekly", "Monthly", "Quarterly"),
    freq.color = c("firebrick", "cyan3", "orange2"),
    ylab=names.ylab$daily,
    lwd=2
  )
  
}

par(mfrow=c(1,1))
```

In general, **none of the three variants seems to be able to eliminate a certain seasonal pattern**, but they pnly cut out local fluctuations; the transformations remain closely aligned with the original curve. Let's try with the **period that seems to be the most relevant**, the **annual one**. We use both versions with `p=365` for daily observations and `p = 52` for monthly ones.

deseasonaling in **daily** observations.

```{r daily yearly deseasonaling, fig.width=8, fig.height=8}
par(mfrow = c(length(area.ts.daily), 1))

for(area_name in names.area) {
  
  daily <- area.ts.daily[[area_name]]
  
  plot(
    daily,
    main=paste(area_name, "- Yearly deseasonaling of daily observations"),
    ylab=names.ylab$daily,
    col="dimgray"
  )
  
  deseasonal.trend = deseasonaling(
    ts=daily, 
    as.integer(freq$daily)
  )
  
  lines(
    deseasonal.trend,
    lty='dashed', lwd=3,
    col='cyan2'
  )
  
}

par(mfrow=c(1,1))
```

Deseasonaling in **weekly** observations.

```{r weekly yearly deseasonaling, fig.width=8, fig.height=8}
par(mfrow = c(length(area.ts.weekly), 1))

for(area_name in names.area) {
  
  weekly <- area.ts.weekly[[area_name]]
  
  plot(
    weekly,
    main=paste(area_name, "- Yearly deaseasoning of weekly deseasonaling"),
    ylab=names.ylab$weekly,
    col="dimgray"
  )
  
  deseasonal.trend = deseasonaling(
    ts=weekly, 
    freq=freq$weekly
  )
  
  lines(
    deseasonal.trend,
    lty='dashed', lwd=3,
    col='cyan2'
  )
  
}

par(mfrow=c(1,1))
```

The results highlight a strong **annual seasonality**, showing patterns similar to those already identified: an alternating phase of decrease and increase for the North and Center areas, and a sharp increase in violations for the South starting from 2021.

### Monthplot

The previous results highlight **two important components contributing to the observations**, trend and seasonality. As a first tool for the **quantification of the magnitude of their impact** we use the **monthplot**, that allows visualizing and comparing these two components by showing 12 different time series, one for each month.

```{r monthplot, fig.width=8, fig.height=8}
par(mfrow = c(length(area.df), 1))

for (area_name in names.area) {
  
  monthly <- daily_df_to_monthly_ts(df=area.df[[area_name]])
  
  monthplot(
    monthly,
    main=paste(area_name, " - Monthplot"),
    ylab="Monthly violations"
  )
  
}
  
par(mfrow=c(1,1))
```


The graph confirms what was expected: the observations exhibit a **strong monthly seasonality**, generally showing an increase in the summer months and a decrease in the winter month. However, it also reveals a certain **systematic trend regardless of the month**: the two effects seem more or less balanced in terms of their contribution to the final observation. Moving specifically to each Area:

* the ***North*** area highlights the previously described alternating trend, with a significant peak in 2017 followed by a decline that reached a very low point in the pandemic years, especially in April and May when the strictest quarantines were in place. The subsequent resurgence of violations in the following years tends to reach the same levels as in 2017 in the winter months, surpassing them in the summer months.

* the ***Central*** area generally shows similar trends to the North, with the exception of a slightly different behavior during the pandemic for the winter months, that don't have the hump shape curve.

* the ***South*** area shows, after a slight oscillation, a general increase in observations from 2021 onward, with a trend that has started to decrease in the very last period. The increase is significantly steeper in the summer months.

## STL Decomposition

The previous results **encourage a decomposition of the time series into three components**: **Trend**, **Seasonality**, and **Error**. To achieve this, we use the **STL technique** (Seasonal and Trend Decomposition using Loess). We compute the decompositions for the three areas using the weekly version which we know to be smoother and easier to interpret.

### Componenents contribution

First, we will focus on the **proportion in terms of contribution of the three components**. In a second part, we will describe the structure of each component, comparing it with the other areas.

#### North
```{r stl north decomposition, fig.width=6, fig.height=5}
plot_stl_decomposition(
  ts=area.ts.weekly$North,
  main=paste("North - Weekly STL Decomposition")
)
```

In the North area, the trend seems to contribute with a magnitude of about 150 observations, while seasonality with 200; the erratic component is quite substantial, contributing almost as much as the trend to the final observation.

#### Center

```{r stl center decomposition, fig.width=6, fig.height=5}
plot_stl_decomposition(
  ts=area.ts.weekly$Center,
  main=paste("Center - Weekly STL Decomposition")
)
```

For the Center area, both the trend and seasonality seem to contribute equally with an amount of 250 observations, while the erratic component is contained in a range of about 150.

#### South
```{r stl south decomposition, fig.width=6, fig.height=5}
plot_stl_decomposition(
  ts=area.ts.weekly$South,
  main=paste("South - Weekly STL Decomposition")
)
```

In the South, the trend covers about 250 observations, while both seasonality and error contribute to about 200 of the observations.

In general, the **contribution among the three components is mostly balanced**. This is not very desirable when the error is also involved, as we aim to make it the smaller as possible. However, it confirms that between trend and seasonality, there isn't a clear component that prevails over the other. Both somehow have a balanced contribution to the final number of violations.

### Components comparision

To better inspect the differences between the three areas, let's **compare the three components** of the Areas with particular attention to the trend.

#### Trend

```{r stl trend decomposition, fig.width=8, fig.height=7}
plot_stl_components(
  ts_list = area.ts.weekly,
  names=names.area,
  component_name="trend", 
  main=paste("Trend comparison of Chicago areas"), 
  ylab="Daily violations"
)
```

Here some main points:

* All three areas **highlight a peek of observations in 2017**, which is less pronounced in the South.
* Between 2018 and 2020, there is a decline in the North and Center, reaching a significant drop in the North, while during these years the trend in the South remains unchanged. 
* For all three areas, 2021 shows a rapid growth in violations, reaching the levels of 2017 for the North and Center and reaching new previously unrecorded levels in the South.
* While in recent observations the trend in the South has start decreasing, the opposite happens for Center and North areas.

#### Seasonality

```{r stl decomposition season, fig.width=8, fig.height=7}
plot_stl_components(
  ts_list = area.ts.weekly,
  names=names.area,
  component_name="seasonal", 
  main=paste("Seasonal decomposition comparison of Chicago areas"), 
  ylab="Daily violations"
)
```

The seasonal effect is **nearly identical and indicates a general condition of the city**. The only slight difference that might be noticed is that the summer peaks in the South tends to focus more in a shorter period.

#### Erratic component

```{r stl decomposition errors, fig.width=8, fig.height=7}
plot_stl_components(
  ts_list = area.ts.weekly,
  names=names.area,
  component_name="remainder", 
  main=paste("Error decomposition comparison of Chicago areas"), 
  ylab="Daily violations"
)
```

The erratic component is **not entirely satisfactory**, as it is possible to identify a **pattern with clusters of observations with positive and negative sign**, that is generally undesirable for the residuals of a model. This behavior was hinted to be present in the trend or in the seasonality but perhaps not fully captured.

## Conclusions

The investigation confirms a **clear annual seasonality**, leading to oscillations in the number of violations with summer peaks and winter lows. Although less pronounced, each area is also influenced by a **certain trend that has a very similar impact on the final number of violations**. An evident outcome is that in the post-pandemic years the average number of violations in the South area has undergone a drastic increase, reaching unprecedented levels. For the North and Center areas, it seems that after 2017, a certain policy might have been adopted to limit infractions, but this was overturned in the post-pandemic period, reinstating high values. These findings highlight a phenomenon that has resulted in a significant increase in violations and may warrant a reconsideration of the city's road strategy.

***
# 3. Weekly seasonality

The analysis in the previous chapter highlights a strong component linked to the month but also **hint at possible fluctuations within a single month**. These fluctuations may be related, for example, to **varying conditions concerning the day of the week**. This chapter aims to analyze the **importance of the weekly component within the observations**.

## Correlation of daily observations

First, we use various tools to understand if there is **evidence in the data of weekly dependencies**.

### ACF and PACF

We inspect the autocorrelation function of daily observations $Y_t$. More precisely we are interested in the **spikes at lags multiple of $7$**, that indicates the **linear correlation between the number of violations in the same weekday**.

```{r daily acf pacf, fig.width=7, fig.height=5}
for(area_name in names.area) {
    
  daily <- area.ts.daily[[area_name]]

  tsdisplay(
    daily,
    main=paste(area_name, "- Daily plot"),
    ylab=expression(Y[t])
  )
  
}
```

The ACF shows an **sinusoidal trend** (with the exception that the values do not tend to become negative in the first cycle for the South). The correlation tends to decrease in absolute value but then returns to be higher in lags that are multiples of an annual frequency, remarking the importance on annual seasonality. However, it is possible to identify a **series of higher spikes throughout the sequence**; let's try using a smaller number of lags to better understand if this factor can prove useful in the weekly day dependency.

```{r daily acf pacf 2, fig.width=7, fig.height=5}
for(area_name in names.area) {
    
  daily <- area.ts.daily[[area_name]]

  tsdisplay(
    daily,
    lag.max=50,
    main=paste(area_name, "- Daily plot"),
    ylab=expression(Y[t])
  )
  
}
```

As can be seen, although the correlation is still very high, the **multiples of 7 lags**, i.e., those referring to the same day of the week, **tend to always have a higher correlation**. This may be a sign of a recurring pattern on that day of the week.

### Weeklyplot

Exploiting this insight into the weekly day dependency, let's plot an analogue of the monthplot: the **weeklyplot**, a **collection of 7 different time series**, each corresponding to a **different day of the week**.

```{r weeklyplot, fig.width=12, fig.height=3}
for(area_name in names.area) {
    
  df <- area.df[[area_name]]
  
  weeklyplot(
    df=df,
    main=paste(area_name, "- Weekly plot")
  )
}
```

The trend is **consistent regardless of the weekday**, which it's very similar to what was already described in the previous section. However, the weekly trend shows how the average number of violations tends to be higher on Fridays, reaching its peak on Saturdays, decreasing almost to Friday's levels on Sundays, and then returning to a slightly lower level for the rest of the week. However, **this type of pattern has a significantly reduced impact compared to a much clearer trend**.

### ACF and PACF of 7-lagged version

In light of what has been analyzed, let's **try to remove the weekly factor through differencing**. We inspect the correlation of the $7$-lagged version of the observations considering $\widetilde{Y}_t = Y_t - Y_{t-7}$.

```{r daily 7 lag acf pacf, fig.width=7, fig.height=5}
for(area_name in names.area) {
    
  daily      <- area.ts.daily[[area_name]]
  daily_lag7 <- diff(daily, 7)

  tsdisplay(
    daily_lag7,
    lag.max=60,
    main=paste(area_name, "- 7 lagged Daily plot"),
    ylab=expression(tilde(Y[t]))
  )
  
}
```

The resulting ACF and PACF highlights significant spikes at lag multiple of 7, the order of the differencing; there still evidence of such strong pattern after a differentiation, hinting that although there is evidence of a **certain type of dependency related to the weekday**, this has a **reduced effect in the data compared to more influential periodic components such as the annual one**.

## Weekday and Weekend split

There is evidence in the data of an **increase in observations during the weekend**. Let's create **two separate time series for weekdays and weekends** to investigate if they are subjected to different dynamics.

```{r weekday weekend split}
area.ts.weeklydays <- lapply(
  area.df, 
  daily_df_to_weekly_ts_weekday_weekend
)
```

### Violations comparison

Let's plot the two in the same plot to investigate.

```{r weekday weekend plot, fig.width=8, fig.height=8}
par(mfrow = c(length(area.ts.weeklydays), 1))

for(area_name in names.area) {
    
  weeklydays <- area.ts.weeklydays[[area_name]]

  plot_multiple_ts(
    ts_list = weeklydays,
    names   = names(area.ts.weeklydays$Center),
    colors  = list(weekday='steelblue1', weekend='tomato1'),
    main    = paste(area_name, "- Violations in Weekdays and Weekends"),
    ylab    = "Average daily violations"
  )

}

par(mfrow=c(1,1))
```

For any area **the number of violations per day is higher during the weekend compared to weekdays**, with gap between the two that tends to amplify during the summer months. They are both **subject to the most seasonal effect** with more pronounced peaks in the summer seasons for the weekend.

### Weekend and Weekday CCF

This fact can be visualized in a more formal manner by looking at the **cross-correlation plot**.

```{r weekday weekend ccf, fig.width=8, fig.height=7}
par(mfrow = c(length(area.ts.weeklydays), 1))

for(area_name in names.area) {
    
  weeklydays <- area.ts.weeklydays[[area_name]]
  
  ccf(
    x=as.numeric(weeklydays$weekday),
    y=as.numeric(weeklydays$weekend),
    lag.max = 50,
    main=paste(area_name, "- Weekdays and Weekend Cross Correlogram"),
    ylab="CCF"
  )
} 

par(mfrow = c(1, 1))
```

The graph highlights what was expected, namely the **strong linear dependence between weekdays and weekends**.

### Linear regression fit

The previous results highlight a strong linearity between weekdays and weekends, suggesting that a simple **linear regression model** may be sufficient to achieve a **good level of prediction** between them.

#### North
```{r weekday weekend linear regression north, fig.width6, fig.height=4}
fit <- list()


# Fitting linear regression
fit$North <- lm(area.ts.weeklydays$North$weekend ~ area.ts.weeklydays$North$weekday)

plot(
  x=area.ts.weeklydays$North$weekday,
  y=area.ts.weeklydays$North$weekend,
  pch=16, col="steelblue",
  main=paste("North - Weekdays VS Weekend violations"),
  xlab="Avg violations on weekdays",
  ylab="Avg violations on weekdays",
)
abline(fit$North,  col = "orange2", lwd = 2, lty="dashed")
grid()
  
print(summary(fit$North))
```

#### Center
```{r weekday weekend linear regression center, fig.width6, fig.height=4}

# Fitting linear regression
fit$Center <- lm(area.ts.weeklydays$Center$weekend ~ area.ts.weeklydays$Center$weekday)

plot(
  x=area.ts.weeklydays$Center$weekday,
  y=area.ts.weeklydays$Center$weekend,
  pch=16, col="steelblue",
  main=paste("Center - Weekdays VS Weekend violations"),
  xlab="Avg violations on weekdays",
  ylab="Avg violations on weekdays",
)
abline(fit$Center,  col = "orange2", lwd = 2, lty="dashed")
grid()
  
print(summary(fit$Center))
```

#### South
```{r weekday weekend linear regression south, fig.width6, fig.height=4}

# Fitting linear regression
fit$South <- lm(area.ts.weeklydays$South$weekend ~ area.ts.weeklydays$South$weekday)

plot(
  x=area.ts.weeklydays$South$weekday,
  y=area.ts.weeklydays$South$weekend,
  pch=16, col="steelblue",
  main=paste("South - Weekdays VS Weekend violations"),
  xlab="Avg violations on weekdays",
  ylab="Avg violations on weekdays",
)
abline(fit$South,  col = "orange2", lwd = 2, lty="dashed")
grid()
  
print(summary(fit$South))
```

The result evidence the **dependency between weekdays and weekends**, which we can conclude to be **linear**. The model works particularly well for the South area, which has a multiple R-squared that exceeds $0.9$. This type of visualization also provides another insights of the number of violations for the South area, which we know has undergone a mean increase in recent years, highlighted by the different density of two point clouds in the graph.

## Conclusions
The investigation reveals **no significant evidence of a different weekly pattern depending on the weekday**, let alone a distinct weekday and weekend scenario. This result provides a valuable insight for building forecasting models as it suggests ignoring potential weekly dependencies and, more importantly, it indicates that it is **appropriate to work on a weekly forecasting level**. The weekly prediction is also beneficial if interest the daily prediction,yet we demonstrated that the value can be reproportionated from the average week level.

***
# 4. Forecasting

One of the tasks certainly more interesting is the **time series forecasting**: that is, using statistical techniques that leverage a historical dataset to **make predictions about the number of future observations**. This chapter will focus on **predictions using ARIMA models**, employing both **daily and weekly forecasts**. Since a good predictive mechanism requires a varied analysis and experimentation, this chapter will only focus on making predictions for the Central area. The other two will be considered again in the next chapter, investigating predictive capabilities with reference to the central area.

The process requires **training a model and evaluating it**, for this reason, we adhere to the typical paradigm of **splitting our dataset into train set**, for model fitting, and **test set**, to measure generalization capabilities on unseen data. The temporal dependence inherent in the data necessitates a **split that preserves the temporal relationships between time points**. We opt to use the first seven years of observations, spanning from 2015 to 2021, as the training set. Conversely, the sole year 2022 is designated as the test set. This choice offer the advantage of comparing predictions over a one-year time window, helping us discern whether there are specific periods during the year where the models perform better or worse.


```{r train test split}
test_split_date <- as.Date("2022-01-01")

area.ts.daily.split  <- lapply(
  area.ts.daily,
  function(ts) {
    split_ts(ts=ts, date_split=test_split_date, train_test = TRUE)
  }
)
fit.daily <- list()

area.ts.weekly.split  <- lapply(
  area.ts.weekly,
  function(ts) {
    split_ts(ts=ts, date_split=test_split_date, train_test = TRUE)
  }
)
fit.weekly <- list()
```

## Daily forecasting

Let's begin with **daily prediction**. First of all we visualize the split between training and testing.

```{r daily train test split, fig.height=5, fig.width=7}
plot_multiple_ts(
  ts_list=area.ts.daily.split$Center,
  names=names(area.ts.daily.split$Center),
  colors=list(train="steelblue", test="orange2"),
  main="Center - Daily train test split",
  ylab=names.ylab$daily,
)
```

### Fitting models

We proceed by inspecting **various transformations of the time series** and their **autocorrelation and partial autocorrelation** functions. This allows us to verify if the conditions for applying a model are met and, in case we have an intuition about the number of parameters characterizing the ARIMA process.

#### Original one

First of all, let's visualize the **original time series**.

```{r daily tsdisplay1, fig.width=7, fig.height=5}
tsdisplay(
  area.ts.daily.split$Center$train,
  main = "Center - Original time series",
  ylab = names.ylab$Daily
)
```

We know the time series to have a trend, although not super outline, so stationarity assumptions cannot be really founded. The ACF shows a sinusoidal pattern that does not tend to decay uniformly, while the PACF is null after a certain lag. Let's try fitting a model that has both autoregressive and moving average components, for example, **ARMA(4, 2)**.

```{r daily fit1}
fit.daily$Center <- list()
fit.daily$Center$fit1 <- Arima(
  area.ts.daily.split$Center$train, 
  order=c(4, 0, 2)
)
summary(fit.daily$Center$fit1)
```

The fitted model:

$$(1 - 1.8380B + 1.4247B^2 - 0.2017B^3 - 0.3120B^4) Y_t = 557.6361 + (1 - 1.2473B + 0.9912B^2) Z_t\ ; \quad Z_t \sim WN(0, 4087) $$

#### First order differencing

We apply **first order differencing** attempting to make the process stationary.

```{r daily tsdisplay2, fig.width=7, fig.height=5}
tsdisplay(
  diff(area.ts.daily.split$Center$train, 1),
  main = "Center - First order differencing",
  ylab = paste(names.ylab$Daily, "- Diff(1)"),
  lag.max = 70
)
```

The process is now definitely more aligned with the requirements of stationarity. Both ACF and PACF exhibit a sinusoidal pattern that tends to fade in the later lags of PACF. Let's try fitting ans **ARIMA(3, 1, 2)**.

```{r daily fit2}
fit.daily$Center$fit2 <- Arima(
  area.ts.daily.split$Center$train, 
  order=c(3, 1, 2)
)
summary(fit.daily$Center$fit2)
```

The fitted model:

$$(1 - 0.797 B + 0.415 B^2 + 0.2983 B^3) (1 - B) Y_t = (1 - 1.2433 B + 0.599 B^2) Z_t\ ; \quad Z_t \sim WN(0, 4211) $$
#### Weekly

```{r daily tsdisplay week, fig.width=7, fig.height=5}
tsdisplay(
  diff(area.ts.daily.split$Center$train, 7),
  main = "Center - Weekly order differencing",
  ylab = paste(names.ylab$Daily, "- Diff(7)"),
  lag.max = 70
)
```

```{r}
fit.daily$Center$fit3 <- Arima(
  area.ts.daily.split$Center$train, 
  order=c(3, 5, 3)
)
summary(fit.daily$Center$fit3)

```



#### Yearly order differencing

We can try **removing the seasonal effect** by **differencing for the period**, that is 365 days.

```{r daily tsdisplay3, fig.width=7, fig.height=5}
tsdisplay(
  diff(area.ts.daily.split$Center$train, as.integer(freq$daily)),
  main = "Center - Daily order differencing",
  ylab = paste(names.ylab$Daily, "- Diff(", as.integer(freq$daily), ")", sep=""),
  lag.max = 70
)
```

Nevertheless, applying differencing to eliminate potential periodic factors might be impractical and risky in the case of daily observations. This is because we are not considering time domains such as months or weeks where a certain type of pattern is expected over a relatively large time period. The difference between days in two different years is highly variable, influenced by factors like weather or the day of the week, making it uninformative and challenging to utilize effectively.

#### Autofit

Finally, let's leverage an **automatic fit** with parameters automatically extracted by software with `auto.arima()` using *AICc* as the criterion for the best fit selection.

```{r daily autofit}
fit.daily$Center$auto <- auto.arima(
  area.ts.daily.split$Center$train,
  trace=TRUE,
  ic="aicc"
)

summary(fit.daily$Center$auto)
```

The fitted model is an **ARIMA(5, 1, 1)**:

$$(1 + 0.0475B + 0.2813B^2 + 0.3331B^3 + 0.2949B^4 + 0.2383B^5)(1 - B)Y_t = (1 - 0.4414B)Z_t\ ; \quad Z_t \sim WN(0, 4108) $$

### Best fit selection

We compare the three fitted models and choose the best one in terms of *AICc*.

```{r daily best fit}
fit.daily$Center$best <- arima_fit_selection(
  fit_list = fit.daily$Center,
  criteria = 'AICc'
)
```

The **best fitted model** is the one resulted by the **automatic parameter selection**. Let's inspect its behavior in terms of residuals.

```{r daily best fit diagnostic, fig.width=7, fig.height=5}
tsdiag(fit.daily$Center$best, main="Daily fit - Residuals")
```

The **residuals are not satisfactory**, indicated by the Ljung-Box test showing some autocorrelation, and they do not display characteristics consistent with white noise. The model's quality is not optimal, and this can be attributed, in part, to the difficult nature of modeling data with extremely high variability, especially in the context of daily observations. Even if **daily modeling result ineffective**, Perhaps predicting the individual daily value may be not truly the focus of real-word application: it might be more interesting and useful to **predict an average weekly trend**, which is what we aim to do in the next chapter.


```{r daily forecasts, fig.width=8, fig.height=7, include=FALSE}
par(mfrow=c(2, 2))

split_dates <- list(
  as.Date("2022-01-01"),
  as.Date("2022-06-01"),
  as.Date("2022-09-01"),
  as.Date("2022-12-01")
)

errors <- list()

errors$daily <- model_multiple_evaluation(
  ts=area.ts.daily$Center,
  model=fit.daily$Center$best,
  split_dates=split_dates,
  main="Prediction after",
  ylab=names.ylab$daily
)

par(mfrow=c(1, 1))
```

```{r daily forecasts errors, include=FALSE}
print(errors$daily)
```

```{r daily one step ahead forecasts, fig.height=5, fig.width=7, include=FALSE}
osa_prediction <- list()
osa_prediction$daily <- model_one_step_ahead_evaluation(
  ts=area.ts.daily$Center,
  model=fit.daily$Center$best,
  date_start=as.Date("2022-01-01"), # first Monday
  date_end=as.Date("2022-12-31"),
  freq_type="daily",
  main="Center - True vs Predicted 1 step-ahead forecasting",
  ylab=names.ylab$daily
)
```

```{r daily one step ahead forecasts errors, fig.height=5, fig.width=7, include=FALSE}
errors_analysis(
  pred_ts = osa_prediction$daily,
  error_type = "RMSE",
  k=6,
  h=3,
  freq_type = "daily",
  start_date=as.Date("2022-01-03"),
  main="Center - 1 step-ahead forecasting prediction error",
  ylab="RMSE error"
)
```

## Weekly forecasting

Let's move to **weekly prediction**. We start by visualizing the split between training and testing.

```{r weekly train test split, fig.height=5, fig.width=7}
plot_multiple_ts(
  ts_list=area.ts.weekly.split$Center,
  names=names(area.ts.weekly.split$Center),
  colors=list(train="steelblue", test="orange2"),
  main="Center - Weekly Train test split",
  ylab=names.ylab$weekly,
)
```

### Fitting models

As we have previously done with the daily forecasting, we inspect **different transformation of the original time series** with their ACF and PACF to devise different fitting models.

#### Original one

We start with the **original time series**.

```{r weekly tsdisplay1, fig.width=7, fig.height=5}
tsdisplay(
  area.ts.weekly.split$Center$train,
  main = "Center - Original time series",
  ylab = names.ylab$Weekly
)
```

Even though we cannot fully rely on stationarity assumptions, the ACF shows a sinusoidal trend that is decreasing, and the PACF does not have significant spikes after the fifth lag. Based on this, we fit an **AR(5)** model.

```{r weekly fit1}
fit.weekly <- list()
fit.weekly$Center <- list()
fit.weekly$Center$fit_orig <- Arima(
  area.ts.weekly.split$Center$train, 
  order=c(5, 0, 0)
)
summary(fit.weekly$Center$fit_orig)
```

The fitted model:

$$ (1 - 0.7171 B - 0.1853 B^2 - 0.0829 B^3 - 0.1205 B^4 + 0.1645 B^5)Y_t = 549.6611 + Z_t\ ; \quad  Z_t \sim WN(0, 1812) $$

#### First order differencing

To better adhere to the assumption of stationarity, we model the time series with **first-order differencing**.

```{r weekly tsdisplay2, fig.width=7, fig.height=5}
tsdisplay(
  diff(area.ts.weekly.split$Center$train, 1),
  main = "Center - First order differencing",
  ylab = paste(names.ylab$Weekly, "- Diff(1)"),
  lag.max = 70
)
```

However no clear structure can be evinced by ACF and PACF.

#### Yearly order differencing

Let's try to **remove the seasonal effect** by taking $52$-order differencing, that is the weekly frequency in a year.

```{r weekly tsdisplay3, fig.width=7, fig.height=5}
tsdisplay(
  diff(area.ts.weekly.split$Center$train, freq$weekly),
  main = "Center - Weekly order differencing",
  ylab = paste(names.ylab$Weekly, "- Diff(", freq$weekly, ")", sep=""),
  lag.max = 70
)
```

The process is clearly non stationary so we cannot make any conclusion on the ACF and PACF to fit models.

#### Yearly and first order differencing

We apply **first order differencing to $52$-order one**, attempting for stationarity.

```{r weekly tsdisplay4, fig.width=7, fig.height=5}
tsdisplay(
  diff(diff(area.ts.weekly.split$Center$train, freq$weekly), 1),
  main = "Center - Weekly order differencing plus fist order differencing",
  ylab = paste(names.ylab$Weekly, "- Diff(", freq$weekly, ", 1)", sep=""),
  lag.max = 70
)
```

ACF and PACF have really few significative spikes. We model this process as a **SARIMA(0, 1, 1)(0, 1, 1)[52]**.

```{r weekly fit2}
fit.weekly$Center$seasonal <- Arima(
  area.ts.weekly.split$Center$train, 
  order=c(0, 1, 1),
  seasonal=list(order=c(0, 1, 1), period=freq$weekly)
)
summary(fit.weekly$Center$seasonal)
```

The fitted model:

$$(1 - B)(1 - B^{52}) Y_t = (1 - 0.4435B)(1 - 0.9976B^{52})Z_t\ ; \quad Z_t \sim WN(0, 1504)$$

#### Autofit

Finally we employ **automatic model selection** with the `auotarima()` function, using *AICc* as criteria.

```{r weekly autofit}
fit.weekly$Center$auto <- auto.arima(
  area.ts.weekly.split$Center$train,
  trace=TRUE,
  ic="aicc"
)

summary(fit.weekly$Center$auto)
```

The fitted model is an **SARIMA(1, 1, 0)(1, 1, 0)[52]**:

$$(1 + 0.3405 B)(1 + 0.5437 B^{52})(1-B)(1-B^{52}) Y_t = Z_t\ ; \quad  Z_t \sim WN(0, 2340) $$

### Best fit selection

We **select the best among the three fitted models** in terms of *AICc*.

```{r weekly best fit}
fit.weekly$Center$best <- arima_fit_selection(
  fit_list = fit.weekly$Center,
  criteria = 'AICc'
)
```

The best select one is the **SARIMA(0,1,1)(0,1,1)[52]** we devised from the yearly and first order differencing analysis. Let's investigate it's residuals.

```{r weekly best fit diagnostic, fig.width=7, fig.height=5}
tsdiag(fit.weekly$Center$best)
```

The residuals are normally distributed and passes the Ljiung-Box test and so **behave as white noise**. Our model can be validated.

### Forecasting

Once the good validity of the model in terms of residuals has been confirmed, we proceed to test its predictive capabilities; we seek to assess how well the model predicts unseen data. To this end, we **analyze the forecasting accuracy across four different time 1periods**:

1. the last year
2. the last six months
3. the last three months
4. the last month

For each period, we visualize the point forecast along with its 80% and 95% prediction intervals. Additionally, we compute quantitative metrics to gauge prediction errors in various forms.

```{r weekly forecasts, fig.width=8, fig.height=7}
par(mfrow=c(2, 2))

errors$weekly <- model_multiple_evaluation(
  ts=area.ts.weekly$Center,
  model=fit.weekly$Center$best,
  split_dates=split_dates,
  main="Prediction after",
  ylab=names.ylab$Weekly
)

par(mfrow=c(1, 1))
```

The prediction interval in quite wide for any prediction horizon. The one-month and three-month point predictions adhere to the true trend, while there is an underestimation for the last six months and an overestimation for the last month. Errors reflect this point.

```{r weekly forecasts errors}
print(errors$weekly)
```

### One-step-ahead forecasting

This type of model works well on a short-term prediction window so the comparison over different time periods cannot be as fair. We perform **one-step-ahead forecasting for each instance in the test set**, meaning a single week prediction using the information available up to the week before. We plot the true observations against the predicted ones along with their prediction intervals.

```{r weekly one step ahead forecasts, fig.height=5, fig.width=7}
osa_prediction$weekly <- model_one_step_ahead_evaluation(
  ts=area.ts.weekly$Center,
  model=fit.weekly$Center$best,
  date_start=as.Date("2022-01-03"), # first monday
  date_end=as.Date("2022-12-31"),
  freq_type="weekly",
  main="Center - True vs Predicted 1 step-ahead forecasting",
  ylab=names.ylab$weekly
)
```

The prediction appears to **adequately follow the actual trend with moderately contained variability**. Such kind of predictions allows to infer weeks have experienced the highest errors.

```{r weekly one step ahead forecasts errors, fig.height=5, fig.width=7}
errors_analysis(
  pred_ts = osa_prediction$weekly,
  error_type = "RMSE",
  k=5,
  h=5,
  freq_type = "weekly",
  start_date=as.Date("2022-01-03"),
  main="Center - 1 step-ahead forecasting prediction error",
  ylab="RMSE error"
)
```

The weeks in April and July stand out as having lower errors, suggesting potentially better predictive capabilities for the model during these periods. Conversely, the model performs poorly especially on the last two weeks of May; looking at the trend we can suspect that a extraordinary event leaded to increased traffic during that time. 

## Conclusions

We can conclude that **building a sufficiently adequate and accurate daily prediction model is very challenging**. The daily variability is inherently challenging to capture, and with a considerable number of observations in a period, even seasonality becomes complicated to model. The model does not meet the requirements for residuals. However, this result does not completely undermine the predictive intent. Generally, **we are not interested in a precise prediction for a single day**, but rather in a broader time window that serves as an indicator of a certain behavior over a period.

In this regard, a **weekly forecasting model appears to achieve good predictive capabilities** by explicitly modeling the seasonal component and meeting the technical requirements necessary to validate the model. The model provides good forecasting horizons and performs well in terms of one-step-ahead forecasting. Furthermore, the results from the previous chapter suggest that it is **appropriate to work at the level of the average weekly violations**, with potential adjustments based on the specific day of the week.

# 5. Dependencies between areas

In this final section, our objective is to explore the **possibility of a correlation between different regions** and whether such **correlation could improve the predictive capabilities of forecasting models**. The idea is to examine whether there are **patterns or relationships among regions** that, when considered in the forecasting process, could lead to more accurate predictions.

## Interdependencies

As an initial step, we can employ **statistical tools** to analyze potential **relationships that interconnect the three areas**. These will help us in quantifying and understand the strength and nature of the relationships between different areas

### Cross correlation

We start with the analysis of the cross-correlation between the Center area (the region of interest for prediction) and the other two regions.

We plot the cross correlation between the Center and the North.

```{r north ccf, fig.height=5, fig.width=6}
ccf(
  y=as.numeric(area.ts.weekly$Center), 
  x=as.numeric(area.ts.weekly$North),
  main="Center and North - CCF",
  lag.max = 100
)
```

We plot the cross correlation between the Center and the South.

```{r south ccf, fig.height=5, fig.width=6}
ccf(
  x=as.numeric(area.ts.weekly$Center),
  y=as.numeric(area.ts.weekly$South),
  main="Center and South - CCF",
  lag.max = 100
)
```

The two cross-correlograms reveal a **robust linear dependence between the two time series**, persisting even at considerable time lags. The observed pattern is sinusoidal, indicating a negative correlation occurring roughly every six months. The substantial linear relationship is in **general expected since the all observations are probably affected by a scenario common to the entire city** (such as weather conditions or specific holiday days).

While the cross-correlogram with the North is symmetric, indicating a symmetric dependence between the two regions, the same cannot be said for the cross-correlogram with the South. Particularly, when looking at the negative portions of the sinusoid, it reveals a dependence of the South on the Center that is less pronounced than the reciprocal one.

### Linear regression

Given the insights obtained, it is reasonable to **explore the predictive capabilities** of the North and South areas on the Center one through the lens of **linear regression**. In this regard, we proceed to fit several models employing these two regions as predictive factors. 

#### North

Let's start by using the ***North* area** as the **single predictor**.

```{r north lr, fig.height=4, fig.width=6}
plot(
  x=as.numeric(area.ts.weekly$North),
  y=as.numeric(area.ts.weekly$Center),
  xlab="North violations",
  ylab="Center violations",
  pch=19, col="steelblue"
)
grid()

lm.fit <- list()

lm.fit$North <- lm(area.ts.weekly$Center ~ area.ts.weekly$North)
summary(lm.fit$North)
abline(lm.fit$North,  col = "orangered", lwd = 3, lty="dashed")
```

The scatterplot indicates that the relationship is **well-suited for linear regression**, explaining approximately 82% of the variability. Let's examine the residuals in terms of autocorrelation.

```{r north lr resid, fig.height=5, fig.width=7}
checkresiduals(lm.fit$North)
```

The ACF does not resemble that of white noise, which is expected. The linear fitting was not explicitly optimized to achieve this purpose. Instead, it was designed to produce residuals with zero mean and a normal distribution.

#### South

Let's now use the ***South* area** as the **single predictor**.

```{r south lr, fig.height=4, fig.width=6}
plot(
  x=as.numeric(area.ts.weekly$South),
  y=as.numeric(area.ts.weekly$Center),
  xlab="South violations",
  ylab="Center violations",
  pch=19, col="steelblue"
)
grid()

lm.fit$South <- lm(area.ts.weekly$Center ~ area.ts.weekly$South)
summary(lm.fit$South)
abline(lm.fit$South,  col = "orangered", lwd = 3, lty="dashed")
```

In the case of the South, the relationship is **not as straightforwardly linear**. The linearity appears to diminish as the number of observations increases. However, the model can still explain 65% of the variability, which is a respectable result. Now, let's examine the residuals.

```{r south lr resid, fig.height=5, fig.width=7}
checkresiduals(lm.fit$South)
```

Similar to what occurred with the North, the residuals appear to have a zero mean and follow a normal distribution. However, the ACF deviates significantly from the white noise pattern one would expect, again because linear regression is not explicitly optimized to produce white noise residuals.

#### North and South

Let's now **combine the information from the two areas** using **both *North* and *South* predictors**.

```{r north south lr}
lm.fit$NorthSouth <- lm(area.ts.weekly$Center ~ area.ts.weekly$North + area.ts.weekly$South)
summary(lm.fit$NorthSouth)
```

When used together both predictors are significant and lead to an **increase in explained variability** up to 87%. The result suggests that both predictors can contribute to explaining the number of violations in the center by providing two diverse pieces of information.

```{r north south lr resid, fig.height=5, fig.width=7}
checkresiduals(lm.fit$NorthSouth)
```

The considerations about the residuals are almost the same as those conducted in the models using a single area as a predictor.

## Dynamic regression

In this last part we employ a different model for forecasting the number of violations in the Center area. This alternative approach involves employing a **dynamic regression technique**, which include in the model a **set of regressors** that in our context to the violations in the other two areas.

### Fitting

As we did with linear regression, we **fit various models by altering the types of regressors**. This also allows us to make comparisons with the model fitted in the previous chapter.

#### North

We start using the violations in the **North as regressor**.

```{r north dm fit}
dr.fit <- list()

dr.fit$North <- auto.arima(
  area.ts.weekly.split$Center$train,
  xreg=area.ts.weekly.split$North$train
)
summary(dr.fit$North)

```

The fitted model is a regression with **ARIMA(0,1,2)(0,0,1)[52]** errors:

$$Y_t = 0.9545 X_t + \eta_t \\ (1-B)\eta_t = (1 - 0.4374B - 0.0776 B^2)(1 - 0.0869B^{52})\epsilon_t $$

```{r north dm checkresid, fig.width=7, fig.height=5}
checkresiduals(dr.fit$North)
```

#### South

We replicate the same operation using **South area as regressor**.
```{r south dm fit}
dr.fit$South <- auto.arima(
  area.ts.weekly.split$Center$train,
  xreg=area.ts.weekly.split$South$train
)
summary(dr.fit$South)
```

The fitted model is a regression with **ARIMA(0,1,2)(0,0,2)[52]** errors:

$$ Y_t = 0.9141 X_t + \eta_t \\ (1-B)\eta_t = (1 - 0.3704 B - 0.1108 B^2)(1 + 0.1015 B^{52} + 0.0656 B^{104})\epsilon_t $$
```{r south dm checkresid, fig.width=7, fig.height=5}
checkresiduals(dr.fit$South)
```

#### North and South

Finally we employ ***both North and South as regressors***.

```{r north south dm fit}
dr.fit$NorthSouth <- auto.arima(
  area.ts.weekly.split$Center$train,
  xreg=cbind(North=area.ts.weekly.split$North$train, 
             South=area.ts.weekly.split$South$train)
)
summary(dr.fit$NorthSouth)
```

The fitted model is a regression with **ARIMA(2, 3, 1)** errors, which differently from previous ones hasn't a seasonal part:

$$
Y_t = 0.7411 X_{North_t} + 0.4080 X_{South_t} + \eta_t \\ (1+1.2167 B + 0.6068 B^2)(1-B)\eta_t = (1 + 0.8165 B - 0.0332 B^2 - 0.4636 B^3)\epsilon_t
$$
```{r northsouth dm checkresid, fig.width=7, fig.height=5}
checkresiduals(dr.fit$NorthSouth)
```

### Model comparison

We evaluate the models from two main perspectives. First, we **examine their forecasts and compare their Information Criteria**. Second, we **assess their performance** based on the **errors observed in the test set**. These two viewpoints provide a comprehensive understanding of how well the models capture the dynamics and variability of the data.

### Confidence Interval and Information Criteria

We proceed to compare these **three dynamic regression models** alongside the **deterministic model** resulting from the previous analyses. We visualize their forecasting performance over the entire test set and compare their Information Criteria (IC). This comprehensive evaluation allows us to judge how well each model captures the underlying patterns and variability in the data.

```{r model comparison ic, fig.width=8, fig.height=10}
models <- list(
  North = list(
    fit=dr.fit$North, 
    xreg=area.ts.weekly.split$North$test, 
    main="North regressor", 
    col="orangered2"
  ),
  South = list(
    fit=dr.fit$South,
    xreg=area.ts.weekly.split$South$test,
    main="South regressor",
    col="green2"
  ),
  NorthSouth = list(
    fit=dr.fit$NorthSout,
    xreg=cbind(North=area.ts.weekly.split$North$test,
               South=area.ts.weekly.split$South$test),
    main="North-South regressor",
    col="pink2"
  ),
  Deterministic = list(
    fit=fit.weekly$Center$best,
    h=length(area.ts.weekly.split$South$test),
    main="Deterministic",
    col="deepskyblue2"
  )
)

model_comparison_ic(
  models=models,
  ylab=names.ylab$weekly
)
```

In general, the **four models are comparable** both in terms of **point predictions** and **prediction intervals**. However, the deterministic model exhibits a smoother line with fewer oscillations compared to the other dynamic regression models. These oscillations in the dynamic regression models are attributed to the regressors, which, being test data, introducethemselves slight fluctuations in the predictions.

The information criteria (IC) of the three regression models align with the observations made during the linear regression analysis. The North appears to explain the observations in the Center better than the South in isolation. However, a combined use of both predictors can still contribute to some improvement. Nevertheless, the **deterministic model**, which also uses fewer parameters compared to the other regression models, remains the **best model in terms of IC**, any of the three measures we consider.

### Prediction error

Moving on, let's assess the performance of the models in terms of **forecasting errors on the test set**. It's worth noting that the regression models have an advantage in this regard because they use the current recorded values as inputs, whereas in a real-world scenario, their own predictions would need to be used. In this case, they can provide information about potential extraordinary fluctuations that would be challenging to capture in a real-world predictions.

```{r model comparison err 1, fig.width=7, fig.height=5}
model_comparison_prediction(
  models=models,
  train=area.ts.weekly.split$Center$train,
  test=area.ts.weekly.split$Center$test,
  main="Models prediction comparison",
  ylab=names.ylab$weekly
)
```

We zoom in on the prediction horizon to gain a better understanding.

```{r model comparison err 2, fig.width=7, fig.height=5}
model_comparison_prediction(
  models=models,
  train=area.ts.weekly.split$Center$train,
  test=area.ts.weekly.split$Center$test,
  main="Models prediction comparison",
  ylab=names.ylab$weekly,
  lwd = 2,
  plot_train = FALSE
)
```

The predictions from the South regressors area are, as expected, the  least precise, while the most accurate predictions come from the North and NorthSouth ones, with the latter not seeming to significantly benefit from the second regressor. However, the **deterministic model achieves a good level of accuracy** compared to these, even though **it doesn't have the chance to utilize actual future values**, as the regression models do. Looking at the graph, it's quite evident that the error in the regression models is favorable by the possibility to capture fluctuations that would be challenging to predict in a real-word two step-forecasting, that requires first to forecast the expected violation for the other areas and employ the number as a regressor.

## Conclusions

A **model** that **combines predictions from multiple areas through dynamic regression** seems unpromising and ultimately **not advantageous** compared to the deterministic model developed in the previous chapter. This is because dynamic regression may leverage its potential effectively when the domains of the regressors differ from that of the prediction and represent factors influencing the phenomenon of interest, such as precipitation or other meteorological factors.

We observed that the **three areas are highly correlated and likely represent slightly different manifestations of a common factor influencing the entire city**. The real-word application of the dynamic regression requires the forecast of one area, which is used as regressor for a second one. This process is redundant, and contributes more or less the same information as the deterministic model, which directly forecasts for that area, but with less variability due to the non-stationary nature of errors.

