---
title: "Chicago - Red Light Camera Violations"
author: "Sebastiano Quintavalle"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    theme: united
  pdf_document: default
editor_options: null
chunk_output_type: console
---

```{r output setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.align='center')
```

# 1. Data preparation and setup

## Environment setup

```{r environment setup, include=FALSE}
Sys.setlocale("LC_TIME", "en_US.UTF-8")
rm(list=ls())
```

Loading the necessary **packages** for the project.

```{r packages}
library(forecast)
```

Importing **custom variables** and **functions** from local files.

```{r source files}
source("./src/arima_utils.R")
source("./src/globals.R")
source("./src/plotting.R")
source("./src/smoothing.R")
source("./src/time.R")
```

## Data preparation

### Reading file

Reading the [`violations.csv`](out/violations.csv) file, containing preprocessed **daily traffic light violation** downloaded from the [Chicago Data Portal](https://data.cityofchicago.org/Transportation/Red-Light-Camera-Violations/spqx-js37/data_preview).

```{r reading file}
# Reading file
violations.regions.df <- read.csv(file=violation_file)

# Casting Regions as factors
violations.regions.df$Region = as.factor(violations.regions.df$Region)

# Converting Date column to DateType
violations.regions.df$Date <- as.Date(
  x      = as.character(violations.regions.df$Date),
  format = "%m/%d/%Y"
)
```

Let's inspect the very first few lines.
```{r df head}
head(violations.regions.df)
```

Moreover we are interested in **basics statistics**.
```{r summary}
summary(violations.regions.df)
```

The observations cover a **time window of 8 years**, from *January 1, 2015*, to *December 31, 2022*.

There are a total of **nine different regions**.

```{r region levels}
levels(violations.regions.df$Region)
```


### Aggregating by areas

The dataset encompasses observations for **nine distinct regions** within Chicago. To streamline the analysis, which could become cumbersome when examining each of the nine regions individually, a **subsequent aggregation** is conducted, categorizing the city into **three primary areas**:

* ***North***: FarNorth, NorthWest, North.
* ***Center***: Central, West, SouthWest, South.
* ***South***: FarSouthWest, FarSouthEast.

```{r chicago sides,  fig.cap="Chicago sides", out.width = "700px", echo=FALSE, include=TRUE}
knitr::include_graphics("./out/chicago_sides_and_areas.png")
```


```{r area definition}
# Assigning each Region to the specific Area
violations.regions.df$Area <- 
  ifelse(violations.regions.df$Region %in% names.regions$North,  'North',
  ifelse(violations.regions.df$Region %in% names.regions$Center, 'Center',
  ifelse(violations.regions.df$Region %in% names.regions$South,  'South',  NA)))

# Casting to factors
violations.regions.df$Area = as.factor(violations.regions.df$Area)

# Aggregating violations by areas
violations.areas.df = aggregate(
  Violations ~ Area + Date,
  data = violations.regions.df,
  sum
)

# First few observations
head(violations.areas.df)

# Basic statistics
summary(violations.areas.df)
```

### Splitting dataset

We utilize the labels associated to each region and area to **partition the dataset into a list** of datasets, with each one linked to a specific region or area.

```{r dataframe region split}
# List of regions
region.df <- split(
  violations.regions.df,
  violations.regions.df$Region
)
names(region.df)
```

```{r dataframe area split}
# List of areas
area.df <- split(
  violations.areas.df,
  violations.areas.df$Area
)
names(area.df)
```

## Creating time series

We employ custom functions to transform the dataset into **daily**, **weekly** and **monthly formats**. The monthly format involves aggregating the total number of violations within each month, revealing essential insights for seasonality analysis.

#### Daily

Daily time series also includes the two leap years including *29th February*; for this reason the frequency is $365.25$.

```{r daily time series}
region.ts.daily <- lapply(
  region.df, 
  daily_df_to_daily_ts
)

area.ts.daily <- lapply(
  area.df, 
  daily_df_to_daily_ts
)
```

#### Weekly 

Weekly time series don't consider the first and the last week of the year because they have an arbitrary number of days that introduce variance different to control.

```{r weekly time series}
region.ts.weekly <- lapply(
  region.df, 
  daily_df_to_weekly_ts
)

area.ts.weekly <- lapply(
  area.df, 
  daily_df_to_weekly_ts
)
```

#### Monthly

Monthly time series are derived from daily ones aggregating by the month.

```{r monthly time series}
region.ts.monthly <- lapply(
  region.df, 
  daily_df_to_monthly_ts
)

area.ts.monthly <- lapply(
  area.df, 
  daily_df_to_monthly_ts
)
```

## Visualization

### Regions daily violaitions

To begin, let's visualize the daily, weekly and monthly **violations** for each **individual region**.

```{r regions ts plot, fig.width=9, fig.height=6}
region.frequecies <- list(region.ts.daily, region.ts.weekly, region.ts.monthly)

for(i in 1:length(region.frequecies)) {
  
  print(names.freq[i])
  
  ts <- region.frequecies[[i]]

  par(mfrow = c(length(ts) %/% 3, 3))
  
  for (region_name in unlist(names.regions)) {
    
    daily        <- ts[[region_name]]
    region_color <- region.colors[[region_name]]
    
    plot(
      daily,
      main=region_name,
      col=region_color,
      ylab=paste(names.freq[i], "violations")
    )
  }
  
  par(mfrow = c(1, 1))

}
```

While the magnitude of the variations varies, the range of values for each series does not seem to require particular transformations. All nine regions exhibit significant, likely monthly, seasonal oscillation. Additionally, some regions reach more pronounced peaks in specific years, such as *Central* in 2017 or *South* in 2021.

### Area violaitions

Let's also visualize the **aggregated** version for each **area**.

```{r areas ts plot, fig.width=8, fig.height=8}
area.frequecies <- list(area.ts.daily, area.ts.weekly, area.ts.monthly)

for(i in 1:length(area.frequecies)) {
  
  print(names.freq[i])
  
  ts <- area.frequecies[[i]]

  par(mfrow = c(length(names.area), 1))
  
  for (area_name in names.area) {
    
    daily      <- ts[[area_name]]
    area_color <- area.colors[[area_name]]
    
    plot(
      daily,
      main=area_name,
      col=area_color,
      ylab=paste(names.freq[i], "violations")
    )
  }
  
  par(mfrow = c(1, 1))
  
}
```

The time series resemble those of the individual regions, but now some local peaks in a particular year are less evident due to the aggregation. A quick visual inspection also suggests a fairly strong similarity in the plots of the *Center* and the *South*. To better compare the three trends with different magnitudes, let's plot them together in a single graph.

```{r area ts single plot, fig.width=6, fig.height=5}
for(i in 1:length(area.frequecies)) {
  
  ts <- area.frequecies[[i]]

  plot_multiple_time_series(
    ts_list=ts,
    colors=area.colors,
    main=paste(names.freq[i], "violations in Chicago area"),
    ylab=paste(names.freq[i], "violations")
  )
  
}
```

The observations recorded in the Center are generally more numerous than those in the North and especially the South. In general, the three regions seem to reflect a shared condition of the city, particularly highlighting a significant factor related to seasonality over the course of a year.

### Anomaly date

From the graphs, the presence of a **remarkable outlier** in 2020 is quite evident. This outlier caused a significant pick in violations in the *Center* and *South* areas of the city, counterbalanced by a sharp decrease in the *North* area of the city.

```{r anomaly date}
get_observation_over_threshold(
  ts=area.ts.daily$Center,
  threshold = 1500
)
```

Inspecting this phenomenon, the date corresponds to`30th May 2020`, when there was a lot of disorder in the city due to urban unrest as a consequence of **Black Lives Matter protest**, see more [here](https://en.wikipedia.org/wiki/George_Floyd_protests_in_Chicago).

<br>
```{r blm protest,  fig.cap="Protesters clash with police in Chicago , on May 30, 2020 during a protest against the death of George Floyd (Photo by Jim Vondruska)", out.width = "400px", echo=FALSE, include=TRUE}
knitr::include_graphics("https://media.nbcchicago.com/2019/09/GettyImages-1216502248.jpg?quality=85&strip=all&fit=8660%2C5773&w=775&h=436&crop=0")
```
<br>

---
# 2. Trend and Seasonality decomposition

## Smoothing and Low-pass filtering

The objective of this section is to utilize **filtering techniques** to analyze certain components of time series data. 

1. Initially, various **smoothing techniques** will be employed to eliminate noise and short-term fluctuations, **emphasizing more apparent patterns**.
2. Similarly, these smoothed components can be utilized as **low-pass filters**, highlighting the **trend** of the time series.
3. From these low-pass filters, **high-pass filters** can be eventually derived to accentuate high-frequency components, such as **seasonality**.

### Simple moving average filter

The filter computes an **arithmetic average** within a time window $p$.

$$
\hat{f}_t = \frac{1}{2p + 1} \sum_{i=-p}^p y_{t+i}
$$

The value of $p$ plays a significant role in determining the effect of smoothing by considering a larger time window. The larger the time window, the less the filter will be affected by high frequency components.

```{r simple ma, fig.width=8, fig.height=8}
# Using different values of p
p        <- c(         60,           120,          183)
p.colors <- c('lawngreen', 'deepskyblue', 'chocolate1')

par(mfrow = c(length(area.ts.daily), 1))

for (area_name in names.area) {
  
  daily <- area.ts.daily[[area_name]]
  
  plot_simple_ma_varying_p(
    ts=daily,
    p=p,
    p.color=p.colors,
    main=paste(area_name, "- Simple Moving Average filter"),
    ylab="Daily violations"
  )
  
}
par(mfrow=c(1,1))
```

As anticipated, higher values of $p$ emphasize a trend that is not influenced by a specific seasonal component. In particular, when $p=183$, it considers a time window of one year and is therefore capable of removing the annual seasonality.

### Binomial filter

The filter computes an **weighted average** within a time window $p$ using Newton binomial coefficients as weights.

$$
\hat{f}_t = \frac{1}{2^{p-1}} \sum_{i=0}^p {p \choose i} y_{t-\lceil p/2\rceil + j}
$$

With respect to simple moving average, more importance is given to observations 
close to the center of filter application.

```{r binomial, fig.width=8, fig.height=8}
# Uncomment to set value and colors different from previous ones
# p        <- c(         60,           120,          183)
# p.colors <- c('lawngreen', 'deepskyblue', 'chocolate1')

par(mfrow = c(length(area.ts.daily), 1))

for (area_name in names.area) {
  
  daily <- area.ts.daily[[area_name]]
  
  plot_binomial_varying_p(
    ts=daily,
    p=p,
    p.color=p.colors,
    main=paste(area_name, "- Binomial filter"),
    ylab="Daily violations"
  )
  
}

par(mfrow=c(1,1))
```


Compared to the results obtained with the moving average, $p$ does not seem to have an effect in changing the type of trend obtained. In all three cases, it produces a smoothed version of the seasonal pattern of the series, eliminating many fluctuations. 

As $p$ increases, enlarging the window, the weight associated with central observations also increases, making it less effective in removing seasonal effects within a given window.

### Deseasoning filter

We can highlight trend by removing seasonality effect, this can be achieved with a filter that averages among two consecutive time windows of a period $p$.

$$
\hat{f}_t = \frac{0.5\ y_{t-p} + y_{t-p+1}+ \ldots + y_0 + \ldots + y_{t+p-1} + 0.5\ y_{t+p}}{p}
$$

Let's consider multiple cases.

#### Weekly deseasoning of daily observations 

The resulting trend reduces a more frequent level of fluctuations that could be attributed to weekly seasonality. However, there still remains a noticeable annual oscillation, likely attributed to monthly patterns.

```{r daily weekly deseasoning, fig.width=8, fig.height=8}
par(mfrow = c(length(area.ts.daily), 1))

for(area_name in names.area) {
  
  daily <- area.ts.daily[[area_name]]
  
  plot(
    daily,
    main=paste(area_name, "- Weekly deseasoning of daily observations"),
    ylab="Daily violations"
  )
  
  deseasonal.trend = deseasoning(
    ts=daily, 
    freq=7
  )
  
  lines(
    deseasonal.trend,
    lty='dashed', lwd=3,
    col='steelblue1'
  )
  
}

par(mfrow=c(1,1))
```
  
#### Yearly deseasoning of daily observations

The trend is capable of almost completely eliminating seasonal effects related to the time of the year.

```{r daily yearly deseasoning, fig.width=8, fig.height=8}
par(mfrow = c(length(area.ts.daily), 1))

for(area_name in names.area) {
  
  daily <- area.ts.daily[[area_name]]
  
  plot(
    daily,
    main=paste(area_name, "- Yearly deseasoning of daily observations"),
    ylab="Daily violations"
  )
  
  deseasonal.trend = deseasoning(
    ts=daily, 
    as.integer(daily.freq)
  )
  
  lines(
    deseasonal.trend,
    lty='dashed', lwd=3,
    col='steelblue1'
  )
  
}

par(mfrow=c(1,1))
```


#### Yearly deseasoning of daily observations

In general we expect a similar outcome as compared to previous one. A smaller number of points highlight a situation very similar to the previous one, where seasonality dependent on the annual cycle is canceled out, thus revealing a certain pattern in the data.

```{r monthly yearly deseasoning, fig.width=8, fig.height=8}
par(mfrow = c(length(area.ts.monthly), 1))

for(area_name in names.area) {
  
  monthly <- area.ts.monthly[[area_name]]
  
  plot(
    monthly,
    main=paste(area_name, "- Yearly deseasoning of monthly data"),
    ylab="Monthly violations"
  )
  
  deseasonal.trend = deseasoning(
    ts=monthly, 
    as.integer(monthly.freq)
  )
  
  lines(
    deseasonal.trend,
    lty='dashed', lwd=3,
    col='steelblue1'
  )
  
}

par(mfrow=c(1,1))
```
  
#### Yearly deseasoning of daily observations

Finally, an analogous situation occurs when considering yearly deseasoning of weekly observations

```{r weekly yearly deseasoning, fig.width=8, fig.height=8}
par(mfrow = c(length(area.ts.weekly), 1))

for(area_name in names.area) {
  
  weekly <- area.ts.weekly[[area_name]]
  
  plot(
    weekly,
    main=paste(area_name, "- Weekly Deseasoning"),
    ylab="Weekly violations"
  )
  
  deseasonal.trend = deseasoning(
    ts=weekly, 
    freq=weekly.freq
  )
  
  lines(
    deseasonal.trend,
    lty='dashed', lwd=3,
    col='steelblue1'
  )
  
}

par(mfrow=c(1,1))
```

### Monthplot

The previous results highlight the importance of a significant seasonal component tied to the month but also indicate the presence of a certain trend. The graphical tool **monthplot** allows visualizing and comparing these two components by showing 12 different time series for each month.

```{r monthplot, fig.width=8, fig.height=8}
par(mfrow = c(length(area.ts.monthly), 1))

for (area_name in names.area) {
  
  monthly <- area.ts.monthly[[area_name]]
  
  monthplot(
    monthly,
    main=paste(area_name, " - Monthplot"),
    ylab="Monthly violations"
  )
  
}
  
par(mfrow=c(1,1))
```

The graph confirms what was expected: the observations exhibit a strong monthly seasonality, generally showing an increase in the summer months and a decrease in the winter months. However, it also reveals a certain systematic trend regardless of the month. The two effects seem more or less balanced in terms of their contribution to the final observation.


### Moving Average Decomposition

To better analyze these properties, let's use the **Moving Average Decomposition** into trend, seasonality, and error.

```{r ma decomposition, fig.width=6, fig.height=5}
for(area_name in names.area) {
  
  daily <- area.ts.daily[[area_name]]
  
  plot_ma_decomposition(
    ts=daily,
    main=paste(area_name, "- Daily MA Decomposition")
  )
}
```

The decomposition highlights a trend that is generally similar for the three areas but with some distinct differences. The seasonality, on the other hand, is common across the entire city. More detailed results on the decomposition will be provided in the next paragraph.

## STL Decomposition

### STL Decomposition - Areas and Frequencies

A more powerful decomposition tool is STL (Seasonal and Trend decomposition using Loess), which relies on Loess smoothing to ensure more flexible seasonality and a robust trend. Let's analyze the decomposition for all three versions.

#### Daily
```{r stl daily decomposition, fig.width=6, fig.height=5}
for(area_name in names.area) {
  
  daily <- area.ts.daily[[area_name]]
  
  plot_stl_decomposition(
    ts=daily,
    main=paste(area_name, "- Daily STL Decomposition")
  )
}
```

#### Weekly
```{r stl weekly decomposition, fig.width=6, fig.height=5}
for(area_name in names.area) {
  
  weekly <- area.ts.weekly[[area_name]]
  
  plot_stl_decomposition(
    ts=weekly,
    main=paste(area_name, "- Weekly STL Decomposition")
  )
}
```

#### Monthly
```{r stl monthly decomposition, fig.width=6, fig.height=5}
for(area_name in names.area) {
  
  monthly <- area.ts.monthly[[area_name]]
  
  plot_stl_decomposition(
    ts=monthly,
    main=paste(area_name, "- Monthly STL Decomposition")
  )
}
```

In general, the results are analogous to those of the moving average, showing a certain type of trend with a common pattern but slightly different behaviors in the three areas. Meanwhile, seasonality linked to the month is practically identical. As anticipated, in terms of contribution to the final observations, the trend and seasonality appear to have a nearly balanced influence, with the error component contributing proportionally less.

### STL - Component comparision

To better inspect the differences between the three areas, let's compare the three components with particular attention to the trend.

#### Trend

```{r stl trend decomposition, fig.width=8, fig.height=6}
plot_stl_components(
  ts_list = area.ts.daily,
  names=names.area,
  component_name="trend", 
  main=paste("Trend comparison of Chicago areas"), 
  ylab="Daily violations"
)
```


The three trends show a peak in *2017* followed by a significant decline, remaining relatively low until the pandemic years. They then experience a rapid growth in *2022*. Some important details to highlight:

* The northern area experiences a further decline in *2020*, leading to a decrease in violations never recorded before. It generally tends to rebound with a slight delay compared to the other two regions.
* While for the north and center, the growth in *2022* is comparable to the levels of the previous 5 years, the southern area surpasses that level significantly.

#### Seasonality

```{r stl decomposition season, fig.width=8, fig.height=6}
plot_stl_components(
  ts_list = area.ts.daily,
  names=names.area,
  component_name="seasonal", 
  main=paste("Seasonal decomposition comparison of Chicago areas"), 
  ylab="Daily violations"
)
```

The seasonal effect is nearly identical and indicates a general condition of the city. The only slight difference that might be noticed is that the summer peaks in the south generally last for a shorter duration.

#### Erratic component

```{r stl decomposition errors, fig.width=8, fig.height=6}
plot_stl_components(
  ts_list = area.ts.daily,
  names=names.area,
  component_name="remainder", 
  main=paste("Error decomposition comparison of Chicago areas"), 
  ylab="Daily violations"
)
```

The erratic component is not entirely satisfactory, as it is possible to identify a pattern that is generally undesirable for the residuals of a model. In particular, errors often tend to be positive before *2018* and after *2021*, and negative in the intervening period, highlighting a different behavior that was hinted at in the trend but perhaps not fully captured.

# 3. Analyzing weekly seasonality

The analysis in the previous chapter highlights a strong component linked to the month but also hint at possible fluctuations within a single month. These fluctuations may be related, for example, to varying conditions concerning the day of the week. This chapter aims to analyze the importance of the weekly component within the observations.

## Correlation of daily observations

### Analyzing ACF and PACF

For first we inspect the autocorrelation function of daily observations $Y_t$. We are interested in the linear correlations at lags multiple of 7.

```{r daily acf pacf, fig.width=8, fig.height=6}
for(area_name in names.area) {
    
  daily <- area.ts.daily[[area_name]]

  tsdisplay(
    daily,
    lag.max=100,
    main=paste(area_name, "- Daily plot"),
    ylab=expression(Y[t])
  )
  
}
```

The ACF shows an exponential decreasing trend, the PACF a sinusoidal decreasing one. The ACF always highlights higher spikes at lag multiple of $7$, that is indicative for the importance of the weekday component. We can not reason in terms of AR and MA interpretation because as we saw the process has a trend and it's not stationary, thus we'll probably need to apply differencing.

## Weekly seasonality

### Weeklyplot

Let's plot an analogous representation of the monthplot for the weekdays, comparing the 7 different time series, each corresponding to a different day of the week.

```{r weeklyplot, fig.width=12, fig.height=3}
for(area_name in names.area) {
    
  df <- area.df[[area_name]]
  
  weeklyplot(
    df=df,
    main=paste(area_name, "- Weekly plot")
  )
}
```

Although there is evidence of an average increase on weekdays, especially on Saturdays, the seasonality does not appear to be significant when compared to the trend, which remains consistent for each weekday.

### Analyzing ACF and PACF of 7-lagged version

Let's firstly inspect the correlation of a $7$-lagged version of the observations considering $\widetilde{Y}_t = Y_t - Y_{t-7}$.

```{r daily 7 lag acf pacf, fig.width=8, fig.height=6}
for(area_name in names.area) {
    
  daily      <- area.ts.daily[[area_name]]
  daily_lag7 <- diff(daily, 7)

  tsdisplay(
    daily_lag7,
    lag.max=60,
    main=paste(area_name, "- 7 lagged Daily plot"),
    ylab=expression(tilde(Y[t]))
  )
  
}
```

The plot still shows important spikes right at lags that are multiple of seven, meaning that the weekly dependence was not eliminated.

### Monthly intercation

The previous approach has likely proven to be unsuccessful as it solely considered a weekly seasonality without taking into account the monthly one, whereas both are likely present. We consider the weekly and monthly aspects together: for each time series, we produce $7\times 12$ plots that correspond to the trend of a certain day of the week in a specific month.


```{r weeklymonthlyplot, fig.width=10, fig.height=22}
for(area_name in names.area) {

  df <- area.df[[area_name]]

  weeklymonthlyplot(
    df=df,
    main=paste(area_name, "- Weekly Monhtly plot")
  )
}
```

For each of the plots, the trend effect adheres to the general pattern that had been extracted from previous analyses. However, now the effect related to the day of the week is more evident, demonstrating an increase during the weekend, with an increase more pronounced in the summer months.

## Weekday and Weekend split

There is evidence in the data of an increase in observations during the weekend. Let's try to create two separate time series for weekdays and weekends.

```{r weekday weekend split}
region.ts.weeklydays <- lapply(
  region.df, 
  daily_df_to_weekly_ts_weekday_weekend
)

area.ts.weeklydays <- lapply(
  area.df, 
  daily_df_to_weekly_ts_weekday_weekend
)
```

### Violations comparison

Let's plot the two in the same plot to investigate the plots.

```{r weekday weekend plot, fig.width=6, fig.height=5}
for(area_name in names.area) {
  
  weekly <- area.ts.weeklydays[[area_name]]
  
  plot_multiple_time_series(
    ts_list = area.ts.weeklydays[[area_name]],
    colors  = list(weekday='steelblue1', weekend='tomato1'),
    main    = paste(area_name, "- Violations in Weekdays and Weekends"),
    ylab    = "Daily violations"
  )
  
}
```

The observations seem to closely follow the same trend, only at different scales due to the varying number of days. 

### Violations per day comparison 

Let's also investigate the number of observations per day.


```{r weekday weekend pday plot, fig.width=4, fig.height=5}
  
for(area_name in names.area) {
  
  weekly <- area.ts.weeklydays[[area_name]]
  
  plot_multiple_time_series(
    ts_list = list(
      weekday = area.ts.weeklydays[[area_name]]$weekday / 5,
      weekend = area.ts.weeklydays[[area_name]]$weekend / 2
    ),
    colors  = list(weekday='steelblue3', weekend='tomato3'),
    main    = paste(area_name, "- Average per-day violations in Weekdays and Weekends"),
    ylab    = "Average per-day violations"
  )
  
}
```

In general, the number of violations per day is higher during the weekend compared to weekdays, the trend is almost the same and the difference between the two tends to amplify during the summer months.

### Weekend and Weekday CCF

This fact can be visualized in a more formal manner by looking at the cross-correlation plot, which highlights a clear linear dependence.

```{r weekday weekend ccf, fig.width=9, fig.height=8}
par(mfrow = c(length(area.ts.weeklydays), 1))

for(area_name in names.area) {
  
  weekly <- area.ts.weeklydays[[area_name]]
  
  ccf(
    x=as.numeric(weekly$weekday),
    y=as.numeric(weekly$weekday),
    lag.max = 50,
    main=paste(area_name ,"- Weekdays and Weekend Cross Correlogram"),
    ylab="CCF"
  )
  
}

par(mfrow=c(1,1))
```

### Linear regression

The linear relationship is so strong that the dependence between the two can be easily modeled by a linear regression.

```{r weekday weekend linear regression, fig.width=7, fig.height=7}
par(mfrow = c(length(area.ts.weeklydays), 1))

for(area_name in names.area) {
  
  weekly <- area.ts.weeklydays[[area_name]]
  
  violations.weekday <- as.numeric(weekly$weekday)
  violations.weekend <- as.numeric(weekly$weekend)
  
  plot(
    x=violations.weekday,
    y=violations.weekend,
    pch=16, col="steelblue",
    main=paste(area_name, "- Weekdays VS Weekend violations"),
    xlab="Weekly violations on weekdays",
    ylab="Weekly violations on weekdays",
  )
  grid()
  
  fit <- lm(violations.weekend ~ violations.weekday)
  abline(fit,  col = "orangered", lwd = 2, lty="dashed")
  
}

par(mfrow=c(1,1))
```

### ARIMA decomposition

To conclude, let's compare their characterization in terms of ARIMA models using the `auto.arima` function. More detailed analyses regarding the ARIMA model description will be the focus of the next chapter.

```{r}
if (FALSE) { ## Avoid recomputing
  for(area_name in names.area) {
    
    fit.weekend <- auto.arima(area.ts.weeklydays[[area_name]]$weekend)
    fit.weekday <- auto.arima(area.ts.weeklydays[[area_name]]$weekday)
    
    print(area_name)
    print(paste("- Weekday:", arima_formula(fit=fit.weekday)))
    print(paste("- Weekend:", arima_formula(fit=fit.weekend)))
    print("")
    
  }
} else {
  cat(
    "North\n",
    "- Weekday: ARIMA(1,1,0) (1,1,0)[50]\n",
    "- Weekend: ARIMA(1,1,0) (0,1,0)[50]\n",
    "\n",
    "Center\n",
    "- Weekday: ARIMA(3,1,0) (1,1,0)[50]\n",
    "- Weekend: ARIMA(0,1,2) (1,1,0)[50]\n",
    "\n",
    "South\n",
    "- Weekday: ARIMA(4,0,0) (1,1,0)[50]\n",
    "- Weekend: ARIMA(2,0,2) (1,1,0)[50]\n",
    "\n"
  )
}
```


The results are interesting because they seem to capture different aspects of the time series. The seasonal component is similar in all six time series, capturing a seasonality of $50$ weeks corresponding to an annual oscillation. While the northern component doesn't show significant differences, the other two have distinct expressions in terms of autoregressive and moving average components. The most noteworthy result is related to the central area, which exhibits an autoregressive part for weekdays and a completely different characterization with moving averages for the weekends.

These findings suggest that, despite a strong linear correspondence in observations, the phenomena generating the observations in the two types may have very different natures. It's important to note that we are placing significant trust in the models calculated by `auto.arima` without inspecting them or performing any diagnostic checks.

# 4. ARIMA Decomposition

## North

### Monthly

#### ACF, PACF and fitting models 

```{r north monthly tsdisplay1, fig.width=8, fig.height=6}
tsdisplay(
  area.ts.monthly$North,
  main = "North - Original time series",
  ylab = "Monthly violations"
)
```

```{r north monthly fit1}
fit.north.monthly <- list()
fit.north.monthly$fit1 <- Arima(
  area.ts.monthly$North, 
  order=c(2, 0, 1)
)
summary(fit.north.monthly$fit1)
```

```{r north monthly tsdisplay2, fig.width=8, fig.height=6}
tsdisplay(
  diff(area.ts.monthly$North, 1),
  main = "North - First order differencing",
  ylab = "Monthly violations"
)
```

```{r north monthly fit2}
fit.north.monthly$fit2 <- Arima(
  area.ts.monthly$North, 
  order=c(4, 1, 1)
)
summary(fit.north.monthly$fit2)
```

```{r north monthly tsdisplay3, fig.width=8, fig.height=6}
tsdisplay(
  diff(area.ts.monthly$North, monthly.freq),
  main = "North - Monthly order differencing",
  ylab = "Monthly violations"
)
```

```{r north monthly fit3}
fit.north.monthly$fit3 <- Arima(
  area.ts.monthly$North, 
  order=c(1, 0, 0),
  seasonal=list(order=c(1, 0, 0), period=monthly.freq)
)
summary(fit.north.monthly$fit3)
```

```{r north monthly tsdisplay4, fig.width=8, fig.height=6}
tsdisplay(
  diff(diff(area.ts.monthly$North, monthly.freq), 1),
  main = "North - Monthly plus first order differencing",
  ylab = "Monthly violations"
)
```

```{r north monthly fit4}
fit.north.monthly$fit4 <- Arima(
  area.ts.monthly$North, 
  order=c(1, 1, 0),
  seasonal=list(order=c(1, 1, 0), period=monthly.freq)
)
summary(fit.north.monthly$fit4)
```

```{r north monthly autofit}
fit.north.monthly$fit5 <- auto.arima(
  area.ts.monthly$North,
  ic="bic",
  trace=TRUE
)
```

#### Best fit selection

```{r north monthly best fit}
fit.north.monthly$best <- arima_selection(
  fit_list = fit.north.monthly,
  criteria = 'bic'
)
fit.north.monthly$best
```

```{r north monthly residuals diagnostic, fig.width=8, fig.height=6}
tsdiag(fit.north.monthly$best)
```

```{r north monthly forecast, fig.width=8, fig.height=6}
plot(forecast(fit.north.monthly$best, h=2*monthly.freq))
```

#### Forecasting on test set

```{r north monthly test forecast, fig.width=8, fig.height=6}
for(date_str in c("2022-01-01", "2022-06-01", "2022-09-01")) {
  
  date <- as.Date(date_str)
  
  errors <- train_test_model(
    ts=area.ts.monthly$North,
    date_split=date,
    arima_order=arimaorder(fit.north.monthly$best),
    freq_type='monthly',
    main=paste('North - Monthly prediction after', date),
    ylab="Monthly violations"
  )

  cat(
    "Errors for ", date, "prediction:\n",
    "MAE:  ", errors$mae,  "\n",
    "MPE:  ", errors$mpe,  "\n",
    "MSE:  ", errors$mse,  "\n",
    "RMSE: ", errors$rmse, "\n"
  )
  
}
```

### Weekly

#### ACF, PACF and fitting models 

```{r north weekly tsdisplay1, fig.width=8, fig.height=6}
tsdisplay(
  area.ts.weekly$North,
  main = "North - Original time series",
  ylab = "Weekly violations"
)
```

```{r north weekly fit1}
fit.north.weekly <- list()
fit.north.weekly$fit1 <- Arima(
  area.ts.weekly$North, 
  order=c(1, 0, 0)
)
summary(fit.north.weekly$fit1)
```

```{r north weekly tsdisplay2, fig.width=8, fig.height=6}
tsdisplay(
  diff(area.ts.weekly$North, 1),
  main = "North - First order differencing",
  ylab = "Weekly violations"
)
```

```{r north weekly fit2}
fit.north.weekly$fit2 <- Arima(
  area.ts.weekly$North, 
  order=c(0, 1, 1)
)
summary(fit.north.weekly$fit2)
```

```{r north weekly tsdisplay3, fig.width=8, fig.height=6}
tsdisplay(
  diff(area.ts.weekly$North, weekly.freq),
  main = "North - Weekly order differencing",
  ylab = "Weekly violations"
)
```

```{r north weekly fit3}
fit.north.weekly$fit3 <- Arima(
  area.ts.weekly$North, 
  order=c(1, 0, 0),
  seasonal=list(order=c(2, 0, 0), period=weekly.freq)
)
summary(fit.north.weekly$fit3)
```

```{r north weekly tsdisplay4, fig.width=8, fig.height=6}
tsdisplay(
  diff(diff(area.ts.weekly$North, weekly.freq), 1),
  main = "North - Weekly plus first order differencing",
  ylab = "Weekly violations"
)
```

```{r north weekly fit4}
fit.north.weekly$fit4 <- Arima(
  area.ts.weekly$North, 
  order=c(2, 1, 0),
  seasonal=list(order=c(1, 1, 0), period=weekly.freq)
)
summary(fit.north.weekly$fit4)
```

```{r north weekly autofit}
fit.north.weekly$fit5 <- auto.arima(
  area.ts.weekly$North,
  ic="bic",
  trace=TRUE
)
```

#### Best fit selection

```{r north weekly best fit}
fit.north.weekly$best <- arima_selection(
  fit_list = fit.north.weekly,
  criteria = 'bic'
)
fit.north.weekly$best
```

```{r north weekly residuals diagnostic, fig.width=8, fig.height=6}
tsdiag(fit.north.weekly$best)
```

```{r north weekly forecast, fig.width=8, fig.height=6}
plot(forecast(fit.north.weekly$best, h=2*weekly.freq))
```

#### Forecasting on test set

```{r north weekly test forecast, fig.width=8, fig.height=6}
for(date_str in c("2022-01-01", "2022-06-01", "2022-09-01")) {
  
  date <- as.Date(date_str)
  
  errors <- train_test_model(
    ts=area.ts.weekly$North,
    date_split=date,
    arima_order=arimaorder(fit.north.weekly$best),
    freq_type='weekly',
    main=paste('North - Weekly prediction after', date),
    ylab="Weekly violations"
  )

  cat(
    "Errors for ", date, "prediction:\n",
    "MAE:  ", errors$mae,  "\n",
    "MPE:  ", errors$mpe,  "\n",
    "MSE:  ", errors$mse,  "\n",
    "RMSE: ", errors$rmse, "\n"
  )
  
}
```


### Daily

#### ACF, PACF and fitting models 

```{r north daily tsdisplay1, fig.width=8, fig.height=6}
tsdisplay(
  area.ts.daily$North,
  main = "North - Original time series",
  ylab = "Daily violations"
)
```

```{r north daily fit1}
fit.north.daily <- list()
fit.north.daily$fit1 <- Arima(
  area.ts.daily$North, 
  order=c(7, 0, 0)
)
summary(fit.north.daily$fit1)
```

```{r north daily tsdisplay2, fig.width=8, fig.height=6}
tsdisplay(
  diff(area.ts.daily$North, 1),
  main = "North - First order differencing",
  ylab = "Daily violations"
)
```

```{r north daily fit2}
fit.north.daily$fit2 <- Arima(
  area.ts.daily$North, 
  order=c(7, 1, 0)
)
summary(fit.north.daily$fit2)
```

```{r north daily tsdisplay3, fig.width=8, fig.height=6}
tsdisplay(
  diff(area.ts.daily$North, as.integer(daily.freq)),
  main = "North - Daily order differencing",
  ylab = "Daily violations"
)
```


```{r north daily tsdisplay4, fig.width=8, fig.height=6}
tsdisplay(
  diff(diff(area.ts.daily$North, as.integer(daily.freq)), 1),
  main = "North - Daily plus first order differencing",
  ylab = "Daily violations"
)
```

```{r north daily fourier fits}
fit.north.daily$fit3 <- Arima(
  area.ts.daily$North, 
  order=c(2,0,0), 
  xreg=fourier(area.ts.daily$North, K=4)
)
summary(fit.north.daily$fit3)
```

```{r north daily autofit}
fit.north.daily$fit4 <- auto.arima(
  area.ts.daily$North,
  ic="bic",
  trace=TRUE
)

fit.north.daily$fit5 <- auto.arima(
  area.ts.daily$North,
  seasonal=FALSE,
  xreg=fourier(area.ts.daily$North, K=4),
  ic="bic",
  trace=TRUE
)
```

#### Best fit selection

```{r north daily best fit}
fit.north.daily$best <- arima_selection(
  fit_list = fit.north.daily,
  criteria = 'bic'
)
fit.north.daily$best
```

```{r north daily residuals diagnostic, fig.width=8, fig.height=6}
tsdiag(fit.north.daily$best)
tsdiag(fit.north.daily$fit5)
```

```{r north daily forecast, fig.width=8, fig.height=6}
plot(forecast(fit.north.daily$best, h=as.integer(daily.freq)))
```

```{r  north daily forecast fuorier, fig.width=8, fig.height=6}
plot(forecast(
  fit.north.daily$fit5,
  h=as.integer(daily.freq),
  xreg=fourier(area.ts.daily$North, K=4, h=as.integer(daily.freq)))
)
```


#### Forecasting on test set

```{r north daily test forecast, fig.width=8, fig.height=6}

for(date_str in c("2022-01-01", "2022-06-01", "2022-09-01")) {
  
  date <- as.Date(date_str)
  
  errors <- train_test_model(
    ts=area.ts.daily$North,
    date_split=date,
    arima_order=arimaorder(fit.north.daily$best),
    freq_type='daily',
    main=paste('North - Weekly prediction after', date),
    ylab="Weekly violations"
  )

  cat(
    "Errors for ", date, "prediction:\n",
    "MAE:  ", errors$mae,  "\n",
    "MPE:  ", errors$mpe,  "\n",
    "MSE:  ", errors$mse,  "\n",
    "RMSE: ", errors$rmse, "\n"
  )
  
}
```

```{r north daily test forecast fuorier, fig.width=8, fig.height=6}

for(date_str in c("2022-01-01", "2022-06-01", "2022-09-01")) {
  
  date <- as.Date(date_str)
  
  errors <- train_test_model(
    ts=area.ts.daily$North,
    date_split=date,
    arima_order=arimaorder(fit.north.daily$fit5),
    fourier_ = 4,
    freq_type='daily',
    main=paste('North - Weekly prediction after', date),
    ylab="Weekly violations"
  )
  
  length(fourier(area.ts.daily$North, K=4, h=365))

  cat(
    "Errors for ", date, "prediction:\n",
    "MAE:  ", errors$mae,  "\n",
    "MPE:  ", errors$mpe,  "\n",
    "MSE:  ", errors$mse,  "\n",
    "RMSE: ", errors$rmse, "\n"
  )
  
}
```
