---
title: "Chicago - Red Light Camera Violations"
author: "Sebastiano Quintavalle"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    theme: united
  pdf_document: default
editor_options: null
  chunk_output_type: console
chunk_output_type: console
---

```{r output setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE)
knitr::opts_chunk$set(include=TRUE)
knitr::opts_chunk$set(fig.align='center')
```

# 1. Data preparation and setup

```{r environment setup, include=FALSE}
rm(list=ls())
Sys.setlocale("LC_TIME", "en_US.UTF-8")
```

```{r packages, include=FALSE}
library(forecast)
```

```{r source files}
source("./src/arima_utils.R")
source("./src/globals.R")
source("./src/plotting.R")
source("./src/smoothing.R")
source("./src/time.R")
```

Read the file preprocessed

```{r reading file}
# Reading the file
violations.region.df <- read.csv(file=violation_file)

# Casting Regions as factors
violations.region.df$Region = as.factor(violations.region.df$Region)

# Converting Date column to DateType
violations.region.df$Date <- as.Date(
  x      = as.character(violations.region.df$Date),
  format = "%m/%d/%Y"
)
```

Let's inspect the very first few lines.
```{r df head}
head(violations.region.df, 15)
```

Moreover, we are take a look to **basics statistics**.
```{r df summary}
summary(violations.region.df)
```

Let's inspect the NAN rows
```{r}
violations.region.df[is.na(violations.region.df$Violations),]
```


For each region we have a total of $2922$ observations, which cover a **time window of 8 years**, from *January 1, 2015*, to *December 31, 2022* (please note *2016* and *2020* are leap years).

There are a total of **nine different regions**.

```{r region levels}
levels(violations.region.df$Region)
```

```{r}
knitr::include_graphics("./out/chicago_sides.png")
```


Creating a list of dataset for each different region

```{r}
region.df <- split(
  violations.region.df,
  violations.region.df$Region
)
```


Creating daily time series

```{r}
region.ts.daily <- lapply(
  region.df, 
  daily_df_to_daily_ts
)
```

Plotting daily time series

```{r}
plot_ts_grid(
  ts_list=region.ts.daily,
  n_row=5,
  names=unlist(names.regions),
  colors=region.colors,
  main="Daily red light camera violations in Chicago regions",
  ylab="Daily violations"
)
```

Different degreees of magnitutes, let's plot together the data

```{r}
plot_multiple_time_series(
  ts_list=region.ts.daily,
  colors=region.colors,
  names=unlist(names.regions),
  main="Daily red light camera violations in Chicago regions",
  ylab="Daily violations"
)
```

Confusing, but from the two we can retrieve two particular critical observations

```{r}
get_observation_over_threshold(
  ts=region.ts.daily$West,
  threshold=700
)

get_observation_over_threshold(
  ts=region.ts.daily$West,
  threshold = 120,
  upper=FALSE
) 

get_observation_over_threshold(
  ts=region.ts.daily$West,
  threshold = 110,
  upper=FALSE
) 


get_observation_over_threshold(
  ts=region.ts.daily$FarSouthEast,
  threshold=300
)
```

First one is about the BLM protest

<br>
```{r blm protest,  fig.cap="Protesters destroy police vehicles , on May 30, 2020 during a protest against the death of George Floyd (Photo by Jim Vondruska)", out.width = "400px", echo=FALSE, include=TRUE}
#https://www.nbcchicago.com/news/local/20-stunning-photos-show-how-protests-unrest-unfolded-in-chicago/2281065/
  knitr::include_graphics("https://media.nbcchicago.com/2019/09/GettyImages-1216502225.jpg?quality=85&strip=all&fit=8660%2C5773&w=775&h=436&crop=0")
```

The second ones corresponds to the very same date for which we have NAN. Nothing is found of the web, possible something didn't work so we can't rely on this observations. We won't work with regions but we must take care of the propagation of this aspect.

Third historic winter snow in the north

Nothing for the 13 August 2013, only swedish house mafia, local to that place, no explanation

https://www.weather.gov/lot/2015_Feb01_Snow



### Weekly 

work at weekly level+ 53 week

```{r}
region.ts.weekly <- lapply(
  region.df,
  daily_df_to_weekly_ts
)

length(region.ts.weekly$Central)
```

```{r}
# Your DataFrame df
df <- data.frame(A = c(1, 2, 3, 4, 5))

# Define your function f(a)
f <- function(a) {
  # Your element-wise operation here
  result <- a * 2  # Replace this with your actual function
  return(result)
}

# Apply the function element-wise and create a new column B
df$B <- f(df$A)
```


```{r}
plot_ts_grid(
  ts_list=region.ts.weekly,
  n_row=5,
  names=unlist(names.regions),
  colors=region.colors,
  main="Avg daily red light camera violations per week in Chicago regions",
  ylab="Avg daily violations per week"
)
```

One point as a summary of seven, smoother reduce variablity over a month. Since can be measliding let's try to plot them together

```{r}
plot_multiple_time_series(
  ts_list=region.ts.weekly,
  colors=region.colors,
  names=unlist(names.regions),
  main="Avg daily red light camera violations per week in Chicago regions",
  ylab="Avg daily violations per week",
  lwd=2
)
```

### Aggregating by areas

The dataset encompasses observations for **nine distinct regions** within Chicago. To streamline the analysis, which could become cumbersome when examining each of the nine regions individually, a **subsequent aggregation** is conducted, categorizing the city into **three primary areas**:

* ***North***: FarNorth, NorthWest, North.
* ***Center***: Central, West, SouthWest, South.
* ***South***: FarSouthWest, FarSouthEast.

Motivate why but in the end it make sense :)

The NAN had no intervention so risk, but as we saw the date is problematic so the problem it's posponed but it will probably end up in a rescheduling. south missing observations.

```{r chicago sides,  fig.cap="Chicago sides", out.width = "700px", echo=FALSE, include=TRUE}
knitr::include_graphics("./out/chicago_sides_and_areas.png")
```

```{r area definition}
# Assigning each Region to the specific Area
violations.region.df$Area <- 
  ifelse(violations.region.df$Region %in% names.regions$North,  'North',
  ifelse(violations.region.df$Region %in% names.regions$Center, 'Center',
  ifelse(violations.region.df$Region %in% names.regions$South,  'South',  NA)))

# Casting to factors
violations.region.df$Area = as.factor(violations.region.df$Area)

# Aggregating violations by areas
violations.area.df = aggregate(
  Violations ~ Area + Date,
  data = violations.region.df,
  sum
)
```

Again we inspect the first few lines of the dataset and we take a look to the principal statistics.

```{r areas head statistics}
# First few observations
head(violations.area.df)

# Basic statistics
summary(violations.area.df)
```

one missing, add 0

```{r}

# Add missing observation
violations.area.df <- rbind(
  violations.area.df, 
  data.frame(
    Area       = as.factor("South"),
    Date       = as.Date("2021-12-07"),
    Violations = 0
  )
)

# Sort the dataset by the date column
violations.area.df <- violations.area.df[order(violations.area.df$Date), ]
```


### Splitting dataset

We utilize the labels associated to each region and area to **partition the dataset into a list** of datasets, with each one linked to a specific region or area.

```{r dataframe area split}
# List of areas
area.df <- split(
  violations.area.df,
  violations.area.df$Area
)
names(area.df)
```

## Creating time series

We employ custom functions to transform the dataset into **daily**, **weekly** and **monthly formats**. The monthly format involves aggregating the total number of violations within each month, revealing essential insights for seasonality analysis.

same reasoning as before at an higher level

```{r}
area.ts.daily <- lapply(
  area.df, 
  daily_df_to_daily_ts
)
```

```{r}
plot_ts_grid(
  ts_list=area.ts.daily,
  n_row=3,
  names=names.area,
  colors=area.colors,
  main="Daily red light camera violations in Chicago areas",
  ylab="Daily violations"
)
```

all in one

```{r}
plot_multiple_time_series(
  ts_list=area.ts.daily,
  names=names.area,
  colors=area.colors,
  main="Daily red light camera violations in Chicago areas",
  ylab="Daily violations"
)
```


With weekly

```{r}
area.ts.weekly <- lapply(
  area.df, 
  daily_df_to_weekly_ts
)
```

```{r}
plot_ts_grid(
  ts_list=area.ts.weekly,
  n_row=3,
  names=names.area,
  colors=area.colors,
  main="Avg daily red light camera violations per week in Chicago regions",
  ylab="Avg daily violations per week"
)
```

all in one

```{r}
plot_multiple_time_series(
  ts_list=area.ts.weekly,
  names=names.area,
  colors=area.colors,
  main="Avg daily red light camera violations per week in Chicago regions",
  ylab="Avg daily violations per week",
  lwd=2
)
```

discuss the approximation form the region, more on the center but in general good

The observations recorded in the Center are generally more numerous than those in the North and especially the South. In general, the three regions seem to reflect a shared condition of the city, particularly highlighting a significant factor related to seasonality over the course of a year.

### Anomaly date

use outliers diagnostic based on stl decomposition

#### North
```{r}
outliers = list()

outliers$North <- outliers_diagnostic(
    ts=area.ts.daily$North,
    colors=list(plot=area.colors$North, 
                old='deeppink', 
                new='steelblue'),
    main=paste("North Outliers"),
    ylab="Daily violations"
  )

```

discuss + replace
```{r}
# replace outliers
area.df$North = replace_outliers(
  df=area.df$North,
  ts=area.ts.daily$North,
  outliers=outliers$North
)
```

#### Center
```{r}
outliers$Center <- outliers_diagnostic(
    ts=area.ts.daily$Center,
    colors=list(plot=area.colors$Center, 
                old='deeppink', 
                new='steelblue'),
    main=paste("Center Outliers"),
    ylab="Daily violations"
)

```

discuss + replace
```{r}
# replace outliers
area.df$Center = replace_outliers(
  df=area.df$Center,
  ts=area.ts.daily$Center,
  outliers=outliers$Center
)
```

#### South
```{r}
outliers$South <- outliers_diagnostic(
    ts=area.ts.daily$South,
    colors=list(plot=area.colors$South, 
                old='deeppink', 
                new='orange'),
    main=paste("South Outliers"),
    ylab="Daily violations"
  )

```

discuss + replace
```{r}
# replace outliers
area.df$South = replace_outliers(
  df=area.df$South,
  ts=area.ts.daily$South,
  outliers=outliers$South
)
```

Regenerate ts starting from dataset
```{r}
area.ts.daily<- lapply(
  area.df, 
  daily_df_to_daily_ts
)
area.ts.weekly <- lapply(
  area.df, 
  daily_df_to_weekly_ts
)
```

and we plot back

```{r}
plot_ts_grid(
  ts_list=area.ts.daily,
  n_row=3,
  names=names.area,
  colors=area.colors,
  main="Daily red light camera violations in Chicago areas",
  ylab="Daily violations"
)
```

```{r}
plot_ts_grid(
  ts_list=area.ts.weekly,
  n_row=3,
  names=names.area,
  colors=area.colors,
  main="Avg daily red light camera violations per week in Chicago regions",
  ylab="Avg daily violations per week"
)
```

---
# 2. Trend and Seasonality decomposition

## Smoothing and Low-pass filtering

The objective of this section is to utilize **filtering techniques** to analyze certain components of time series data. 

1. Initially, various **smoothing techniques** will be employed to eliminate noise and short-term fluctuations, **emphasizing more apparent patterns**.
2. Similarly, these smoothed components can be utilized as **low-pass filters**, highlighting the **trend** of the time series.
3. From these low-pass filters, **high-pass filters** can be eventually derived to accentuate high-frequency components, such as **seasonality**.

### Simple moving average filter

The filter computes an **arithmetic average** within a time window $p$.

$$
\hat{f}_t = \frac{1}{2p + 1} \sum_{i=-p}^p y_{t+i}
$$

The value of $p$ plays a significant role in determining the effect of smoothing by considering a larger time window. The larger the time window, the less the filter will be affected by high frequency components.

```{r simple ma, fig.width=8, fig.height=8}
# Using different values of p
p        <- c(         30,            90,          180)
p.colors <- c('lawngreen', 'deepskyblue', 'chocolate1')

par(mfrow = c(length(area.ts.daily), 1))

for (area_name in names.area) {
  
  daily <- area.ts.daily[[area_name]]
  
  plot_simple_ma_varying_p(
    ts=daily,
    p=p,
    p.color=p.colors,
    main=paste(area_name, "- Simple Moving Average filter"),
    ylab="Daily violations"
  )
  
}
par(mfrow=c(1,1))
```

```{r simple ma, fig.width=8, fig.height=8}
# Using different values of p
p        <- c(          6,            13,            26)
p.colors <- c('lawngreen', 'deepskyblue', 'chocolate1')

par(mfrow = c(length(area.ts.daily), 1))

for (area_name in names.area) {
  
  weekly <- area.ts.weekly[[area_name]]
  
  plot_simple_ma_varying_p(
    ts=weekly,
    p=p,
    p.color=p.colors,
    main=paste(area_name, "- Simple Moving Average filter"),
    ylab="Avg weekly violations pday"
  )
  
}
par(mfrow=c(1,1))
```

As anticipated, higher values of $p$ emphasize a trend that is not influenced by a specific seasonal component. In particular, when $p=183$, it considers a time window of one year and is therefore capable of removing the annual seasonality.

Compared to the results obtained with the moving average, $p$ does not seem to have an effect in changing the type of trend obtained. In all three cases, it produces a smoothed version of the seasonal pattern of the series, eliminating many fluctuations. 

As $p$ increases, enlarging the window, the weight associated with central observations also increases, making it less effective in removing seasonal effects within a given window.

### Deseasoning filter

We can highlight trend by removing seasonality effect, this can be achieved with a filter that averages among two consecutive time windows of a period $p$.

$$
\hat{f}_t = \frac{0.5\ y_{t-p} + y_{t-p+1}+ \ldots + y_0 + \ldots + y_{t+p-1} + 0.5\ y_{t+p}}{p}
$$

Let's consider multiple cases.

#### Weekly deseasoning of daily observations 

The resulting trend reduces a more frequent level of fluctuations that could be attributed to weekly seasonality. However, there still remains a noticeable annual oscillation, likely attributed to monthly patterns.

```{r daily weekly deseasoning, fig.width=8, fig.height=8}
par(mfrow = c(length(area.ts.daily), 1))

for(area_name in names.area) {
  
  daily <- area.ts.daily[[area_name]]
  
  plot(
    daily,
    main=paste(area_name, "- Weekly deseasoning of daily observations"),
    ylab="Daily violations",
    col="dimgray"
  )
  
  deseasonal.trend = deseasoning(
    ts=daily, 
    freq=7
  )
  
  lines(
    deseasonal.trend,
    col='firebrick1', lwd=2
  )
  
}

par(mfrow=c(1,1))
```
  
#### Yearly deseasoning of daily observations

The trend is capable of almost completely eliminating seasonal effects related to the time of the year.

```{r daily yearly deseasoning, fig.width=8, fig.height=8}
par(mfrow = c(length(area.ts.daily), 1))

for(area_name in names.area) {
  
  daily <- area.ts.daily[[area_name]]
  
  plot(
    daily,
    main=paste(area_name, "- Yearly deseasoning of daily observations"),
    ylab="Daily violations",
    col="dimgray"
  )
  
  deseasonal.trend = deseasoning(
    ts=daily, 
    as.integer(daily.freq)
  )
  
  lines(
    deseasonal.trend,
    lty='dashed', lwd=3,
    col='steelblue1'
  )
  
}

par(mfrow=c(1,1))
```

#### Yearly deseasoning of daily observations

Finally, an analogous situation occurs when considering yearly deseasoning of weekly observations

```{r weekly yearly deseasoning, fig.width=8, fig.height=8}
par(mfrow = c(length(area.ts.weekly), 1))

for(area_name in names.area) {
  
  weekly <- area.ts.weekly[[area_name]]
  
  plot(
    weekly,
    main=paste(area_name, "- Weekly Deseasoning"),
    ylab="Weekly violations",
    color="dimgray"
  )
  
  deseasonal.trend = deseasoning(
    ts=weekly, 
    freq=weekly.freq
  )
  
  lines(
    deseasonal.trend,
    lty='dashed', lwd=3,
    col='steelblue1'
  )
  
}

par(mfrow=c(1,1))
```

### Monthplot

The previous results highlight the importance of a significant seasonal component tied to the month but also indicate the presence of a certain trend. The graphical tool **monthplot** allows visualizing and comparing these two components by showing 12 different time series for each month.

```{r monthplot, fig.width=8, fig.height=8}
par(mfrow = c(length(area.df), 1))

for (area_name in names.area) {
  
  monthly <- daily_df_to_monthly_ts(df=area.df[[area_name]])
  
  monthplot(
    monthly,
    main=paste(area_name, " - Monthplot"),
    ylab="Monthly violations"
  )
  
}
  
par(mfrow=c(1,1))
```

The graph confirms what was expected: the observations exhibit a strong monthly seasonality, generally showing an increase in the summer months and a decrease in the winter months. However, it also reveals a certain systematic trend regardless of the month. The two effects seem more or less balanced in terms of their contribution to the final observation.


### Moving Average Decomposition

To better analyze these properties, let's use the **Moving Average Decomposition** into trend, seasonality, and error.

```{r ma decomposition, fig.width=6, fig.height=5}
for(area_name in names.area) {
  
  daily <- area.ts.daily[[area_name]]
  
  plot_ma_decomposition(
    ts=daily,
    main=paste(area_name, "- Daily MA Decomposition")
  )
}
```

The decomposition highlights a trend that is generally similar for the three areas but with some distinct differences. The seasonality, on the other hand, is common across the entire city. More detailed results on the decomposition will be provided in the next paragraph.

## STL Decomposition

### STL Decomposition - Areas and Frequencies

A more powerful decomposition tool is STL (Seasonal and Trend decomposition using Loess), which relies on Loess smoothing to ensure more flexible seasonality and a robust trend. Let's analyze the decomposition for all three versions.

#### Daily
```{r stl daily decomposition, fig.width=6, fig.height=5}
plot_stl_decomposition(
  ts=area.ts.daily$North,
  main=paste("North - Daily STL Decomposition")
)
```

```{r stl daily decomposition, fig.width=6, fig.height=5}
plot_stl_decomposition(
  ts=area.ts.daily$Center,
  main=paste("Center - Daily STL Decomposition")
)
```

```{r stl daily decomposition, fig.width=6, fig.height=5}
plot_stl_decomposition(
  ts=area.ts.daily$South,
  main=paste("South - Daily STL Decomposition")
)
```

#### Weekly
```{r stl daily decomposition, fig.width=6, fig.height=5}
plot_stl_decomposition(
  ts=area.ts.weekly$North,
  main=paste("North - Weekly STL Decomposition")
)
```

```{r stl daily decomposition, fig.width=6, fig.height=5}
plot_stl_decomposition(
  ts=area.ts.weekly$Center,
  main=paste("Center - Weekly STL Decomposition")
)
```

```{r stl daily decomposition, fig.width=6, fig.height=5}
plot_stl_decomposition(
  ts=area.ts.weekly$South,
  main=paste("South - Weekly STL Decomposition")
)
```

### STL - Component comparision

To better inspect the differences between the three areas, let's compare the three components with particular attention to the trend.

#### Trend

```{r stl trend decomposition, fig.width=8, fig.height=6}
plot_stl_components(
  ts_list = area.ts.daily,
  names=names.area,
  component_name="trend", 
  main=paste("Trend comparison of Chicago areas"), 
  ylab="Daily violations"
)
```


The three trends show a peak in *2017* followed by a significant decline, remaining relatively low until the pandemic years. They then experience a rapid growth in *2022*. Some important details to highlight:

* The northern area experiences a further decline in *2020*, leading to a decrease in violations never recorded before. It generally tends to rebound with a slight delay compared to the other two regions.
* While for the north and center, the growth in *2022* is comparable to the levels of the previous 5 years, the southern area surpasses that level significantly.

#### Seasonality

```{r stl decomposition season, fig.width=8, fig.height=6}
plot_stl_components(
  ts_list = area.ts.daily,
  names=names.area,
  component_name="seasonal", 
  main=paste("Seasonal decomposition comparison of Chicago areas"), 
  ylab="Daily violations"
)
```

The seasonal effect is nearly identical and indicates a general condition of the city. The only slight difference that might be noticed is that the summer peaks in the south generally last for a shorter duration.

#### Erratic component

```{r stl decomposition errors, fig.width=8, fig.height=6}
plot_stl_components(
  ts_list = area.ts.daily,
  names=names.area,
  component_name="remainder", 
  main=paste("Error decomposition comparison of Chicago areas"), 
  ylab="Daily violations"
)
```

The erratic component is not entirely satisfactory, as it is possible to identify a pattern that is generally undesirable for the residuals of a model. In particular, errors often tend to be positive before *2018* and after *2021*, and negative in the intervening period, highlighting a different behavior that was hinted at in the trend but perhaps not fully captured.

# 3. Analyzing weekly seasonality

The analysis in the previous chapter highlights a strong component linked to the month but also hint at possible fluctuations within a single month. These fluctuations may be related, for example, to varying conditions concerning the day of the week. This chapter aims to analyze the importance of the weekly component within the observations.

## Correlation of daily observations

### Analyzing ACF and PACF

For first we inspect the autocorrelation function of daily observations $Y_t$. We are interested in the linear correlations at lags multiple of 7.

```{r daily acf pacf, fig.width=8, fig.height=6}
for(area_name in names.area) {
    
  daily <- area.ts.daily[[area_name]]

  tsdisplay(
    daily,
    lag.max=100,
    main=paste(area_name, "- Daily plot"),
    ylab=expression(Y[t])
  )
  
}
```

The ACF shows an exponential decreasing trend, the PACF a sinusoidal decreasing one. The ACF always highlights higher spikes at lag multiple of $7$, that is indicative for the importance of the weekday component. We can not reason in terms of AR and MA interpretation because as we saw the process has a trend and it's not stationary, thus we'll probably need to apply differencing.

## Weekly seasonality

### Weeklyplot

Let's plot an analogous representation of the monthplot for the weekdays, comparing the 7 different time series, each corresponding to a different day of the week.

```{r weeklyplot, fig.width=12, fig.height=3}
for(area_name in names.area) {
    
  df <- area.df[[area_name]]
  
  weeklyplot(
    df=df,
    main=paste(area_name, "- Weekly plot")
  )
}
```

Although there is evidence of an average increase on weekdays, especially on Saturdays, the seasonality does not appear to be significant when compared to the trend, which remains consistent for each weekday.

### Analyzing ACF and PACF of 7-lagged version

Let's firstly inspect the correlation of a $7$-lagged version of the observations considering $\widetilde{Y}_t = Y_t - Y_{t-7}$.

```{r daily 7 lag acf pacf, fig.width=8, fig.height=6}
for(area_name in names.area) {
    
  daily      <- area.ts.daily[[area_name]]
  daily_lag7 <- diff(daily, 7)

  tsdisplay(
    daily_lag7,
    lag.max=60,
    main=paste(area_name, "- 7 lagged Daily plot"),
    ylab=expression(tilde(Y[t]))
  )
  
}
```

The plot still shows important spikes right at lags that are multiple of seven, meaning that the weekly dependence was not eliminated.


## Weekday and Weekend split

There is evidence in the data of an increase in observations during the weekend. Let's try to create two separate time series for weekdays and weekends.

```{r weekday weekend split}
area.ts.weeklydays <- lapply(
  area.df, 
  daily_df_to_weekly_ts_weekday_weekend
)
```

### Violations comparison

Let's plot the two in the same plot to investigate the plots.

```{r weekday weekend plot, fig.width=6, fig.height=5}
par(mfrow=c(3, 1))
for(area_name in names.area) {
  
  weekly <- area.ts.weeklydays[[area_name]]
  
  plot_multiple_time_series(
    ts_list = weekly,
    names   = names(weekly),
    colors  = list(weekday='steelblue1', weekend='tomato1'),
    main    = paste(area_name, "- Violations in Weekdays and Weekends"),
    ylab    = "Average daily violations"
  )
  
}
par(mfrow=c(1, 1))
```

In general, the number of violations per day is higher during the weekend compared to weekdays, the trend is almost the same and the difference between the two tends to amplify during the summer months.

### Weekend and Weekday CCF

This fact can be visualized in a more formal manner by looking at the cross-correlation plot, which highlights a clear linear dependence.

```{r weekday weekend ccf, fig.width=9, fig.height=8}
par(mfrow = c(length(area.ts.weeklydays), 1))

for(area_name in names.area) {
  
  weekly <- area.ts.weeklydays[[area_name]]
  
  ccf(
    x=as.numeric(weekly$weekday),
    y=as.numeric(weekly$weekday),
    lag.max = 50,
    main=paste(area_name ,"- Weekdays and Weekend Cross Correlogram"),
    ylab="CCF"
  )
  
}

par(mfrow=c(1,1))
```

### Linear regression

The linear relationship is so strong that the dependence between the two can be easily modeled by a linear regression.

```{r weekday weekend linear regression, fig.width=7, fig.height=7}
par(mfrow = c(length(area.ts.weeklydays), 1))

for(area_name in names.area) {
  
  weekly <- area.ts.weeklydays[[area_name]]
  
  violations.weekday <- as.numeric(weekly$weekday)
  violations.weekend <- as.numeric(weekly$weekend)
  
  plot(
    x=violations.weekday,
    y=violations.weekend,
    pch=16, col="steelblue",
    main=paste(area_name, "- Weekdays VS Weekend violations"),
    xlab="Weekly violations on weekdays",
    ylab="Weekly violations on weekdays",
  )
  grid()
  
  fit <- lm(violations.weekend ~ violations.weekday)
  abline(fit,  col = "orangered", lwd = 2, lty="dashed")
  
}

par(mfrow=c(1,1))
```

# 4. ARIMA Decomposition

Train test split
```{r}
area.ts.daily.split  <- lapply(
  area.ts.daily,
  function(ts) {
    split_ts(ts=ts, date_split=as.Date("2022-01-01"), train_test = TRUE)
  }
)
fit.daily <- list()
area.ts.weekly.split  <- lapply(
  area.ts.weekly,
  function(ts) {
    split_ts(ts=ts, date_split=as.Date("2022-01-01"), train_test = TRUE)
  }
)
fit.weekly <- list()
```

# Daily

```{r}
plot_multiple_time_series(
  ts_list=area.ts.daily.split$Center,
  names=names(area.ts.daily.split$Center),
  colors=list(train="steelblue", test="orange2"),
  main="North, daily - Train test split",
  ylab=names.ylab$Daily,
)
```


```{r north monthly tsdisplay1, fig.width=8, fig.height=6}
tsdisplay(
  area.ts.daily.split$Center$train,
  main = "Center - Original time series",
  ylab = names.ylab$Daily
)
```

```{r north monthly fit1}
fit.daily$Center <- list()
fit.daily$Center$fit1 <- Arima(
  area.ts.daily.split$Center$train, 
  order=c(4, 0, 2)
)
summary(fit.daily$Center$fit1)
```

```{r north monthly tsdisplay2, fig.width=8, fig.height=6}
tsdisplay(
  diff(area.ts.daily.split$Center$train, 1),
  main = "Center - First order differencing",
  ylab = paste(names.ylab$Daily, "- Diff(1)"),
  lag.max = 70
)
```

```{r north monthly fit1}
fit.daily$Center$fit2 <- Arima(
  area.ts.daily.split$Center$train, 
  order=c(3, 1, 2)
)
summary(fit.daily$Center$fit2)
```

```{r north monthly tsdisplay3, fig.width=8, fig.height=6}
tsdisplay(
  diff(area.ts.daily.split$Center$train, as.integer(daily.freq)),
  main = "Center - Daily order differencing",
  ylab = paste(names.ylab$Daily, "- Diff(", as.integer(daily.freq), ")", sep=""),
  lag.max = 70
)
```

```{r north monthly tsdisplay4, fig.width=8, fig.height=6}
tsdisplay(
  diff(diff(area.ts.daily.split$Center$train, as.integer(daily.freq)), 1),
  main = "Center - Daily order differencing",
  ylab = paste(names.ylab$Daily, "- Diff(", as.integer(daily.freq), ", 1)", sep=""),
  lag.max = 70
)
```


```{r north monthly autofit}
# fit.daily$Center$auto <- auto.arima(
#   area.ts.daily.split$Center$train,
#   trace=TRUE,
#   ic="aicc"
# )
fit.weekly$Center$auto <- Arima(
  area.ts.daily.split$Center$train,
  order=c(5, 1, 1)
)

summary(fit.daily$Center$auto)
```

#### Best fit selection

```{r north monthly best fit}
fit.daily$Center$best <- arima_fit_selection(
  fit_list = fit.daily$Center,
  criteria = 'AICc'
)
```

```{r north monthly residuals diagnostic, fig.width=8, fig.height=6}
tsdiag(fit.daily$Center$best)
```


```{r north monthly test forecast, fig.width=8, fig.height=6}
par(mfrow=c(2, 2))

split_dates <- list(
  as.Date("2022-01-01"),
  as.Date("2022-06-01"),
  as.Date("2022-09-01"),
  as.Date("2022-12-01")
)

errors <- model_evaluation_multiple(
  ts=area.ts.daily$Center,
  model=fit.daily$Center$best,
  split_dates=split_dates,
  main="Prediction until",
  ylab=names.ylab$Daily
)
par(mfrow=c(1, 1))
print(errors)
```

```{r}
single_prediction <- model_evaluate_single_prediction(
  ts=area.ts.daily$Center,
  model=fit.daily$Center$best,
  date_start=as.Date("2022-01-01"), # first monday
  date_end=as.Date("2022-12-31"),
  freq_type="daily",
  main="aa",
  ylab="bb"
)
```

```{r}
errors_analysis(
  pred_ts = single_prediction,
  error_type = "RMSE",
  k=15,
  freq_type = "daily",
  start_date=as.Date("2022-01-03"),
  main="AA",
  ylab="BB"
)
```

# Weekly

Train test split
```{r}
plot_multiple_time_series(
  ts_list=area.ts.weekly.split$Center,
  names=names(area.ts.weekly.split$Center),
  colors=list(train="steelblue", test="orange2"),
  main="North, weekly - Train test split",
  ylab=names.ylab$Weekly,
)
```


```{r north monthly tsdisplay1, fig.width=8, fig.height=6}
tsdisplay(
  area.ts.weekly.split$Center$train,
  main = "Center - Original time series",
  ylab = names.ylab$Weekly
)
```

```{r north monthly fit1}
fit.weekly <- list()
fit.weekly$Center <- list()
fit.weekly$Center$fit_orig <- Arima(
  area.ts.weekly.split$Center$train, 
  order=c(5, 0, 0)
)
summary(fit.weekly$Center$fit_orig)
```

```{r north monthly tsdisplay2, fig.width=8, fig.height=6}
tsdisplay(
  diff(area.ts.weekly.split$Center$train, 1),
  main = "Center - First order differencing",
  ylab = paste(names.ylab$Weekly, "- Diff(1)"),
  lag.max = 70
)
```


```{r north monthly tsdisplay3, fig.width=8, fig.height=6}
tsdisplay(
  diff(area.ts.weekly.split$Center$train, weekly.freq),
  main = "Center - Weekly order differencing",
  ylab = paste(names.ylab$Weekly, "- Diff(", weekly.freq, ")", sep=""),
  lag.max = 70
)
```

```{r north monthly tsdisplay4, fig.width=8, fig.height=6}
tsdisplay(
  diff(diff(area.ts.weekly.split$Center$train, weekly.freq), 1),
  main = "Center - Weekly order differencing plus fist order differencing",
  ylab = paste(names.ylab$Weekly, "- Diff(", weekly.freq, ", 1)", sep=""),
  lag.max = 70
)
```

```{r north monthly fit4}
fit.weekly$Center$seasonal <- Arima(
  area.ts.weekly.split$Center$train, 
  order=c(0, 1, 1),
  seasonal=list(order=c(0, 1, 1), period=weekly.freq)
)
summary(fit.weekly$Center$seasonal)
```

```{r north monthly autofit}
# fit.weekly$Center$auto <- auto.arima(
#   area.ts.weekly.split$Center$train,
#   trace=TRUE,
#   ic="aicc"
# )
fit.weekly$Center$auto <- Arima(
  area.ts.weekly.split$Center$train, 
  order=c(1, 1, 0),
  seasonal=list(order=c(1, 1, 0), period=weekly.freq)
)

summary(fit.weekly$Center$auto)
```

#### Best fit selection

```{r north monthly best fit}
fit.weekly$Center$best <- arima_fit_selection(
  fit_list = fit.weekly$Center,
  criteria = 'AICc'
)
```

```{r north monthly residuals diagnostic, fig.width=8, fig.height=6}
tsdiag(fit.weekly$Center$best)
```


```{r north monthly test forecast, fig.width=8, fig.height=6}
par(mfrow=c(2, 2))

split_dates <- list(
  as.Date("2022-01-01"),
  as.Date("2022-06-01"),
  as.Date("2022-09-01"),
  as.Date("2022-12-01")
)

errors <- model_evaluation_multiple(
  ts=area.ts.weekly$Center,
  model=fit.weekly$Center$best,
  split_dates=split_dates,
  main="Prediction until",
  ylab=names.ylab$Weekly
)
par(mfrow=c(1, 1))
print(errors)
```

```{r}
single_prediction <- model_evaluate_single_prediction(
  ts=area.ts.weekly$Center,
  model=fit.weekly$Center$best,
  date_start=as.Date("2022-01-03"), # first monday
  date_end=as.Date("2022-12-31"),
  freq_type="weekly",
  main="aa",
  ylab="bb"
)
```

```{r}
errors_analysis(
  pred_ts = single_prediction,
  error_type = "RMSE",
  k=5,
  freq_type = "weekly",
  start_date=as.Date("2022-01-03"),
  main="AA",
  ylab="BB"
)
```


# Dynamic regression

### Weekly

```{r}
ccf(
  y=as.numeric(area.ts.weekly$Center), 
  x=as.numeric(area.ts.weekly$North),
  lag.max = 100
)
ccf(
  x=as.numeric(area.ts.weekly$Center),
  y=as.numeric(area.ts.weekly$South), 
  lag.max = 100
)
```

### Daily
```{r}
ccf(
  y=as.numeric(area.ts.daily$Center), 
  x=as.numeric(area.ts.daily$North),
  lag.max = 100
)
ccf(
  x=as.numeric(area.ts.daily$Center),
  y=as.numeric(area.ts.daily$South), 
  lag.max = 100
)
```

### Linear
```{r}
plot(
  x=as.numeric(area.ts.weekly$North),
  y=as.numeric(area.ts.weekly$Center)
)
grid()
lm1 <- lm(area.ts.weekly$Center ~ area.ts.weekly$North)
summary(lm1)
abline(lm1,  col = "orangered", lwd = 2, lty="dashed")
checkresiduals(resid(lm1))
```

```{r}
plot(
  x=as.numeric(area.ts.weekly$South),
  y=as.numeric(area.ts.weekly$Center)
)
grid()
lm2 <- lm(area.ts.weekly$Center ~ area.ts.weekly$South)
summary(lm2)
abline(lm2,  col = "orangered", lwd = 2, lty="dashed")
checkresiduals(resid(lm2))
```

```{r}
lm3 <- lm(area.ts.weekly$Center ~ area.ts.weekly$North + area.ts.weekly$South)
summary(lm3)
checkresiduals(resid(lm3))
```

```{r}
fit1 <- auto.arima(
  area.ts.weekly.split$Center$train,
  xreg=area.ts.weekly.split$North$train
)
summary(fit1)
```

```{r}
fit2 <- auto.arima(
  area.ts.weekly.split$Center$train,
  xreg=area.ts.weekly.split$South$train
)
summary(fit2)
```

```{r}
aaa
models <- list(
  mod1 = list(fit=fit1, xreg=area.ts.weekly.split$North$test, main="AA", col="red"),
  mod2 = list(fit=fit2, xreg=area.ts.weekly.split$South$test, main="BB", col="green"),
  mod3 = list(fit=fit.weekly$Center$best, h=length(area.ts.weekly.split$South$test), main="CC", col="blue"
)
)

compare_models_ic(
  models=models,
  ylab=names.ylab$Weekly
)

```

```{r}
compare_models_prediction_error(
  models=models,
  train=area.ts.weekly.split$Center$train,
  test=area.ts.weekly.split$Center$test,
  main="AA",
  ylab="bb"
)

compare_models_prediction_error(
  models=models,
  train=area.ts.weekly.split$Center$train,
  test=area.ts.weekly.split$Center$test,
  main="AA",
  ylab="bb",
  plot_train = FALSE
)
```







